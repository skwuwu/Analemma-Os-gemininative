{
  "Comment": "Orchestrator that executes user workflows in segment units and handles HITP",
  "StartAt": "CheckForInjectedConfig",
  "States": {
    "CheckForInjectedConfig": {
      "Type": "Choice",
      "Comment": "Bypass DynamoDB if MOCK_MODE is true and test config exists",
      "Choices": [
        {
          "And": [
            {
              "Variable": "$.MOCK_MODE",
              "StringEquals": "true"
            },
            {
              "Variable": "$.test_workflow_config",
              "IsPresent": true
            }
          ],
          "Next": "InitializeStateData"
        }
      ],
      "Default": "CheckForExistingExecution"
    },
    "CheckForExistingExecution": {
      "Type": "Task",
      "Resource": "arn:aws:states:::dynamodb:getItem",
      "Comment": "[2nd Priority Optimization] Direct SDK Integration: Remove Lambda Cold Start. Query idempotency_key directly from DynamoDB",
      "Parameters": {
        "TableName": "${IdempotencyTable}",
        "Key": {
          "idempotency_key": {
            "S.$": "$.idempotency_key"
          }
        },
        "ProjectionExpression": "executionArn, #st",
        "ExpressionAttributeNames": {
          "#st": "status"
        }
      },
      "ResultSelector": {
        "existing_execution_arn.$": "$.Item.executionArn.S",
        "existing_execution_status.$": "$.Item.status.S"
      },
      "ResultPath": "$.idempotency_check_result",
      "Retry": [
        {
          "ErrorEquals": [
            "DynamoDB.ServiceException",
            "DynamoDB.ThrottlingException",
            "States.TaskFailed"
          ],
          "IntervalSeconds": 2,
          "MaxAttempts": 3,
          "BackoffRate": 2.0,
          "Comment": "DynamoDB ÏùºÏãúÏ†Å Ïò§Î•òÏóê ÎåÄÌïú Ïû¨ÏãúÎèÑ"
        }
      ],
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Comment": "Î©±Îì±ÏÑ± Ï≤¥ÌÅ¨ Ïã§Ìå® Ïãú ÏïàÏ†ÑÌïú Ï≤òÎ¶¨",
          "ResultPath": "$.idempotency_error",
          "Next": "HandleIdempotencyFailure"
        }
      ],
      "Next": "HandleExistingExecution"
    },
    "HandleIdempotencyFailure": {
      "Type": "Choice",
      "Comment": "Î©±Îì±ÏÑ± Ï≤¥ÌÅ¨ Ïã§Ìå® Ïãú ÏïàÏ†Ñ Î™®Îìú ÌôïÏù∏",
      "Choices": [
        {
          "Variable": "$.ALLOW_UNSAFE_EXECUTION",
          "BooleanEquals": true,
          "Next": "InitializeStateData"
        }
      ],
      "Default": "FailIdempotencyUnavailable"
    },
    "FailIdempotencyUnavailable": {
      "Type": "Fail",
      "Error": "IdempotencyCheckFailed",
      "Cause": "Unable to verify execution uniqueness. DynamoDB idempotency check failed and unsafe execution is not allowed."
    },
    "HandleExistingExecution": {
      "Type": "Choice",
      "Comment": "If an existing execution is found, decide whether to resume or fail",
      "Choices": [
        {
          "And": [
            {
              "Variable": "$.idempotency_check_result.existing_execution_arn",
              "IsPresent": true
            },
            {
              "Variable": "$.idempotency_check_result.existing_execution_status",
              "StringEquals": "RUNNING"
            }
          ],
          "Next": "FailDuplicateExecution"
        },
        {
          "And": [
            {
              "Variable": "$.idempotency_check_result.existing_execution_arn",
              "IsPresent": true
            },
            {
              "Variable": "$.idempotency_check_result.existing_execution_status",
              "StringEquals": "SUCCEEDED"
            }
          ],
          "Next": "SucceedDuplicateExecution"
        }
      ],
      "Default": "InitializeStateData"
    },
    "FailDuplicateExecution": {
      "Type": "Fail",
      "Error": "DuplicateExecution",
      "Cause": "An execution with the same idempotency key is already running."
    },
    "SucceedDuplicateExecution": {
      "Type": "Succeed",
      "Comment": "An execution with the same idempotency key already succeeded."
    },
    "InitializeStateData": {
      "Type": "Task",
      "Resource": "arn:aws:states:::lambda:invoke",
      "Comment": "[3ÏàúÏúÑ ÏµúÏ†ÅÌôî] S3 path Î°úÏßÅÏùÑ Lambda ÎÇ¥Î∂ÄÎ°ú Ìù°Ïàò. CheckS3PathPresent, InitializeExecutionWithS3/Inline Ï†úÍ±∞Îê®.",
      "Parameters": {
        "FunctionName": "${InitializeStateDataArn}",
        "InvocationType": "RequestResponse",
        "Payload": {
          "input.$": "$"
        }
      },
      "ResultSelector": {
        "workflow_config.$": "$.Payload.workflow_config",
        "current_state.$": "$.Payload.current_state",
        "input.$": "$.Payload.input",
        "state_s3_path.$": "$.Payload.state_s3_path",
        "state_history.$": "$.Payload.state_history",
        "ownerId.$": "$.Payload.ownerId",
        "workflowId.$": "$.Payload.workflowId",
        "segment_to_run.$": "$.Payload.segment_to_run",
        "idempotency_key.$": "$.Payload.idempotency_key",
        "quota_reservation_id.$": "$.Payload.quota_reservation_id",
        "total_segments.$": "$.Payload.total_segments",
        "partition_map.$": "$.Payload.partition_map",
        "partition_map_s3_path.$": "$.Payload.partition_map_s3_path",
        "segment_manifest.$": "$.Payload.segment_manifest",
        "segment_manifest_s3_path.$": "$.Payload.segment_manifest_s3_path",
        "state_durations.$": "$.Payload.state_durations",
        "last_update_time.$": "$.Payload.last_update_time",
        "start_time.$": "$.Payload.start_time",
        "max_loop_iterations.$": "$.Payload.max_loop_iterations",
        "max_branch_iterations.$": "$.Payload.max_branch_iterations",
        "loop_counter.$": "$.Payload.loop_counter",
        "max_concurrency.$": "$.Payload.max_concurrency",
        "distributed_mode.$": "$.Payload.distributed_mode",
        "llm_segments.$": "$.Payload.llm_segments",
        "hitp_segments.$": "$.Payload.hitp_segments",
        "distributed_strategy.$": "$.Payload.distributed_strategy",
        "distributed_strategy_detail.$": "$.Payload.distributed_strategy_detail"
      },
      "ResultPath": "$.state_data",
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "ResultPath": "$.init_error",
          "Next": "HandleInitFailure"
        }
      ],
      "Next": "CheckLargeWorkflow"
    },
    "HandleInitFailure": {
      "Type": "Task",
      "Resource": "arn:aws:states:::events:putEvents",
      "Comment": "[Fix] InitializeStateData Ïã§Ìå® Ïãú ÏõêÎ≥∏ ÏûÖÎ†•ÏóêÏÑú ownerId Ï∂îÏ∂ú",
      "Parameters": {
        "Entries": [
          {
            "EventBusName": "${WorkflowEventBusArn}",
            "Source": "backend-workflow.lifecycle",
            "DetailType": "WorkflowLifecycleEvent",
            "Detail": {
              "execution_id.$": "$$.Execution.Id",
              "ownerId.$": "$.ownerId",
              "workflowId.$": "$.workflowId",
              "status": "FAILED",
              "notification_type": "execution_progress",
              "message": "Workflow initialization failed",
              "error.$": "$.init_error"
            }
          }
        ]
      },
      "Next": "InitializationFailed"
    },
    "InitializationFailed": {
      "Type": "Fail",
      "Error": "InitializationFailed",
      "Cause": "Failed to initialize workflow state data"
    },
    "CheckLargeWorkflow": {
      "Type": "Choice",
      "Comment": "Check if workflow is very large (>200 segments) and send monitoring warning",
      "Choices": [
        {
          "Variable": "$.state_data.total_segments",
          "NumericGreaterThan": 200,
          "Next": "NotifyLargeWorkflowWarning"
        }
      ],
      "Default": "NotifyWorkflowStarted"
    },
    "NotifyLargeWorkflowWarning": {
      "Type": "Task",
      "Resource": "arn:aws:states:::events:putEvents",
      "Comment": "Notify about very large workflow that may approach Event History limits",
      "Parameters": {
        "Entries": [
          {
            "EventBusName": "${WorkflowEventBusArn}",
            "Source": "backend-workflow.lifecycle",
            "DetailType": "WorkflowLifecycleEvent",
            "Detail": {
              "execution_id.$": "$$.Execution.Id",
              "ownerId.$": "$.state_data.ownerId",
              "workflowId.$": "$.state_data.workflowId",
              "total_segments.$": "$.state_data.total_segments",
              "warning": "Very large workflow detected - monitor Event History usage closely",
              "notification_type": "execution_progress",
              "status": "LARGE_WORKFLOW_WARNING"
            }
          }
        ]
      },
      "ResultPath": "$.large_workflow_warning",
      "Next": "NotifyWorkflowStarted"
    },
    "NotifyWorkflowStarted": {
      "Type": "Task",
      "Resource": "arn:aws:states:::events:putEvents",
      "Comment": "üöÄ Fire-and-forget: Publish workflow start event to EventBridge for async processing",
      "Parameters": {
        "Entries": [
          {
            "EventBusName": "${WorkflowEventBusArn}",
            "Source": "backend-workflow.lifecycle",
            "DetailType": "WorkflowLifecycleEvent",
            "Detail": {
              "TaskToken": "PROGRESS_NOTIFICATION",
              "userId.$": "$.state_data.ownerId",
              "ownerId.$": "$.state_data.ownerId",
              "state_data.$": "$.state_data",
              "conversation_id.$": "$$.Execution.Id",
              "execution_id.$": "$$.Execution.Id",
              "workflowId.$": "$.state_data.workflowId",
              "notification_type": "execution_progress",
              "status": "RUNNING",
              "message": "Workflow started",
              "segment_to_run.$": "$.state_data.segment_to_run"
            }
          }
        ]
      },
      "ResultPath": "$.notification_result",
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Comment": "EventBridge publish failure should not stop workflow",
          "ResultPath": "$.notification_error",
          "Next": "SelectDistributedStrategy"
        }
      ],
      "Next": "SelectDistributedStrategy"
    },
    "SelectDistributedStrategy": {
      "Type": "Choice",
      "Comment": "üöÄ Hybrid Mode: Select execution strategy based on workflow characteristics",
      "Choices": [
        {
          "Variable": "$.state_data.distributed_strategy",
          "StringEquals": "MAP_REDUCE",
          "Next": "ExecuteMapReduceMode"
        },
        {
          "Variable": "$.state_data.distributed_strategy",
          "StringEquals": "BATCHED",
          "Next": "ExecuteBatchedMode"
        }
      ],
      "Default": "ExecuteSegment"
    },
    "ExecuteMapReduceMode": {
      "Type": "Map",
      "Comment": "üöÄ MAP_REDUCE: High-concurrency parallel execution with S3 aggregation",
      "MaxConcurrencyPath": "$.state_data.max_concurrency",
      "ItemsPath": "$.state_data.segment_manifest",
      "Parameters": {
        "segment_config.$": "$$.Map.Item.Value.segment_config",
        "segment_id.$": "$$.Map.Item.Value.segment_id",
        "execution_order.$": "$$.Map.Item.Value.execution_order",
        "workflow_config.$": "$.state_data.workflow_config",
        "current_state.$": "$.state_data.current_state",
        "ownerId.$": "$.state_data.ownerId",
        "workflowId.$": "$.state_data.workflowId",
        "idempotency_key.$": "$.state_data.idempotency_key",
        "total_segments.$": "$.state_data.total_segments",
        "partition_map_s3_path.$": "$.state_data.partition_map_s3_path",
        "execution_mode": "MAP_REDUCE"
      },
      "Iterator": {
        "StartAt": "MapReduceSegmentRunner",
        "States": {
          "MapReduceSegmentRunner": {
            "Type": "Task",
            "Resource": "arn:aws:states:::lambda:invoke",
            "Parameters": {
              "FunctionName": "${ExecuteSegmentArn}",
              "InvocationType": "RequestResponse",
              "Payload.$": "$"
            },
            "ResultSelector": {
              "status.$": "$.Payload.status",
              "segment_id.$": "$.Payload.segment_id",
              "output_s3_path.$": "$.Payload.final_state_s3_path"
            },
            "Retry": [
              {
                "ErrorEquals": [
                  "Lambda.TooManyRequestsException"
                ],
                "IntervalSeconds": 5,
                "MaxAttempts": 10,
                "BackoffRate": 2.0,
                "JitterStrategy": "FULL"
              }
            ],
            "End": true
          }
        }
      },
      "ResultPath": "$.map_reduce_results",
      "Next": "AggregateMapReduceResults"
    },
    "AggregateMapReduceResults": {
      "Type": "Task",
      "Resource": "arn:aws:states:::lambda:invoke",
      "Comment": "Aggregate all Map-Reduce results from S3 into final state",
      "Parameters": {
        "FunctionName": "${AggregateResultsArn}",
        "Payload": {
          "map_results.$": "$.map_reduce_results",
          "ownerId.$": "$.state_data.ownerId",
          "workflowId.$": "$.state_data.workflowId",
          "execution_mode": "MAP_REDUCE"
        }
      },
      "ResultSelector": {
        "final_state.$": "$.Payload.final_state",
        "status.$": "$.Payload.status"
      },
      "ResultPath": "$.aggregation_result",
      "Next": "NotifyWorkflowCompleted"
    },
    "ExecuteBatchedMode": {
      "Type": "Map",
      "Comment": "üöÄ BATCHED: Controlled batch processing with moderate concurrency",
      "MaxConcurrency": 10,
      "ItemsPath": "$.state_data.segment_manifest",
      "Parameters": {
        "segment_config.$": "$$.Map.Item.Value.segment_config",
        "segment_id.$": "$$.Map.Item.Value.segment_id",
        "execution_order.$": "$$.Map.Item.Value.execution_order",
        "dependencies.$": "$$.Map.Item.Value.dependencies",
        "workflow_config.$": "$.state_data.workflow_config",
        "current_state.$": "$.state_data.current_state",
        "ownerId.$": "$.state_data.ownerId",
        "workflowId.$": "$.state_data.workflowId",
        "idempotency_key.$": "$.state_data.idempotency_key",
        "total_segments.$": "$.state_data.total_segments",
        "partition_map_s3_path.$": "$.state_data.partition_map_s3_path",
        "execution_mode": "BATCHED"
      },
      "Iterator": {
        "StartAt": "BatchedSegmentRunner",
        "States": {
          "BatchedSegmentRunner": {
            "Type": "Task",
            "Resource": "arn:aws:states:::lambda:invoke",
            "Parameters": {
              "FunctionName": "${ExecuteSegmentArn}",
              "InvocationType": "RequestResponse",
              "Payload.$": "$"
            },
            "ResultSelector": {
              "status.$": "$.Payload.status",
              "segment_id.$": "$.Payload.segment_id",
              "final_state.$": "$.Payload.final_state"
            },
            "Retry": [
              {
                "ErrorEquals": [
                  "Lambda.TooManyRequestsException"
                ],
                "IntervalSeconds": 3,
                "MaxAttempts": 5,
                "BackoffRate": 2.0,
                "JitterStrategy": "FULL"
              }
            ],
            "End": true
          }
        }
      },
      "ResultPath": "$.batched_results",
      "Next": "AggregateBatchedResults"
    },
    "AggregateBatchedResults": {
      "Type": "Task",
      "Resource": "arn:aws:states:::lambda:invoke",
      "Comment": "Aggregate batched execution results",
      "Parameters": {
        "FunctionName": "${AggregateResultsArn}",
        "Payload": {
          "batch_results.$": "$.batched_results",
          "ownerId.$": "$.state_data.ownerId",
          "workflowId.$": "$.state_data.workflowId",
          "execution_mode": "BATCHED"
        }
      },
      "ResultSelector": {
        "final_state.$": "$.Payload.final_state",
        "status.$": "$.Payload.status"
      },
      "ResultPath": "$.aggregation_result",
      "Next": "NotifyWorkflowCompleted"
    },
    "ExecuteSegment": {
      "Type": "Task",
      "Resource": "arn:aws:states:::lambda:invoke",
      "Comment": "Execute a single segment of the user workflow",
      "Parameters": {
        "FunctionName": "${ExecuteSegmentArn}",
        "InvocationType": "RequestResponse",
        "Payload": {
          "workflow_config.$": "$.state_data.workflow_config",
          "current_state.$": "$.state_data.current_state",
          "state_history.$": "$.state_data.state_history",
          "ownerId.$": "$.state_data.ownerId",
          "workflowId.$": "$.state_data.workflowId",
          "segment_to_run.$": "$.state_data.segment_to_run",
          "idempotency_key.$": "$.state_data.idempotency_key",
          "quota_reservation_id.$": "$.state_data.quota_reservation_id",
          "total_segments.$": "$.state_data.total_segments",
          "partition_map.$": "$.state_data.partition_map",
          "partition_map_s3_path.$": "$.state_data.partition_map_s3_path",
          "max_concurrency.$": "$.state_data.max_concurrency",
          "state_durations.$": "$.state_data.state_durations",
          "last_update_time.$": "$.state_data.last_update_time",
          "start_time.$": "$.state_data.start_time"
        }
      },
      "ResultSelector": {
        "status.$": "$.Payload.status",
        "final_state.$": "$.Payload.final_state",
        "final_state_s3_path.$": "$.Payload.final_state_s3_path",
        "next_segment_to_run.$": "$.Payload.next_segment_to_run",
        "new_history_logs.$": "$.Payload.new_history_logs",
        "error_info.$": "$.Payload.error_info",
        "branches.$": "$.Payload.branches",
        "segment_type.$": "$.Payload.segment_type"
      },
      "ResultPath": "$.execution_result",
      "Retry": [
        {
          "ErrorEquals": [
            "Lambda.ServiceException",
            "Lambda.AWSLambdaException",
            "Lambda.SdkClientException",
            "Lambda.TooManyRequestsException"
          ],
          "IntervalSeconds": 5,
          "MaxAttempts": 6,
          "BackoffRate": 2.0,
          "JitterStrategy": "FULL",
          "Comment": "[Concurrency Protection] Lambda 429Ïóê ÎåÄÌïú Í∞ïÌôîÎêú Ïû¨ÏãúÎèÑ - ÎèôÏãúÏÑ± Ïä¨Î°Ø ÌöåÎ≥µ ÎåÄÍ∏∞"
        },
        {
          "ErrorEquals": [
            "States.TaskFailed"
          ],
          "IntervalSeconds": 2,
          "MaxAttempts": 3,
          "BackoffRate": 2.0,
          "Comment": "ÏùºÎ∞òÏ†ÅÏù∏ ÏûëÏóÖ Ïã§Ìå®Ïóê ÎåÄÌïú Ï†úÌïúÏ†Å Ïû¨ÏãúÎèÑ"
        }
      ],
      "Catch": [
        {
          "ErrorEquals": [
            "PartitionError"
          ],
          "ResultPath": "$.partition_error",
          "Next": "NotifyExecutionFailure"
        },
        {
          "ErrorEquals": [
            "AsyncLLMRequiredException"
          ],
          "ResultPath": "$.async_error",
          "Next": "CheckIfAsyncRequired"
        },
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "ResultPath": "$.execution_result.error_info",
          "Comment": "Catch all errors and preserve error details in execution_result structure for verifier",
          "Next": "NotifyExecutionFailure"
        }
      ],
      "Next": "CheckSegmentStatus"
    },
    "CheckSegmentStatus": {
      "Type": "Choice",
      "Comment": "Check execution status: CONTINUE, PARALLEL_GROUP, PAUSE, FAILED, HALTED, SIGKILL, or COMPLETE",
      "Choices": [
        {
          "Variable": "$.execution_result.status",
          "StringEquals": "FAILED",
          "Next": "NotifyExecutionFailure"
        },
        {
          "Variable": "$.execution_result.status",
          "StringEquals": "HALTED",
          "Comment": "üõ°Ô∏è [Kernel Defense] Concurrency controller halted execution",
          "Next": "NotifyExecutionFailure"
        },
        {
          "Variable": "$.execution_result.status",
          "StringEquals": "SIGKILL",
          "Comment": "üõ°Ô∏è [Kernel Defense] Ring protection violation - security termination",
          "Next": "NotifyExecutionFailure"
        },
        {
          "Variable": "$.execution_result.status",
          "StringEquals": "SKIPPED",
          "Comment": "Kernel decided to skip this segment",
          "Next": "PrepareNextSegment"
        },
        {
          "Variable": "$.execution_result.status",
          "StringEquals": "COMPLETE",
          "Next": "PublishSucceededEvent"
        },
        {
          "Variable": "$.execution_result.status",
          "StringEquals": "CONTINUE",
          "Comment": "More segments to process - continue the execution loop",
          "Next": "PrepareNextSegment"
        },
        {
          "Variable": "$.execution_result.status",
          "StringEquals": "PARALLEL_GROUP",
          "Next": "ProcessParallelSegments"
        },
        {
          "Variable": "$.execution_result.status",
          "StringEquals": "SEQUENTIAL_BRANCH",
          "Comment": "Single branch optimization: use inner_partition_map for sequential execution",
          "Next": "PrepareSequentialBranch"
        },
        {
          "Variable": "$.execution_result.status",
          "StringEquals": "PAUSED_FOR_ASYNC_LLM",
          "Next": "HandleAsyncLLM"
        },
        {
          "Variable": "$.execution_result.status",
          "StringEquals": "PAUSE",
          "Next": "WaitForCallback"
        },
        {
          "Variable": "$.execution_result.status",
          "StringEquals": "PAUSED_FOR_HITP",
          "Next": "WaitForCallback"
        }
      ],
      "Default": "PublishSucceededEvent"
    },
    "PrepareSequentialBranch": {
      "Type": "Pass",
      "Comment": "[SEQUENTIAL_BRANCH] Replace partition_map with inner_partition_map for sequential branch execution",
      "Parameters": {
        "state_data.$": "States.StringToJson(States.JsonToString($.state_data))",
        "execution_result.$": "$.execution_result"
      },
      "Next": "ExecuteSegment"
    },
    "ProcessParallelSegments": {
      "Type": "Map",
      "Comment": "Execute parallel branches inline using a Map state with dynamic concurrency",
      "ItemsPath": "$.execution_result.branches",
      "ResultPath": "$.parallel_results",
      "MaxConcurrencyPath": "$.state_data.max_concurrency",
      "Parameters": {
        "branch_config.$": "$$.Map.Item.Value",
        "branch_id.$": "States.Format('branch_{}', $$.Map.Item.Index)",
        "branch_index.$": "$$.Map.Item.Index",
        "partition_map.$": "$$.Map.Item.Value.partition_map",
        "partition_map_s3_path.$": "$.state_data.partition_map_s3_path",
        "segment_manifest.$": "$.state_data.segment_manifest",
        "segment_manifest_s3_path.$": "$.state_data.segment_manifest_s3_path",
        "workflow_config.$": "$.state_data.workflow_config",
        "current_state.$": "$.state_data.current_state",
        "ownerId.$": "$.state_data.ownerId",
        "workflowId.$": "$.state_data.workflowId",
        "idempotency_key.$": "$.state_data.idempotency_key",
        "quota_reservation_id.$": "$.state_data.quota_reservation_id",
        "state_history.$": "$.state_data.state_history",
        "state_durations.$": "$.state_data.state_durations",
        "last_update_time.$": "$.state_data.last_update_time",
        "start_time.$": "$.state_data.start_time",
        "max_loop_iterations.$": "$.state_data.max_loop_iterations",
        "max_branch_iterations.$": "$.state_data.max_branch_iterations",
        "max_concurrency.$": "$.state_data.max_concurrency",
        "distributed_mode.$": "$.state_data.distributed_mode",
        "llm_segments.$": "$.state_data.llm_segments",
        "hitp_segments.$": "$.state_data.hitp_segments"
      },
      "Iterator": {
        "StartAt": "InitializeBranch",
        "States": {
          "InitializeBranch": {
            "Type": "Pass",
            "Parameters": {
              "segment_to_run": 0,
              "branch_id.$": "$.branch_id",
              "branch_config.$": "$.branch_config",
              "partition_map.$": "$.partition_map",
              "partition_map_s3_path.$": "$.partition_map_s3_path",
              "segment_manifest.$": "$.segment_manifest",
              "segment_manifest_s3_path.$": "$.segment_manifest_s3_path",
              "workflow_config.$": "$.workflow_config",
              "current_state.$": "$.current_state",
              "ownerId.$": "$.ownerId",
              "workflowId.$": "$.workflowId",
              "idempotency_key.$": "$.idempotency_key",
              "quota_reservation_id.$": "$.quota_reservation_id",
              "state_history.$": "$.state_history",
              "state_durations.$": "$.state_durations",
              "last_update_time.$": "$.last_update_time",
              "start_time.$": "$.start_time",
              "loop_counter": 0,
              "max_loop_iterations.$": "$.max_loop_iterations",
              "max_branch_iterations.$": "$.max_branch_iterations",
              "max_concurrency.$": "$.max_concurrency",
              "distributed_mode.$": "$.distributed_mode",
              "llm_segments.$": "$.llm_segments",
              "hitp_segments.$": "$.hitp_segments"
            },
            "ResultPath": "$.state_data",
            "Next": "ExecuteBranchSegment"
          },
          "ExecuteBranchSegment": {
            "Type": "Task",
            "Resource": "arn:aws:states:::lambda:invoke",
            "Parameters": {
              "FunctionName": "${ExecuteSegmentArn}",
              "Payload": {
                "workflow_config.$": "$.state_data.workflow_config",
                "current_state.$": "$.state_data.current_state",
                "state_history.$": "$.state_data.state_history",
                "ownerId.$": "$.state_data.ownerId",
                "workflowId.$": "$.state_data.workflowId",
                "segment_to_run.$": "$.state_data.segment_to_run",
                "idempotency_key.$": "$.state_data.idempotency_key",
                "partition_map.$": "$.state_data.partition_map",
                "branch_config.$": "$.state_data.branch_config",
                "state_durations.$": "$.state_data.state_durations",
                "last_update_time.$": "$.state_data.last_update_time",
                "start_time.$": "$.state_data.start_time"
              }
            },
            "ResultSelector": {
              "status.$": "$.Payload.status",
              "final_state.$": "$.Payload.final_state",
              "final_state_s3_path.$": "$.Payload.final_state_s3_path",
              "next_segment_to_run.$": "$.Payload.next_segment_to_run",
              "new_history_logs.$": "$.Payload.new_history_logs",
              "error_info.$": "$.Payload.error_info",
              "branches.$": "$.Payload.branches",
              "segment_type.$": "$.Payload.segment_type",
              "inner_partition_map.$": "$.Payload.inner_partition_map"
            },
            "ResultPath": "$.execution_result",
            "Retry": [
              {
                "ErrorEquals": [
                  "Lambda.ServiceException",
                  "Lambda.TooManyRequestsException",
                  "Lambda.Unknown"
                ],
                "IntervalSeconds": 2,
                "MaxAttempts": 3,
                "BackoffRate": 2
              }
            ],
            "Catch": [
              {
                "ErrorEquals": [
                  "States.ALL"
                ],
                "ResultPath": "$.branch_error",
                "Next": "HandleBranchError"
              }
            ],
            "Next": "CheckBranchNext"
          },
          "HandleBranchError": {
            "Type": "Pass",
            "Comment": "üõ°Ô∏è [Kernel Defense] Lambda ÏòàÏô∏ ÏóêÎü¨Î•º Partial SuccessÎ°ú Î≥ÄÌôò",
            "Parameters": {
              "status": "PARTIAL_FAILURE",
              "final_state.$": "$.state_data.current_state",
              "final_state_s3_path": null,
              "next_segment_to_run": null,
              "new_history_logs": [],
              "error_info": {
                "error.$": "$.branch_error.Error",
                "cause.$": "$.branch_error.Cause",
                "branch_id.$": "$.state_data.branch_id",
                "segment_to_run.$": "$.state_data.segment_to_run"
              }
            },
            "ResultPath": "$.execution_result",
            "Next": "BranchComplete"
          },
          "HandleBranchFailedStatus": {
            "Type": "Pass",
            "Comment": "üõ°Ô∏è [Kernel Defense] Lambda FAILED ÏÉÅÌÉú Î∞òÌôòÏùÑ Ï≤òÎ¶¨",
            "Parameters": {
              "status": "PARTIAL_FAILURE",
              "final_state.$": "$.execution_result.final_state",
              "final_state_s3_path.$": "$.execution_result.final_state_s3_path",
              "next_segment_to_run": null,
              "new_history_logs.$": "$.execution_result.new_history_logs",
              "error_info.$": "$.execution_result.error_info"
            },
            "ResultPath": "$.execution_result",
            "Next": "BranchComplete"
          },
          "CheckBranchNext": {
            "Type": "Choice",
            "Comment": "Check if branch should continue or complete",
            "Choices": [
              {
                "Variable": "$.execution_result.status",
                "StringEquals": "COMPLETE",
                "Next": "BranchComplete"
              },
              {
                "Variable": "$.execution_result.status",
                "StringEquals": "FAILED",
                "Comment": "Branch execution failed - handle status",
                "Next": "HandleBranchFailedStatus"
              },
              {
                "Variable": "$.execution_result.status",
                "StringEquals": "CONTINUE",
                "Comment": "More segments in branch - continue execution",
                "Next": "UpdateBranchSegment"
              },
              {
                "Variable": "$.execution_result.status",
                "StringEquals": "SEQUENTIAL_BRANCH",
                "Comment": "Sequential branch - switch to inner_partition_map",
                "Next": "UpdateBranchToSequential"
              },
              {
                "Variable": "$.execution_result.status",
                "StringEquals": "PARALLEL_GROUP",
                "Comment": "Nested parallel group in branch - handle as continue",
                "Next": "UpdateBranchSegment"
              },
              {
                "Variable": "$.execution_result.status",
                "StringEquals": "HALTED",
                "Comment": "Branch halted by kernel",
                "Next": "HandleBranchFailedStatus"
              },
              {
                "Variable": "$.execution_result.status",
                "StringEquals": "SIGKILL",
                "Comment": "Branch security violation",
                "Next": "HandleBranchFailedStatus"
              }
            ],
            "Default": "BranchComplete"
          },
          "UpdateBranchSegment": {
            "Type": "Pass",
            "Parameters": {
              "workflow_config.$": "$.state_data.workflow_config",
              "current_state.$": "$.execution_result.final_state",
              "state_history.$": "$.state_data.state_history",
              "ownerId.$": "$.state_data.ownerId",
              "workflowId.$": "$.state_data.workflowId",
              "segment_to_run.$": "$.execution_result.next_segment_to_run",
              "idempotency_key.$": "$.state_data.idempotency_key",
              "quota_reservation_id.$": "$.state_data.quota_reservation_id",
              "partition_map.$": "$.state_data.partition_map",
              "branch_config.$": "$.state_data.branch_config",
              "partition_map_s3_path.$": "$.state_data.partition_map_s3_path",
              "segment_manifest.$": "$.state_data.segment_manifest",
              "segment_manifest_s3_path.$": "$.state_data.segment_manifest_s3_path",
              "state_durations.$": "$.state_data.state_durations",
              "last_update_time.$": "$.state_data.last_update_time",
              "start_time.$": "$.state_data.start_time",
              "loop_counter.$": "States.MathAdd($.state_data.loop_counter, 1)",
              "max_loop_iterations.$": "$.state_data.max_loop_iterations",
              "max_branch_iterations.$": "$.state_data.max_branch_iterations",
              "max_concurrency.$": "$.state_data.max_concurrency",
              "distributed_mode.$": "$.state_data.distributed_mode",
              "llm_segments.$": "$.state_data.llm_segments",
              "hitp_segments.$": "$.state_data.hitp_segments"
            },
            "ResultPath": "$.state_data",
            "Next": "CheckBranchLoopLimit"
          },
          "UpdateBranchToSequential": {
            "Type": "Pass",
            "Comment": "[SEQUENTIAL_BRANCH] Replace partition_map with inner_partition_map in branch context",
            "Parameters": {
              "workflow_config.$": "$.state_data.workflow_config",
              "current_state.$": "$.execution_result.final_state",
              "state_history.$": "$.state_data.state_history",
              "ownerId.$": "$.state_data.ownerId",
              "workflowId.$": "$.state_data.workflowId",
              "segment_to_run": 0,
              "idempotency_key.$": "$.state_data.idempotency_key",
              "quota_reservation_id.$": "$.state_data.quota_reservation_id",
              "partition_map.$": "$.execution_result.inner_partition_map",
              "branch_config.$": "$.state_data.branch_config",
              "partition_map_s3_path": "",
              "segment_manifest.$": "$.state_data.segment_manifest",
              "segment_manifest_s3_path.$": "$.state_data.segment_manifest_s3_path",
              "state_durations.$": "$.state_data.state_durations",
              "last_update_time.$": "$.state_data.last_update_time",
              "start_time.$": "$.state_data.start_time",
              "loop_counter.$": "$.state_data.loop_counter",
              "max_loop_iterations.$": "$.state_data.max_loop_iterations",
              "max_branch_iterations.$": "$.state_data.max_branch_iterations",
              "max_concurrency.$": "$.state_data.max_concurrency",
              "distributed_mode.$": "$.state_data.distributed_mode",
              "llm_segments.$": "$.state_data.llm_segments",
              "hitp_segments.$": "$.state_data.hitp_segments",
              "sequential_branch_id.$": "$.execution_result.branch_id"
            },
            "ResultPath": "$.state_data",
            "Next": "ExecuteBranchSegment"
          },
          "CheckBranchLoopLimit": {
            "Type": "Choice",
            "Comment": "Dynamic branch loop limit based on workflow complexity",
            "Choices": [
              {
                "Variable": "$.state_data.loop_counter",
                "NumericGreaterThanPath": "$.state_data.max_branch_iterations",
                "Next": "BranchLoopLimitExceeded"
              }
            ],
            "Default": "ExecuteBranchSegment"
          },
          "BranchLoopLimitExceeded": {
            "Type": "Fail",
            "Error": "BranchLoopLimitExceeded",
            "Cause": "Parallel branch exceeded maximum loop iterations."
          },
          "BranchComplete": {
            "Type": "Pass",
            "Comment": "[Fix] Î∏åÎûúÏπò Í≤∞Í≥ºÏóê ÏÉÅÌÉú Î∞è ÏóêÎü¨ Ï†ïÎ≥¥ Ìè¨Ìï®",
            "Parameters": {
              "branch_id.$": "$.state_data.branch_id",
              "branch_status.$": "$.execution_result.status",
              "final_state.$": "$.execution_result.final_state",
              "final_state_s3_path.$": "$.execution_result.final_state_s3_path",
              "new_history_logs.$": "$.execution_result.new_history_logs",
              "error_info.$": "$.execution_result.error_info",
              "branch_executed": true
            },
            "End": true
          }
        }
      },
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Comment": "üõ°Ô∏è [Kernel Defense] Map ÏóêÎü¨ Ïãú Î∂ÄÎ∂Ñ Í≤∞Í≥ºÎ°ú Aggregator ÏßÑÌñâ",
          "ResultPath": "$.map_error",
          "Next": "HandleMapError"
        }
      ],
      "Next": "AggregateParallelResults"
    },
    "HandleMapError": {
      "Type": "Pass",
      "Comment": "üõ°Ô∏è [Kernel Defense] Map Ï†ÑÏ≤¥ Ïã§Ìå® Ïãú Îπà Í≤∞Í≥ºÎ°ú Aggregator Ìò∏Ï∂ú",
      "Parameters": {
        "status": "MAP_ERROR",
        "error_info": {
          "error.$": "$.map_error.Error",
          "cause.$": "$.map_error.Cause"
        },
        "parallel_results": []
      },
      "ResultPath": "$.parallel_results_wrapper",
      "Next": "AggregateParallelResultsFromError"
    },
    "AggregateParallelResultsFromError": {
      "Type": "Task",
      "Resource": "arn:aws:states:::lambda:invoke",
      "Comment": "üõ°Ô∏è [Kernel Defense] Map ÏóêÎü¨ ÌõÑ Î∂ÄÎ∂Ñ Í≤∞Í≥º ÏßëÍ≥Ñ",
      "Parameters": {
        "FunctionName": "${SegmentRunnerArn}",
        "InvocationType": "RequestResponse",
        "Payload": {
          "segment_type": "aggregator",
          "parallel_results.$": "$.parallel_results_wrapper.parallel_results",
          "map_error.$": "$.parallel_results_wrapper.error_info",
          "workflow_config.$": "$.state_data.workflow_config",
          "current_state.$": "$.state_data.current_state",
          "ownerId.$": "$.state_data.ownerId",
          "workflowId.$": "$.state_data.workflowId",
          "segment_to_run.$": "$.state_data.segment_to_run",
          "idempotency_key.$": "$.state_data.idempotency_key"
        }
      },
      "ResultSelector": {
        "status.$": "$.Payload.status",
        "final_state.$": "$.Payload.final_state",
        "final_state_s3_path.$": "$.Payload.final_state_s3_path",
        "next_segment_to_run.$": "$.Payload.next_segment_to_run",
        "new_history_logs.$": "$.Payload.new_history_logs"
      },
      "ResultPath": "$.execution_result",
      "Next": "EnsureExecutionResult"
    },
    "EnsureExecutionResult": {
      "Type": "Pass",
      "Comment": "üõ°Ô∏è [Infrastructure Guard] Ensure execution_result structure exists to prevent 'Invalid Path' errors in subsequent choices",
      "Parameters": {
        "status": "FAILED",
        "final_state.$": "$.state_data.current_state",
        "next_segment_to_run": null,
        "new_history_logs": [],
        "error_info": {
          "error": "ExecutionResultMissing",
          "message": "Aggregator failed to return a valid execution_result"
        }
      },
      "ResultPath": "$.execution_result_default",
      "Next": "MergeExecutionResult"
    },
    "MergeExecutionResult": {
      "Type": "Pass",
      "Comment": "Merge default execution_result with actual result if present",
      "Parameters": {
        "execution_result.$": "States.JsonMerge($.execution_result_default, $.execution_result, false)"
      },
      "ResultPath": "$.execution_result_wrapper",
      "Next": "CleanupMergedState"
    },
    "CleanupMergedState": {
      "Type": "Pass",
      "Comment": "üõ°Ô∏è [Payload Safety] Remove parallel_results and debris, keeping only state_data and execution_result. Flatten critical metadata to root.",
      "Parameters": {
        "state_data.$": "$.state_data",
        "execution_result.$": "$.execution_result_wrapper.execution_result",
        "ownerId.$": "$.state_data.ownerId",
        "workflowId.$": "$.state_data.workflowId",
        "idempotency_key.$": "$.state_data.idempotency_key"
      },
      "Next": "UpdateStateData"
    },
    "AggregateParallelResults": {
      "Type": "Task",
      "Resource": "arn:aws:states:::lambda:invoke",
      "Comment": "Aggregate results from parallel branches.",
      "Parameters": {
        "FunctionName": "${SegmentRunnerArn}",
        "InvocationType": "RequestResponse",
        "Payload": {
          "segment_type": "aggregator",
          "parallel_results.$": "$.parallel_results",
          "workflow_config.$": "$.state_data.workflow_config",
          "current_state.$": "$.state_data.current_state",
          "ownerId.$": "$.state_data.ownerId",
          "workflowId.$": "$.state_data.workflowId",
          "segment_to_run.$": "$.state_data.segment_to_run",
          "idempotency_key.$": "$.state_data.idempotency_key"
        }
      },
      "ResultSelector": {
        "status.$": "$.Payload.status",
        "final_state.$": "$.Payload.final_state",
        "final_state_s3_path.$": "$.Payload.final_state_s3_path",
        "next_segment_to_run.$": "$.Payload.next_segment_to_run",
        "new_history_logs.$": "$.Payload.new_history_logs"
      },
      "ResultPath": "$.execution_result",
      "Next": "EnsureExecutionResult"
    },
    "UpdateStateData": {
      "Type": "Task",
      "Resource": "arn:aws:states:::lambda:invoke",
      "Comment": "Update state_data with payload size management and S3 offloading for large states",
      "Parameters": {
        "FunctionName": "${StateDataManagerArn}",
        "InvocationType": "RequestResponse",
        "Payload": {
          "action": "update_and_compress",
          "state_data.$": "$.state_data",
          "execution_result.$": "$.execution_result",
          "max_payload_size_kb": 200
        }
      },
      "ResultSelector": {
        "workflow_config.$": "$.Payload.workflow_config",
        "current_state.$": "$.Payload.current_state",
        "state_s3_path.$": "$.Payload.state_s3_path",
        "state_history.$": "$.Payload.state_history",
        "ownerId.$": "$.Payload.ownerId",
        "workflowId.$": "$.Payload.workflowId",
        "segment_to_run.$": "$.Payload.segment_to_run",
        "idempotency_key.$": "$.Payload.idempotency_key",
        "quota_reservation_id.$": "$.Payload.quota_reservation_id",
        "total_segments.$": "$.Payload.total_segments",
        "partition_map.$": "$.Payload.partition_map",
        "partition_map_s3_path.$": "$.Payload.partition_map_s3_path",
        "segment_manifest.$": "$.Payload.segment_manifest",
        "segment_manifest_s3_path.$": "$.Payload.segment_manifest_s3_path",
        "state_durations.$": "$.Payload.state_durations",
        "last_update_time.$": "$.Payload.last_update_time",
        "start_time.$": "$.Payload.start_time",
        "max_loop_iterations.$": "$.Payload.max_loop_iterations",
        "max_branch_iterations.$": "$.Payload.max_branch_iterations",
        "loop_counter.$": "$.Payload.loop_counter",
        "payload_size_kb.$": "$.Payload.payload_size_kb",
        "compression_applied.$": "$.Payload.compression_applied",
        "llm_segments.$": "$.Payload.llm_segments",
        "hitp_segments.$": "$.Payload.hitp_segments",
        "max_concurrency.$": "$.Payload.max_concurrency",
        "distributed_mode.$": "$.Payload.distributed_mode"
      },
      "ResultPath": "$.state_data",
      "Retry": [
        {
          "ErrorEquals": [
            "Lambda.ServiceException",
            "Lambda.AWSLambdaException",
            "Lambda.SdkClientException",
            "Lambda.TooManyRequestsException"
          ],
          "IntervalSeconds": 5,
          "MaxAttempts": 6,
          "BackoffRate": 2.0,
          "JitterStrategy": "FULL",
          "Comment": "[Concurrency Protection] Lambda 429Ïóê ÎåÄÌïú Í∞ïÌôîÎêú Ïû¨ÏãúÎèÑ - ÎèôÏãúÏÑ± Ïä¨Î°Ø ÌöåÎ≥µ ÎåÄÍ∏∞"
        },
        {
          "ErrorEquals": [
            "S3.ServiceException",
            "S3.ThrottlingException"
          ],
          "IntervalSeconds": 2,
          "MaxAttempts": 4,
          "BackoffRate": 2.0,
          "Comment": "S3 Ïä§Î°úÌãÄÎßÅ Î∞è ÏÑúÎπÑÏä§ Ïò§Î•òÏóê ÎåÄÌïú Ïû¨ÏãúÎèÑ"
        }
      ],
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Comment": "State compression failure - fallback to original Pass logic",
          "ResultPath": "$.compression_error",
          "Next": "UpdateStateDataFallback"
        }
      ],
      "Next": "IsPauseNeeded"
    },
    "UpdateStateDataFallback": {
      "Type": "Pass",
      "Comment": "Fallback state update when compression fails",
      "Parameters": {
        "workflow_config.$": "$.state_data.workflow_config",
        "current_state.$": "$.execution_result.final_state",
        "state_s3_path.$": "$.execution_result.final_state_s3_path",
        "state_history.$": "$.execution_result.new_history_logs",
        "ownerId.$": "$.state_data.ownerId",
        "workflowId.$": "$.state_data.workflowId",
        "segment_to_run.$": "$.state_data.segment_to_run",
        "idempotency_key.$": "$.state_data.idempotency_key",
        "quota_reservation_id.$": "$.state_data.quota_reservation_id",
        "total_segments.$": "$.state_data.total_segments",
        "partition_map.$": "$.state_data.partition_map",
        "partition_map_s3_path.$": "$.state_data.partition_map_s3_path",
        "segment_manifest.$": "$.state_data.segment_manifest",
        "segment_manifest_s3_path.$": "$.state_data.segment_manifest_s3_path",
        "max_concurrency.$": "$.state_data.max_concurrency",
        "distributed_mode.$": "$.state_data.distributed_mode",
        "state_durations.$": "$.state_data.state_durations",
        "last_update_time.$": "$.state_data.last_update_time",
        "start_time.$": "$.state_data.start_time",
        "max_loop_iterations.$": "$.state_data.max_loop_iterations",
        "max_branch_iterations.$": "$.state_data.max_branch_iterations",
        "loop_counter.$": "$.state_data.loop_counter",
        "llm_segments.$": "$.state_data.llm_segments",
        "hitp_segments.$": "$.state_data.hitp_segments"
      },
      "ResultPath": "$.state_data",
      "Next": "IsPauseNeeded"
    },
    "IsPauseNeeded": {
      "Type": "Choice",
      "Comment": "Check if the segment execution resulted in a PAUSE or PAUSED_FOR_HITP status",
      "Choices": [
        {
          "Variable": "$.execution_result.status",
          "StringEquals": "PAUSE",
          "Next": "WaitForCallback"
        },
        {
          "Variable": "$.execution_result.status",
          "StringEquals": "PAUSED_FOR_HITP",
          "Next": "WaitForCallback"
        }
      ],
      "Default": "CheckForNextSegment"
    },
    "CheckForNextSegment": {
      "Type": "Choice",
      "Comment": "Check if there is a next segment to run, or if workflow is complete. Default safely terminates.",
      "Choices": [
        {
          "And": [
            {
              "Variable": "$.execution_result.status",
              "StringEquals": "COMPLETE"
            },
            {
              "Variable": "$.execution_result.next_segment_to_run",
              "IsNull": true
            }
          ],
          "Next": "PublishSucceededEvent"
        },
        {
          "And": [
            {
              "Variable": "$.execution_result.status",
              "StringEquals": "COMPLETE"
            },
            {
              "Not": {
                "Variable": "$.execution_result.next_segment_to_run",
                "IsPresent": true
              }
            }
          ],
          "Next": "PublishSucceededEvent"
        },
        {
          "Variable": "$.execution_result.status",
          "StringEquals": "CONTINUE",
          "Comment": "Explicit CONTINUE status - continue to next segment",
          "Next": "PrepareNextSegment"
        }
      ],
      "Default": "PublishSucceededEvent"
    },
    "WaitForCallback": {
      "Type": "Task",
      "Resource": "arn:aws:states:::lambda:invoke.waitForTaskToken",
      "Comment": "HITP: TaskToken Ï†ÄÏû• ‚Üí ÏïåÎ¶º Ï†ÑÏÜ° ‚Üí Ïô∏Î∂Ä resume ÎåÄÍ∏∞",
      "Parameters": {
        "FunctionName": "${StoreTaskTokenArn}",
        "Payload": {
          "TaskToken.$": "$$.Task.Token",
          "conversation_id.$": "$$.Execution.Id",
          "execution_id.$": "$$.Execution.Id",
          "execution_name.$": "$$.Execution.Name",
          "idempotency_key.$": "$.state_data.idempotency_key",
          "workflow_config.$": "$.state_data.workflow_config",
          "current_state.$": "$.execution_result.final_state",
          "state_s3_path.$": "$.execution_result.final_state_s3_path",
          "segment_to_run.$": "$.execution_result.next_segment_to_run",
          "partition_map.$": "$.state_data.partition_map",
          "total_segments.$": "$.state_data.total_segments",
          "ownerId.$": "$.state_data.ownerId",
          "workflowId.$": "$.state_data.workflowId",
          "state_data.$": "$.state_data",
          "MOCK_MODE.$": "$.MOCK_MODE"
        }
      },
      "ResultPath": "$.callback_result",
      "Next": "PrepareStateAfterPause"
    },
    "PrepareStateAfterPause": {
      "Type": "Task",
      "Comment": "[3ÏàúÏúÑ ÏµúÏ†ÅÌôî] Callback Ï†ïÍ∑úÌôî Î°úÏßÅÏùÑ Lambda ÎÇ¥Î∂ÄÎ°ú Ìù°Ïàò. NormalizeCallbackResult, PromoteCallbackPayload/Direct Ï†úÍ±∞.",
      "Resource": "arn:aws:states:::lambda:invoke",
      "Parameters": {
        "FunctionName": "${MergeCallbackArn}",
        "InvocationType": "RequestResponse",
        "Payload": {
          "previous_final_state.$": "$.execution_result.final_state",
          "previous_final_state_s3_path.$": "$.execution_result.final_state_s3_path",
          "callback_result.$": "$.callback_result",
          "state_data.$": "$.state_data",
          "segment_to_run.$": "$.execution_result.next_segment_to_run",
          "ownerId.$": "$.state_data.ownerId",
          "workflowId.$": "$.state_data.workflowId"
        }
      },
      "ResultSelector": {
        "new_current_state.$": "$.Payload.new_current_state",
        "new_state_s3_path.$": "$.Payload.new_state_s3_path",
        "new_state_history.$": "$.Payload.new_state_history",
        "segment_to_run.$": "$.Payload.segment_to_run",
        "workflow_config.$": "$.Payload.workflow_config"
      },
      "ResultPath": "$.current_state_merge",
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Next": "NotifyExecutionFailure"
        }
      ],
      "Next": "ApplyMergedState"
    },
    "ApplyMergedState": {
      "Type": "Pass",
      "Comment": "Transfer merged new_current_state into state_data.current_state and set segment_to_run",
      "Parameters": {
        "workflow_config.$": "$.state_data.workflow_config",
        "current_state.$": "$.current_state_merge.new_current_state",
        "state_history.$": "$.current_state_merge.new_state_history",
        "state_s3_path.$": "$.current_state_merge.new_state_s3_path",
        "segment_to_run.$": "$.current_state_merge.segment_to_run",
        "partition_map.$": "$.state_data.partition_map",
        "partition_map_s3_path.$": "$.state_data.partition_map_s3_path",
        "segment_manifest.$": "$.state_data.segment_manifest",
        "segment_manifest_s3_path.$": "$.state_data.segment_manifest_s3_path",
        "total_segments.$": "$.state_data.total_segments",
        "ownerId.$": "$.state_data.ownerId",
        "workflowId.$": "$.state_data.workflowId",
        "idempotency_key.$": "$.state_data.idempotency_key",
        "quota_reservation_id.$": "$.state_data.quota_reservation_id",
        "max_concurrency.$": "$.state_data.max_concurrency",
        "distributed_mode.$": "$.state_data.distributed_mode",
        "state_durations.$": "$.state_data.state_durations",
        "last_update_time.$": "$.state_data.last_update_time",
        "start_time.$": "$.state_data.start_time",
        "max_loop_iterations.$": "$.state_data.max_loop_iterations",
        "max_branch_iterations.$": "$.state_data.max_branch_iterations",
        "loop_counter.$": "$.state_data.loop_counter",
        "llm_segments.$": "$.state_data.llm_segments",
        "hitp_segments.$": "$.state_data.hitp_segments"
      },
      "ResultPath": "$.state_data",
      "Next": "ExecuteSegment"
    },
    "CheckIfAsyncRequired": {
      "Type": "Choice",
      "Comment": "Check if error type is AsyncLLMRequiredException",
      "Choices": [
        {
          "Variable": "$.async_error.Error",
          "StringEquals": "AsyncLLMRequiredException",
          "Next": "NotifyAsyncLLMProcessing"
        }
      ],
      "Default": "NotifyExecutionFailure"
    },
    "NotifyAsyncLLMProcessing": {
      "Type": "Task",
      "Resource": "arn:aws:states:::events:putEvents",
      "Comment": "üõ°Ô∏è [UX] ÎπÑÎèôÍ∏∞ LLM Ï≤òÎ¶¨ Ï§ë ÏïåÎ¶º - ÏÇ¨Ïö©ÏûêÏóêÍ≤å Ï§ëÎã®Îêú Í≤ÉÏ≤òÎüº Î≥¥Ïù¥ÏßÄ ÏïäÎèÑÎ°ù",
      "Parameters": {
        "Entries": [
          {
            "EventBusName": "${WorkflowEventBusArn}",
            "Source": "backend-workflow.lifecycle",
            "DetailType": "WorkflowLifecycleEvent",
            "Detail": {
              "execution_id.$": "$$.Execution.Id",
              "ownerId.$": "$.state_data.ownerId",
              "workflowId.$": "$.state_data.workflowId",
              "segment_to_run.$": "$.state_data.segment_to_run",
              "notification_type": "execution_progress",
              "status": "ASYNC_LLM_PROCESSING",
              "message": "Large language model is processing asynchronously. This may take several minutes."
            }
          }
        ]
      },
      "ResultPath": "$.async_notification_result",
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Comment": "Notification failure should not block async processing",
          "ResultPath": "$.async_notification_error",
          "Next": "HandleAsyncLLM"
        }
      ],
      "Next": "HandleAsyncLLM"
    },
    "HandleAsyncLLM": {
      "Type": "Task",
      "Resource": "arn:aws:states:::lambda:invoke.waitForTaskToken",
      "Comment": "ÎπÑÎèôÍ∏∞ LLM Ï≤òÎ¶¨Î•º ÏúÑÌï¥ Task TokenÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ ÎåÄÍ∏∞",
      "Parameters": {
        "FunctionName": "${AsyncLLMHandlerArn}",
        "InvocationType": "RequestResponse",
        "Payload": {
          "TaskToken.$": "$$.Task.Token",
          "execution_id.$": "$$.Execution.Id",
          "idempotency_key.$": "$.state_data.idempotency_key",
          "workflow_config.$": "$.state_data.workflow_config",
          "current_state.$": "$.state_data.current_state",
          "ownerId.$": "$.state_data.ownerId",
          "segment_to_run.$": "$.state_data.segment_to_run",
          "workflowId.$": "$.state_data.workflowId"
        }
      },
      "ResultPath": "$.async_result",
      "Next": "ProcessAsyncResult"
    },
    "ProcessAsyncResult": {
      "Type": "Pass",
      "Comment": "ÎπÑÎèôÍ∏∞ LLM Í≤∞Í≥ºÎ•º Ï≤òÎ¶¨ÌïòÍ≥† Îã§Ïùå ÏÑ∏Í∑∏Î®ºÌä∏Î°ú ÏßÑÌñâ. Resume Handler ÏùëÎãµÏóê ÎåÄÌïú Î∞©Ïñ¥Ï†Å Ï≤òÎ¶¨ Ìè¨Ìï®.",
      "Parameters": {
        "workflow_config.$": "$.state_data.workflow_config",
        "current_state.$": "States.JsonMerge($.state_data.current_state, $.async_result.Payload, false)",
        "state_s3_path.$": "$.state_data.state_s3_path",
        "partition_map.$": "$.state_data.partition_map",
        "partition_map_s3_path.$": "$.state_data.partition_map_s3_path",
        "segment_manifest.$": "$.state_data.segment_manifest",
        "segment_manifest_s3_path.$": "$.state_data.segment_manifest_s3_path",
        "total_segments.$": "$.state_data.total_segments",
        "ownerId.$": "$.state_data.ownerId",
        "segment_to_run.$": "States.MathAdd($.state_data.segment_to_run, 1)",
        "idempotency_key.$": "$.state_data.idempotency_key",
        "quota_reservation_id.$": "$.state_data.quota_reservation_id",
        "workflowId.$": "$.state_data.workflowId",
        "max_concurrency.$": "$.state_data.max_concurrency",
        "distributed_mode.$": "$.state_data.distributed_mode",
        "state_durations.$": "$.state_data.state_durations",
        "last_update_time.$": "$.state_data.last_update_time",
        "start_time.$": "$.state_data.start_time",
        "max_loop_iterations.$": "$.state_data.max_loop_iterations",
        "max_branch_iterations.$": "$.state_data.max_branch_iterations",
        "loop_counter.$": "$.state_data.loop_counter",
        "llm_segments.$": "$.state_data.llm_segments",
        "hitp_segments.$": "$.state_data.hitp_segments"
      },
      "ResultPath": "$.state_data",
      "Next": "CheckLoopLimit"
    },
    "PrepareNextSegment": {
      "Type": "Choice",
      "Comment": "Check if there is a next segment to run (must be a valid number), or if workflow is complete",
      "Choices": [
        {
          "Variable": "$.execution_result.next_segment_to_run",
          "IsNumeric": true,
          "Comment": "next_segment_to_run is a valid number - continue to next segment",
          "Next": "UpdateSegmentToRun"
        }
      ],
      "Default": "PublishSucceededEvent"
    },
    "UpdateSegmentToRun": {
      "Type": "Pass",
      "Comment": "Advance to the next segment when ExecuteSegment signalled CONTINUE, and increment loop counter",
      "Parameters": {
        "workflow_config.$": "$.state_data.workflow_config",
        "current_state.$": "$.execution_result.final_state",
        "state_s3_path.$": "$.execution_result.final_state_s3_path",
        "partition_map.$": "$.state_data.partition_map",
        "partition_map_s3_path.$": "$.state_data.partition_map_s3_path",
        "segment_manifest.$": "$.state_data.segment_manifest",
        "segment_manifest_s3_path.$": "$.state_data.segment_manifest_s3_path",
        "total_segments.$": "$.state_data.total_segments",
        "ownerId.$": "$.state_data.ownerId",
        "segment_to_run.$": "$.execution_result.next_segment_to_run",
        "idempotency_key.$": "$.state_data.idempotency_key",
        "quota_reservation_id.$": "$.state_data.quota_reservation_id",
        "workflowId.$": "$.state_data.workflowId",
        "max_concurrency.$": "$.state_data.max_concurrency",
        "distributed_mode.$": "$.state_data.distributed_mode",
        "state_durations.$": "$.state_data.state_durations",
        "last_update_time.$": "$.state_data.last_update_time",
        "start_time.$": "$.state_data.start_time",
        "state_history.$": "$.state_data.state_history",
        "max_loop_iterations.$": "$.state_data.max_loop_iterations",
        "max_branch_iterations.$": "$.state_data.max_branch_iterations",
        "loop_counter.$": "States.MathAdd($.state_data.loop_counter, 1)",
        "llm_segments.$": "$.state_data.llm_segments",
        "hitp_segments.$": "$.state_data.hitp_segments"
      },
      "ResultPath": "$.state_data",
      "Next": "CheckLoopLimit"
    },
    "CheckLoopLimit": {
      "Type": "Choice",
      "Comment": "Safety valve: Check loop counter to prevent infinite loops (dynamic limit based on workflow complexity)",
      "Choices": [
        {
          "Variable": "$.state_data.loop_counter",
          "NumericGreaterThanPath": "$.state_data.max_loop_iterations",
          "Next": "LoopLimitExceeded"
        }
      ],
      "Default": "ExecuteSegment"
    },
    "LoopLimitExceeded": {
      "Type": "Fail",
      "Error": "LoopLimitExceeded",
      "CausePath": "States.Format('Workflow execution exceeded maximum loop iterations ({}). Possible infinite loop detected. Current: {}, Max: {}', $.state_data.max_loop_iterations, $.state_data.loop_counter, $.state_data.max_loop_iterations)"
    },
    "PublishSucceededEvent": {
      "Type": "Task",
      "Resource": "arn:aws:states:::events:putEvents",
      "Comment": "Publish a domain event to EventBridge indicating the workflow succeeded",
      "Parameters": {
        "Entries": [
          {
            "EventBusName": "${WorkflowEventBusArn}",
            "Source": "backend-workflow.lifecycle",
            "DetailType": "WorkflowLifecycleEvent",
            "Detail": {
              "execution_id.$": "$$.Execution.Id",
              "conversation_id.$": "$$.Execution.Id",
              "ownerId.$": "$.state_data.ownerId",
              "workflowId.$": "$.state_data.workflowId",
              "status": "COMPLETED",
              "notification_type": "execution_progress",
              "message": "Workflow completed successfully",
              "state_data.$": "$",
              "final_result.$": "$.state_data.current_state"
            }
          }
        ]
      },
      "ResultPath": "$.event_publish_result",
      "Next": "PrepareSuccessOutput"
    },
    "PrepareSuccessOutput": {
      "Type": "Pass",
      "Comment": "[Fix] ÏµúÏ¢Ö Ï∂úÎ†•Ïóê execution_result Î∞è Í∞ÄÎìúÎ†àÏùº Î©îÌä∏Î¶≠ Ìè¨Ìï®",
      "Parameters": {
        "status": "SUCCEEDED",
        "execution_id.$": "$$.Execution.Id",
        "ownerId.$": "$.state_data.ownerId",
        "workflowId.$": "$.state_data.workflowId",
        "final_state.$": "$.execution_result.final_state",
        "final_state_s3_path.$": "$.execution_result.final_state_s3_path",
        "state_s3_path.$": "$.execution_result.final_state_s3_path",
        "execution_result.$": "$.execution_result",
        "loop_counter.$": "$.state_data.loop_counter",
        "max_loop_iterations.$": "$.state_data.max_loop_iterations",
        "llm_segments.$": "$.state_data.llm_segments",
        "hitp_segments.$": "$.state_data.hitp_segments",
        "start_time.$": "$.state_data.start_time",
        "state_durations.$": "$.state_data.state_durations",
        "total_segments.$": "$.state_data.total_segments"
      },
      "Next": "NotifyExecutionSuccess"
    },
    "NotifyExecutionSuccess": {
      "Type": "Task",
      "Resource": "arn:aws:states:::events:putEvents",
      "Comment": "Publish workflow success event to trigger ExecutionProgressNotifierFunction",
      "Parameters": {
        "Entries": [
          {
            "EventBusName": "${WorkflowEventBusArn}",
            "Source": "backend-workflow",
            "DetailType": "WorkflowExecutionSucceeded",
            "Detail": {
              "execution_id.$": "$$.Execution.Id",
              "conversation_id.$": "$$.Execution.Id",
              "ownerId.$": "$.ownerId",
              "workflowId.$": "$.workflowId",
              "status": "SUCCEEDED",
              "notification_type": "execution_progress",
              "message": "Workflow execution completed successfully",
              "final_state.$": "$.final_state",
              "final_state_s3_path.$": "$.final_state_s3_path",
              "total_segments.$": "$.total_segments",
              "start_time.$": "$.start_time"
            }
          }
        ]
      },
      "ResultPath": "$.success_notification_result",
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Comment": "EventBridge publish failure should not stop workflow success",
          "ResultPath": "$.success_notification_error",
          "Next": "WorkflowSucceeded"
        }
      ],
      "Next": "WorkflowSucceeded"
    },
    "WorkflowSucceeded": {
      "Type": "Succeed",
      "Comment": "ÏõåÌÅ¨ÌîåÎ°úÏö∞Í∞Ä ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§. - ÏµúÏ¢Ö Ï∂úÎ†•Ïóê S3 Í≤ΩÎ°ú Ìè¨Ìï®"
    },
    "NotifyWorkflowCompleted": {
      "Type": "Task",
      "Resource": "arn:aws:states:::events:putEvents",
      "Comment": "üöÄ Hybrid Mode: Publish completion event for MAP_REDUCE/BATCHED modes",
      "Parameters": {
        "Entries": [
          {
            "EventBusName": "${WorkflowEventBusArn}",
            "Source": "backend-workflow.lifecycle",
            "DetailType": "WorkflowLifecycleEvent",
            "Detail": {
              "execution_id.$": "$$.Execution.Id",
              "conversation_id.$": "$$.Execution.Id",
              "ownerId.$": "$.state_data.ownerId",
              "workflowId.$": "$.state_data.workflowId",
              "status": "COMPLETED",
              "notification_type": "execution_progress",
              "message": "Workflow completed via hybrid distributed mode",
              "distributed_strategy.$": "$.state_data.distributed_strategy",
              "final_state.$": "$.aggregation_result.final_state"
            }
          }
        ]
      },
      "ResultPath": "$.completion_notification_result",
      "Next": "PrepareHybridModeOutput"
    },
    "PrepareHybridModeOutput": {
      "Type": "Pass",
      "Comment": "üöÄ Hybrid Mode: Prepare final output for MAP_REDUCE/BATCHED execution",
      "Parameters": {
        "status": "SUCCEEDED",
        "execution_id.$": "$$.Execution.Id",
        "ownerId.$": "$.state_data.ownerId",
        "workflowId.$": "$.state_data.workflowId",
        "final_state.$": "$.aggregation_result.final_state",
        "distributed_strategy.$": "$.state_data.distributed_strategy",
        "distributed_strategy_detail.$": "$.state_data.distributed_strategy_detail",
        "total_segments.$": "$.state_data.total_segments",
        "start_time.$": "$.state_data.start_time"
      },
      "Next": "WorkflowSucceeded"
    },
    "NotifyExecutionFailure": {
      "Type": "Task",
      "Resource": "arn:aws:states:::events:putEvents",
      "Comment": "[Fix] ÏõåÌÅ¨ÌîåÎ°úÏö∞ Ïã§Ìå® Ïù¥Î≤§Ìä∏ Î∞úÌñâ - ÏõêÎ≥∏ Ïã§Ìñâ ÏûÖÎ†•ÏóêÏÑú ÏïàÏ†ÑÌïòÍ≤å Ï∞∏Ï°∞ (Catch ÏãúÏóêÎèÑ ÎèôÏûë)",
      "Parameters": {
        "Entries": [
          {
            "EventBusName": "${WorkflowEventBusArn}",
            "Source": "backend-workflow.lifecycle",
            "DetailType": "WorkflowLifecycleEvent",
            "Detail": {
              "event_type": "FAILED",
              "event_version": "1.0",
              "trace_id.$": "$$.Execution.Id",
              "timestamp.$": "$$.State.EnteredTime",
              "TaskToken": "EXECUTION_FAILURE",
              "notification_type": "execution_progress",
              "status": "FAILED",
              "message": "Workflow execution failed",
              "ownerId.$": "$$.Execution.Input.ownerId",
              "userId.$": "$$.Execution.Input.ownerId",
              "workflowId.$": "$$.Execution.Input.workflowId",
              "error.$": "States.JsonToString($)"
            }
          }
        ]
      },
      "ResultPath": "$.failure_notification_result",
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Comment": "EventBridge publish failure should not stop workflow, ensure failure notification result exists",
          "ResultPath": "$.failure_notification_error",
          "Next": "WorkflowFailed"
        }
      ],
      "Next": "WorkflowFailed"
    },
    "WorkflowFailed": {
      "Type": "Fail",
      "Comment": "ÏõåÌÅ¨ÌîåÎ°úÏö∞Í∞Ä Ïã§Ìå®ÌñàÏäµÎãàÎã§."
    }
  }
}