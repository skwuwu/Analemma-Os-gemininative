{
  "Comment": "ÏÇ¨Ïö©Ïûê ÏõåÌÅ¨ÌîåÎ°úÏö∞Î•º ÏÑ∏Í∑∏Î®ºÌä∏ Îã®ÏúÑÎ°ú Ïã§ÌñâÌïòÍ≥†, HITPÎ•º Ï≤òÎ¶¨ÌïòÎäî Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÌÑ∞",
  "StartAt": "CheckForInjectedConfig",
  "States": {
    "CheckForInjectedConfig": {
      "Type": "Choice",
      "Comment": "MOCK_MODEÍ∞Ä trueÏù¥Í≥† ÌÖåÏä§Ìä∏ ÏÑ§Ï†ïÏù¥ ÏûàÏúºÎ©¥ DynamoDB Ïö∞Ìöå",
      "Choices": [
        {
          "And": [
            {
              "Variable": "$.MOCK_MODE",
              "StringEquals": "true"
            },
            {
              "Variable": "$.test_workflow_config",
              "IsPresent": true
            }
          ],
          "Next": "InitializeStateData"
        }
      ],
      "Default": "CheckForExistingExecution"
    },
    "CheckForExistingExecution": {
      "Type": "Task",
      "Resource": "arn:aws:states:::dynamodb:getItem",
      "Comment": "[2ÏàúÏúÑ ÏµúÏ†ÅÌôî] Direct SDK Integration: Lambda Cold Start Ï†úÍ±∞. DynamoDBÏóêÏÑú ÏßÅÏ†ë idempotency_key Ï°∞Ìöå",
      "Parameters": {
        "TableName": "${IdempotencyTable}",
        "Key": {
          "idempotency_key": {
            "S.$": "$.idempotency_key"
          }
        },
        "ProjectionExpression": "executionArn, #st",
        "ExpressionAttributeNames": {
          "#st": "status"
        }
      },
      "ResultSelector": {
        "existing_execution_arn.$": "$.Item.executionArn.S",
        "existing_execution_status.$": "$.Item.status.S"
      },
      "ResultPath": "$.idempotency_check_result",
      "Retry": [
        {
          "ErrorEquals": [
            "DynamoDB.ServiceException",
            "DynamoDB.ThrottlingException",
            "States.TaskFailed"
          ],
          "IntervalSeconds": 2,
          "MaxAttempts": 3,
          "BackoffRate": 2.0,
          "Comment": "DynamoDB ÏùºÏãúÏ†Å Ïò§Î•òÏóê ÎåÄÌïú Ïû¨ÏãúÎèÑ"
        }
      ],
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Comment": "Î©±Îì±ÏÑ± Ï≤¥ÌÅ¨ Ïã§Ìå® Ïãú ÏïàÏ†ÑÌïú Ï≤òÎ¶¨",
          "ResultPath": "$.idempotency_error",
          "Next": "HandleIdempotencyFailure"
        }
      ],
      "Next": "HandleExistingExecution"
    },
    "HandleIdempotencyFailure": {
      "Type": "Choice",
      "Comment": "Î©±Îì±ÏÑ± Ï≤¥ÌÅ¨ Ïã§Ìå® Ïãú ÏïàÏ†Ñ Î™®Îìú ÌôïÏù∏",
      "Choices": [
        {
          "Variable": "$.ALLOW_UNSAFE_EXECUTION",
          "BooleanEquals": true,
          "Next": "InitializeStateData"
        }
      ],
      "Default": "FailIdempotencyUnavailable"
    },
    "FailIdempotencyUnavailable": {
      "Type": "Fail",
      "Error": "IdempotencyCheckFailed",
      "Cause": "Unable to verify execution uniqueness. DynamoDB idempotency check failed and unsafe execution is not allowed."
    },
    "HandleExistingExecution": {
      "Type": "Choice",
      "Comment": "If an existing execution is found, decide whether to resume or fail",
      "Choices": [
        {
          "And": [
            {
              "Variable": "$.idempotency_check_result.existing_execution_arn",
              "IsPresent": true
            },
            {
              "Variable": "$.idempotency_check_result.existing_execution_status",
              "StringEquals": "RUNNING"
            }
          ],
          "Next": "FailDuplicateExecution"
        },
        {
          "And": [
            {
              "Variable": "$.idempotency_check_result.existing_execution_arn",
              "IsPresent": true
            },
            {
              "Variable": "$.idempotency_check_result.existing_execution_status",
              "StringEquals": "SUCCEEDED"
            }
          ],
          "Next": "SucceedDuplicateExecution"
        }
      ],
      "Default": "InitializeStateData"
    },
    "FailDuplicateExecution": {
      "Type": "Fail",
      "Error": "DuplicateExecution",
      "Cause": "An execution with the same idempotency key is already running."
    },
    "SucceedDuplicateExecution": {
      "Type": "Succeed",
      "Comment": "An execution with the same idempotency key already succeeded."
    },
    "InitializeStateData": {
      "Type": "Task",
      "Resource": "arn:aws:states:::lambda:invoke",
      "Comment": "[3ÏàúÏúÑ ÏµúÏ†ÅÌôî] S3 path Î°úÏßÅÏùÑ Lambda ÎÇ¥Î∂ÄÎ°ú Ìù°Ïàò. CheckS3PathPresent, InitializeExecutionWithS3/Inline Ï†úÍ±∞Îê®.",
      "Parameters": {
        "FunctionName": "${InitializeStateDataArn}",
        "InvocationType": "RequestResponse",
        "Payload": {
          "input.$": "$"
        }
      },
      "ResultSelector": {
        "workflow_config.$": "$.Payload.workflow_config",
        "current_state.$": "$.Payload.current_state",
        "input.$": "$.Payload.input",
        "state_s3_path.$": "$.Payload.state_s3_path",
        "state_history.$": "$.Payload.state_history",
        "ownerId.$": "$.Payload.ownerId",
        "workflowId.$": "$.Payload.workflowId",
        "segment_to_run.$": "$.Payload.segment_to_run",
        "idempotency_key.$": "$.Payload.idempotency_key",
        "quota_reservation_id.$": "$.Payload.quota_reservation_id",
        "total_segments.$": "$.Payload.total_segments",
        "partition_map.$": "$.Payload.partition_map",
        "partition_map_s3_path.$": "$.Payload.partition_map_s3_path",
        "segment_manifest.$": "$.Payload.segment_manifest",
        "segment_manifest_s3_path.$": "$.Payload.segment_manifest_s3_path",
        "state_durations.$": "$.Payload.state_durations",
        "last_update_time.$": "$.Payload.last_update_time",
        "start_time.$": "$.Payload.start_time",
        "max_loop_iterations.$": "$.Payload.max_loop_iterations",
        "max_branch_iterations.$": "$.Payload.max_branch_iterations",
        "loop_counter.$": "$.Payload.loop_counter",
        "max_concurrency.$": "$.Payload.max_concurrency",
        "distributed_mode.$": "$.Payload.distributed_mode",
        "llm_segments.$": "$.Payload.llm_segments",
        "hitp_segments.$": "$.Payload.hitp_segments"
      },
      "ResultPath": "$.state_data",
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "ResultPath": "$.init_error",
          "Next": "HandleInitFailure"
        }
      ],
      "Next": "CheckLargeWorkflow"
    },
    "HandleInitFailure": {
      "Type": "Task",
      "Resource": "arn:aws:states:::events:putEvents",
      "Comment": "[Fix] InitializeStateData Ïã§Ìå® Ïãú ÏõêÎ≥∏ ÏûÖÎ†•ÏóêÏÑú ownerId Ï∂îÏ∂ú",
      "Parameters": {
        "Entries": [
          {
            "EventBusName": "${WorkflowEventBusArn}",
            "Source": "backend-workflow.lifecycle",
            "DetailType": "WorkflowLifecycleEvent",
            "Detail": {
              "execution_id.$": "$$.Execution.Id",
              "ownerId.$": "$.ownerId",
              "workflowId.$": "$.workflowId",
              "status": "FAILED",
              "notification_type": "execution_progress",
              "message": "Workflow initialization failed",
              "error.$": "$.init_error"
            }
          }
        ]
      },
      "Next": "InitializationFailed"
    },
    "InitializationFailed": {
      "Type": "Fail",
      "Error": "InitializationFailed",
      "Cause": "Failed to initialize workflow state data"
    },
    "CheckLargeWorkflow": {
      "Type": "Choice",
      "Comment": "Check if workflow is very large (>200 segments) and send monitoring warning",
      "Choices": [
        {
          "Variable": "$.state_data.total_segments",
          "NumericGreaterThan": 200,
          "Next": "NotifyLargeWorkflowWarning"
        }
      ],
      "Default": "NotifyWorkflowStarted"
    },
    "NotifyLargeWorkflowWarning": {
      "Type": "Task",
      "Resource": "arn:aws:states:::events:putEvents",
      "Comment": "Notify about very large workflow that may approach Event History limits",
      "Parameters": {
        "Entries": [
          {
            "EventBusName": "${WorkflowEventBusArn}",
            "Source": "backend-workflow.lifecycle",
            "DetailType": "WorkflowLifecycleEvent",
            "Detail": {
              "execution_id.$": "$$.Execution.Id",
              "ownerId.$": "$.state_data.ownerId",
              "workflowId.$": "$.state_data.workflowId",
              "total_segments.$": "$.state_data.total_segments",
              "warning": "Very large workflow detected - monitor Event History usage closely",
              "notification_type": "execution_progress",
              "status": "LARGE_WORKFLOW_WARNING"
            }
          }
        ]
      },
      "ResultPath": "$.large_workflow_warning",
      "Next": "NotifyWorkflowStarted"
    },
    "NotifyWorkflowStarted": {
      "Type": "Task",
      "Resource": "arn:aws:states:::events:putEvents",
      "Comment": "üöÄ Fire-and-forget: Publish workflow start event to EventBridge for async processing",
      "Parameters": {
        "Entries": [
          {
            "EventBusName": "${WorkflowEventBusArn}",
            "Source": "backend-workflow.lifecycle",
            "DetailType": "WorkflowLifecycleEvent",
            "Detail": {
              "TaskToken": "PROGRESS_NOTIFICATION",
              "userId.$": "$.state_data.ownerId",
              "ownerId.$": "$.state_data.ownerId",
              "state_data.$": "$.state_data",
              "conversation_id.$": "$$.Execution.Id",
              "execution_id.$": "$$.Execution.Id",
              "workflowId.$": "$.state_data.workflowId",
              "notification_type": "execution_progress",
              "status": "RUNNING",
              "message": "Workflow started",
              "segment_to_run.$": "$.state_data.segment_to_run"
            }
          }
        ]
      },
      "ResultPath": "$.notification_result",
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Comment": "EventBridge publish failure should not stop workflow",
          "ResultPath": "$.notification_error",
          "Next": "ExecuteSegment"
        }
      ],
      "Next": "ExecuteSegment"
    },
    "ExecuteSegment": {
      "Type": "Task",
      "Resource": "arn:aws:states:::lambda:invoke",
      "Comment": "Execute a single segment of the user workflow",
      "Parameters": {
        "FunctionName": "${ExecuteSegmentArn}",
        "InvocationType": "RequestResponse",
        "Payload": {
          "workflow_config.$": "$.state_data.workflow_config",
          "current_state.$": "$.state_data.current_state",
          "state_history.$": "$.state_data.state_history",
          "ownerId.$": "$.state_data.ownerId",
          "workflowId.$": "$.state_data.workflowId",
          "segment_to_run.$": "$.state_data.segment_to_run",
          "idempotency_key.$": "$.state_data.idempotency_key",
          "quota_reservation_id.$": "$.state_data.quota_reservation_id",
          "total_segments.$": "$.state_data.total_segments",
          "partition_map.$": "$.state_data.partition_map",
          "partition_map_s3_path.$": "$.state_data.partition_map_s3_path",
          "max_concurrency.$": "$.state_data.max_concurrency",
          "state_durations.$": "$.state_data.state_durations",
          "last_update_time.$": "$.state_data.last_update_time",
          "start_time.$": "$.state_data.start_time"
        }
      },
      "ResultSelector": {
        "status.$": "$.Payload.status",
        "final_state.$": "$.Payload.final_state",
        "final_state_s3_path.$": "$.Payload.final_state_s3_path",
        "next_segment_to_run.$": "$.Payload.next_segment_to_run",
        "new_history_logs.$": "$.Payload.new_history_logs",
        "error_info.$": "$.Payload.error_info",
        "branches.$": "$.Payload.branches",
        "segment_type.$": "$.Payload.segment_type"
      },
      "ResultPath": "$.execution_result",
      "Retry": [
        {
          "ErrorEquals": [
            "Lambda.ServiceException",
            "Lambda.AWSLambdaException",
            "Lambda.SdkClientException",
            "Lambda.TooManyRequestsException"
          ],
          "IntervalSeconds": 5,
          "MaxAttempts": 6,
          "BackoffRate": 2.0,
          "JitterStrategy": "FULL",
          "Comment": "[Concurrency Protection] Lambda 429Ïóê ÎåÄÌïú Í∞ïÌôîÎêú Ïû¨ÏãúÎèÑ - ÎèôÏãúÏÑ± Ïä¨Î°Ø ÌöåÎ≥µ ÎåÄÍ∏∞"
        },
        {
          "ErrorEquals": [
            "States.TaskFailed"
          ],
          "IntervalSeconds": 2,
          "MaxAttempts": 3,
          "BackoffRate": 2.0,
          "Comment": "ÏùºÎ∞òÏ†ÅÏù∏ ÏûëÏóÖ Ïã§Ìå®Ïóê ÎåÄÌïú Ï†úÌïúÏ†Å Ïû¨ÏãúÎèÑ"
        }
      ],
      "Catch": [
        {
          "ErrorEquals": [
            "PartitionError"
          ],
          "ResultPath": "$.partition_error",
          "Next": "NotifyExecutionFailure"
        },
        {
          "ErrorEquals": [
            "AsyncLLMRequiredException"
          ],
          "ResultPath": "$.async_error",
          "Next": "CheckIfAsyncRequired"
        },
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Next": "NotifyExecutionFailure"
        }
      ],
      "Next": "CheckSegmentStatus"
    },
    "CheckSegmentStatus": {
      "Type": "Choice",
      "Comment": "Check execution status: PARALLEL_GROUP, PAUSE, FAILED, or COMPLETE",
      "Choices": [
        {
          "Variable": "$.execution_result.status",
          "StringEquals": "FAILED",
          "Next": "NotifyExecutionFailure"
        },
        {
          "Variable": "$.execution_result.status",
          "StringEquals": "PARALLEL_GROUP",
          "Next": "ProcessParallelSegments"
        },
        {
          "Variable": "$.execution_result.status",
          "StringEquals": "PAUSED_FOR_ASYNC_LLM",
          "Next": "HandleAsyncLLM"
        },
        {
          "Variable": "$.execution_result.status",
          "StringEquals": "PAUSE",
          "Next": "WaitForCallback"
        },
        {
          "Variable": "$.execution_result.status",
          "StringEquals": "PAUSED_FOR_HITP",
          "Next": "WaitForCallback"
        }
      ],
      "Default": "CheckForNextSegment"
    },
    "ProcessParallelSegments": {
      "Type": "Map",
      "Comment": "Execute parallel branches inline using a Map state with dynamic concurrency",
      "ItemsPath": "$.execution_result.branches",
      "ResultPath": "$.parallel_results",
      "MaxConcurrencyPath": "$.state_data.max_concurrency",
      "Parameters": {
        "branch_config.$": "$$.Map.Item.Value",
        "branch_id.$": "States.Format('branch_{}', $$.Map.Item.Index)",
        "branch_index.$": "$$.Map.Item.Index",
        "partition_map.$": "$$.Map.Item.Value.partition_map",
        "partition_map_s3_path.$": "$.state_data.partition_map_s3_path",
        "segment_manifest.$": "$.state_data.segment_manifest",
        "segment_manifest_s3_path.$": "$.state_data.segment_manifest_s3_path",
        "workflow_config.$": "$.state_data.workflow_config",
        "current_state.$": "$.state_data.current_state",
        "ownerId.$": "$.state_data.ownerId",
        "workflowId.$": "$.state_data.workflowId",
        "idempotency_key.$": "$.state_data.idempotency_key",
        "quota_reservation_id.$": "$.state_data.quota_reservation_id",
        "state_history.$": "$.state_data.state_history",
        "state_durations.$": "$.state_data.state_durations",
        "last_update_time.$": "$.state_data.last_update_time",
        "start_time.$": "$.state_data.start_time",
        "max_loop_iterations.$": "$.state_data.max_loop_iterations",
        "max_branch_iterations.$": "$.state_data.max_branch_iterations",
        "max_concurrency.$": "$.state_data.max_concurrency",
        "distributed_mode.$": "$.state_data.distributed_mode",
        "llm_segments.$": "$.state_data.llm_segments",
        "hitp_segments.$": "$.state_data.hitp_segments"
      },
      "Iterator": {
        "StartAt": "InitializeBranch",
        "States": {
          "InitializeBranch": {
            "Type": "Pass",
            "Parameters": {
              "segment_to_run": 0,
              "branch_id.$": "$.branch_id",
              "partition_map.$": "$.partition_map",
              "partition_map_s3_path.$": "$.partition_map_s3_path",
              "segment_manifest.$": "$.segment_manifest",
              "segment_manifest_s3_path.$": "$.segment_manifest_s3_path",
              "workflow_config.$": "$.workflow_config",
              "current_state.$": "$.current_state",
              "ownerId.$": "$.ownerId",
              "workflowId.$": "$.workflowId",
              "idempotency_key.$": "$.idempotency_key",
              "quota_reservation_id.$": "$.quota_reservation_id",
              "state_history.$": "$.state_history",
              "state_durations.$": "$.state_durations",
              "last_update_time.$": "$.last_update_time",
              "start_time.$": "$.start_time",
              "loop_counter": 0,
              "max_loop_iterations.$": "$.max_loop_iterations",
              "max_branch_iterations.$": "$.max_branch_iterations",
              "max_concurrency.$": "$.max_concurrency",
              "distributed_mode.$": "$.distributed_mode",
              "llm_segments.$": "$.llm_segments",
              "hitp_segments.$": "$.hitp_segments"
            },
            "ResultPath": "$.state_data",
            "Next": "ExecuteBranchSegment"
          },
          "ExecuteBranchSegment": {
            "Type": "Task",
            "Resource": "arn:aws:states:::lambda:invoke",
            "Parameters": {
              "FunctionName": "${ExecuteSegmentArn}",
              "Payload": {
                "workflow_config.$": "$.state_data.workflow_config",
                "current_state.$": "$.state_data.current_state",
                "state_history.$": "$.state_data.state_history",
                "ownerId.$": "$.state_data.ownerId",
                "workflowId.$": "$.state_data.workflowId",
                "segment_to_run.$": "$.state_data.segment_to_run",
                "idempotency_key.$": "$.state_data.idempotency_key",
                "partition_map.$": "$.state_data.partition_map",
                "state_durations.$": "$.state_data.state_durations",
                "last_update_time.$": "$.state_data.last_update_time",
                "start_time.$": "$.state_data.start_time"
              }
            },
            "ResultSelector": {
              "status.$": "$.Payload.status",
              "final_state.$": "$.Payload.final_state",
              "final_state_s3_path.$": "$.Payload.final_state_s3_path",
              "next_segment_to_run.$": "$.Payload.next_segment_to_run",
              "new_history_logs.$": "$.Payload.new_history_logs"
            },
            "ResultPath": "$.execution_result",
            "Next": "CheckBranchNext"
          },
          "CheckBranchNext": {
            "Type": "Choice",
            "Choices": [
              {
                "Variable": "$.execution_result.next_segment_to_run",
                "IsPresent": true,
                "Next": "UpdateBranchSegment"
              }
            ],
            "Default": "BranchComplete"
          },
          "UpdateBranchSegment": {
            "Type": "Pass",
            "Parameters": {
              "workflow_config.$": "$.state_data.workflow_config",
              "current_state.$": "$.execution_result.final_state",
              "state_history.$": "$.state_data.state_history",
              "ownerId.$": "$.state_data.ownerId",
              "workflowId.$": "$.state_data.workflowId",
              "segment_to_run.$": "$.execution_result.next_segment_to_run",
              "idempotency_key.$": "$.state_data.idempotency_key",
              "quota_reservation_id.$": "$.state_data.quota_reservation_id",
              "partition_map.$": "$.state_data.partition_map",
              "partition_map_s3_path.$": "$.state_data.partition_map_s3_path",
              "segment_manifest.$": "$.state_data.segment_manifest",
              "segment_manifest_s3_path.$": "$.state_data.segment_manifest_s3_path",
              "state_durations.$": "$.state_data.state_durations",
              "last_update_time.$": "$.state_data.last_update_time",
              "start_time.$": "$.state_data.start_time",
              "loop_counter.$": "States.MathAdd($.state_data.loop_counter, 1)",
              "max_loop_iterations.$": "$.state_data.max_loop_iterations",
              "max_branch_iterations.$": "$.state_data.max_branch_iterations",
              "max_concurrency.$": "$.state_data.max_concurrency",
              "distributed_mode.$": "$.state_data.distributed_mode",
              "llm_segments.$": "$.state_data.llm_segments",
              "hitp_segments.$": "$.state_data.hitp_segments"
            },
            "ResultPath": "$.state_data",
            "Next": "CheckBranchLoopLimit"
          },
          "CheckBranchLoopLimit": {
            "Type": "Choice",
            "Comment": "Dynamic branch loop limit based on workflow complexity",
            "Choices": [
              {
                "Variable": "$.state_data.loop_counter",
                "NumericGreaterThanPath": "$.state_data.max_branch_iterations",
                "Next": "BranchLoopLimitExceeded"
              }
            ],
            "Default": "ExecuteBranchSegment"
          },
          "BranchLoopLimitExceeded": {
            "Type": "Fail",
            "Error": "BranchLoopLimitExceeded",
            "Cause": "Parallel branch exceeded maximum loop iterations."
          },
          "BranchComplete": {
            "Type": "Pass",
            "Comment": "[Fix] Î∏åÎûúÏπò Í≤∞Í≥ºÏóê ÏÉÅÌÉú Î∞è ÏóêÎü¨ Ï†ïÎ≥¥ Ìè¨Ìï®",
            "Parameters": {
              "branch_id.$": "$.state_data.branch_id",
              "branch_status.$": "$.execution_result.status",
              "final_state.$": "$.execution_result.final_state",
              "final_state_s3_path.$": "$.execution_result.final_state_s3_path",
              "new_history_logs.$": "$.execution_result.new_history_logs",
              "error_info.$": "$.execution_result.error_info",
              "branch_executed": true
            },
            "End": true
          }
        }
      },
      "Next": "AggregateParallelResults"
    },
    "AggregateParallelResults": {
      "Type": "Task",
      "Resource": "arn:aws:states:::lambda:invoke",
      "Comment": "Aggregate results from parallel branches.",
      "Parameters": {
        "FunctionName": "${SegmentRunnerArn}",
        "InvocationType": "RequestResponse",
        "Payload": {
          "segment_type": "aggregator",
          "parallel_results.$": "$.parallel_results",
          "workflow_config.$": "$.state_data.workflow_config",
          "current_state.$": "$.state_data.current_state",
          "ownerId.$": "$.state_data.ownerId",
          "workflowId.$": "$.state_data.workflowId",
          "segment_to_run.$": "$.state_data.segment_to_run",
          "idempotency_key.$": "$.state_data.idempotency_key"
        }
      },
      "ResultSelector": {
        "status.$": "$.Payload.status",
        "final_state.$": "$.Payload.final_state",
        "final_state_s3_path.$": "$.Payload.final_state_s3_path",
        "next_segment_to_run.$": "$.Payload.next_segment_to_run",
        "new_history_logs.$": "$.Payload.new_history_logs"
      },
      "ResultPath": "$.execution_result",
      "Next": "UpdateStateData"
    },
    "UpdateStateData": {
      "Type": "Task",
      "Resource": "arn:aws:states:::lambda:invoke",
      "Comment": "Update state_data with payload size management and S3 offloading for large states",
      "Parameters": {
        "FunctionName": "${StateDataManagerArn}",
        "InvocationType": "RequestResponse",
        "Payload": {
          "action": "update_and_compress",
          "state_data.$": "$.state_data",
          "execution_result.$": "$.execution_result",
          "max_payload_size_kb": 200
        }
      },
      "ResultSelector": {
        "workflow_config.$": "$.Payload.workflow_config",
        "current_state.$": "$.Payload.current_state",
        "state_s3_path.$": "$.Payload.state_s3_path",
        "state_history.$": "$.Payload.state_history",
        "ownerId.$": "$.Payload.ownerId",
        "workflowId.$": "$.Payload.workflowId",
        "segment_to_run.$": "$.Payload.segment_to_run",
        "idempotency_key.$": "$.Payload.idempotency_key",
        "quota_reservation_id.$": "$.Payload.quota_reservation_id",
        "total_segments.$": "$.Payload.total_segments",
        "partition_map.$": "$.Payload.partition_map",
        "partition_map_s3_path.$": "$.Payload.partition_map_s3_path",
        "segment_manifest.$": "$.Payload.segment_manifest",
        "segment_manifest_s3_path.$": "$.Payload.segment_manifest_s3_path",
        "state_durations.$": "$.Payload.state_durations",
        "last_update_time.$": "$.Payload.last_update_time",
        "start_time.$": "$.Payload.start_time",
        "max_loop_iterations.$": "$.Payload.max_loop_iterations",
        "max_branch_iterations.$": "$.Payload.max_branch_iterations",
        "loop_counter.$": "$.Payload.loop_counter",
        "payload_size_kb.$": "$.Payload.payload_size_kb",
        "compression_applied.$": "$.Payload.compression_applied",
        "llm_segments.$": "$.Payload.llm_segments",
        "hitp_segments.$": "$.Payload.hitp_segments",
        "max_concurrency.$": "$.Payload.max_concurrency",
        "distributed_mode.$": "$.Payload.distributed_mode"
      },
      "ResultPath": "$.state_data",
      "Retry": [
        {
          "ErrorEquals": [
            "Lambda.ServiceException",
            "Lambda.AWSLambdaException",
            "Lambda.SdkClientException",
            "Lambda.TooManyRequestsException"
          ],
          "IntervalSeconds": 5,
          "MaxAttempts": 6,
          "BackoffRate": 2.0,
          "JitterStrategy": "FULL",
          "Comment": "[Concurrency Protection] Lambda 429Ïóê ÎåÄÌïú Í∞ïÌôîÎêú Ïû¨ÏãúÎèÑ - ÎèôÏãúÏÑ± Ïä¨Î°Ø ÌöåÎ≥µ ÎåÄÍ∏∞"
        },
        {
          "ErrorEquals": [
            "S3.ServiceException",
            "S3.ThrottlingException"
          ],
          "IntervalSeconds": 2,
          "MaxAttempts": 4,
          "BackoffRate": 2.0,
          "Comment": "S3 Ïä§Î°úÌãÄÎßÅ Î∞è ÏÑúÎπÑÏä§ Ïò§Î•òÏóê ÎåÄÌïú Ïû¨ÏãúÎèÑ"
        }
      ],
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Comment": "State compression failure - fallback to original Pass logic",
          "ResultPath": "$.compression_error",
          "Next": "UpdateStateDataFallback"
        }
      ],
      "Next": "IsPauseNeeded"
    },
    "UpdateStateDataFallback": {
      "Type": "Pass",
      "Comment": "Fallback state update when compression fails",
      "Parameters": {
        "workflow_config.$": "$.state_data.workflow_config",
        "current_state.$": "$.execution_result.final_state",
        "state_s3_path.$": "$.execution_result.final_state_s3_path",
        "state_history.$": "$.execution_result.new_history_logs",
        "ownerId.$": "$.state_data.ownerId",
        "workflowId.$": "$.state_data.workflowId",
        "segment_to_run.$": "$.state_data.segment_to_run",
        "idempotency_key.$": "$.state_data.idempotency_key",
        "quota_reservation_id.$": "$.state_data.quota_reservation_id",
        "total_segments.$": "$.state_data.total_segments",
        "partition_map.$": "$.state_data.partition_map",
        "partition_map_s3_path.$": "$.state_data.partition_map_s3_path",
        "segment_manifest.$": "$.state_data.segment_manifest",
        "segment_manifest_s3_path.$": "$.state_data.segment_manifest_s3_path",
        "max_concurrency.$": "$.state_data.max_concurrency",
        "distributed_mode.$": "$.state_data.distributed_mode",
        "state_durations.$": "$.state_data.state_durations",
        "last_update_time.$": "$.state_data.last_update_time",
        "start_time.$": "$.state_data.start_time",
        "max_loop_iterations.$": "$.state_data.max_loop_iterations",
        "max_branch_iterations.$": "$.state_data.max_branch_iterations",
        "loop_counter.$": "$.state_data.loop_counter",
        "llm_segments.$": "$.state_data.llm_segments",
        "hitp_segments.$": "$.state_data.hitp_segments"
      },
      "ResultPath": "$.state_data",
      "Next": "IsPauseNeeded"
    },
    "IsPauseNeeded": {
      "Type": "Choice",
      "Comment": "Check if the segment execution resulted in a PAUSE or PAUSED_FOR_HITP status",
      "Choices": [
        {
          "Variable": "$.execution_result.status",
          "StringEquals": "PAUSE",
          "Next": "WaitForCallback"
        },
        {
          "Variable": "$.execution_result.status",
          "StringEquals": "PAUSED_FOR_HITP",
          "Next": "WaitForCallback"
        }
      ],
      "Default": "CheckForNextSegment"
    },
    "CheckForNextSegment": {
      "Type": "Choice",
      "Comment": "Check if there is a next segment to run, or if workflow is complete",
      "Choices": [
        {
          "And": [
            {
              "Variable": "$.execution_result.status",
              "StringEquals": "COMPLETE"
            },
            {
              "Variable": "$.execution_result.next_segment_to_run",
              "IsNull": true
            }
          ],
          "Next": "PublishSucceededEvent"
        },
        {
          "And": [
            {
              "Variable": "$.execution_result.status",
              "StringEquals": "COMPLETE"
            },
            {
              "Not": {
                "Variable": "$.execution_result.next_segment_to_run",
                "IsPresent": true
              }
            }
          ],
          "Next": "PublishSucceededEvent"
        }
      ],
      "Default": "PrepareNextSegment"
    },
    "WaitForCallback": {
      "Type": "Task",
      "Resource": "arn:aws:states:::lambda:invoke.waitForTaskToken",
      "Comment": "HITP: TaskToken Ï†ÄÏû• ‚Üí ÏïåÎ¶º Ï†ÑÏÜ° ‚Üí Ïô∏Î∂Ä resume ÎåÄÍ∏∞",
      "Parameters": {
        "FunctionName": "${StoreTaskTokenArn}",
        "Payload": {
          "TaskToken.$": "$$.Task.Token",
          "conversation_id.$": "$$.Execution.Id",
          "execution_id.$": "$$.Execution.Id",
          "execution_name.$": "$$.Execution.Name",
          "idempotency_key.$": "$.state_data.idempotency_key",
          "workflow_config.$": "$.state_data.workflow_config",
          "current_state.$": "$.execution_result.final_state",
          "state_s3_path.$": "$.execution_result.final_state_s3_path",
          "segment_to_run.$": "$.execution_result.next_segment_to_run",
          "partition_map.$": "$.state_data.partition_map",
          "total_segments.$": "$.state_data.total_segments",
          "ownerId.$": "$.state_data.ownerId",
          "workflowId.$": "$.state_data.workflowId",
          "state_data.$": "$.state_data",
          "MOCK_MODE.$": "$.MOCK_MODE"
        }
      },
      "ResultPath": "$.callback_result",
      "Next": "PrepareStateAfterPause"
    },
    "PrepareStateAfterPause": {
      "Type": "Task",
      "Comment": "[3ÏàúÏúÑ ÏµúÏ†ÅÌôî] Callback Ï†ïÍ∑úÌôî Î°úÏßÅÏùÑ Lambda ÎÇ¥Î∂ÄÎ°ú Ìù°Ïàò. NormalizeCallbackResult, PromoteCallbackPayload/Direct Ï†úÍ±∞.",
      "Resource": "arn:aws:states:::lambda:invoke",
      "Parameters": {
        "FunctionName": "${MergeCallbackArn}",
        "InvocationType": "RequestResponse",
        "Payload": {
          "previous_final_state.$": "$.execution_result.final_state",
          "previous_final_state_s3_path.$": "$.execution_result.final_state_s3_path",
          "callback_result.$": "$.callback_result",
          "state_data.$": "$.state_data",
          "segment_to_run.$": "$.execution_result.next_segment_to_run",
          "ownerId.$": "$.state_data.ownerId",
          "workflowId.$": "$.state_data.workflowId"
        }
      },
      "ResultSelector": {
        "new_current_state.$": "$.Payload.new_current_state",
        "new_state_s3_path.$": "$.Payload.new_state_s3_path",
        "new_state_history.$": "$.Payload.new_state_history",
        "segment_to_run.$": "$.Payload.segment_to_run",
        "workflow_config.$": "$.Payload.workflow_config"
      },
      "ResultPath": "$.current_state_merge",
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Next": "NotifyExecutionFailure"
        }
      ],
      "Next": "ApplyMergedState"
    },
    "ApplyMergedState": {
      "Type": "Pass",
      "Comment": "Transfer merged new_current_state into state_data.current_state and set segment_to_run",
      "Parameters": {
        "workflow_config.$": "$.state_data.workflow_config",
        "current_state.$": "$.current_state_merge.new_current_state",
        "state_history.$": "$.current_state_merge.new_state_history",
        "state_s3_path.$": "$.current_state_merge.new_state_s3_path",
        "segment_to_run.$": "$.current_state_merge.segment_to_run",
        "partition_map.$": "$.state_data.partition_map",
        "partition_map_s3_path.$": "$.state_data.partition_map_s3_path",
        "segment_manifest.$": "$.state_data.segment_manifest",
        "segment_manifest_s3_path.$": "$.state_data.segment_manifest_s3_path",
        "total_segments.$": "$.state_data.total_segments",
        "ownerId.$": "$.state_data.ownerId",
        "workflowId.$": "$.state_data.workflowId",
        "idempotency_key.$": "$.state_data.idempotency_key",
        "quota_reservation_id.$": "$.state_data.quota_reservation_id",
        "max_concurrency.$": "$.state_data.max_concurrency",
        "distributed_mode.$": "$.state_data.distributed_mode",
        "state_durations.$": "$.state_data.state_durations",
        "last_update_time.$": "$.state_data.last_update_time",
        "start_time.$": "$.state_data.start_time",
        "max_loop_iterations.$": "$.state_data.max_loop_iterations",
        "max_branch_iterations.$": "$.state_data.max_branch_iterations",
        "loop_counter.$": "$.state_data.loop_counter",
        "llm_segments.$": "$.state_data.llm_segments",
        "hitp_segments.$": "$.state_data.hitp_segments"
      },
      "ResultPath": "$.state_data",
      "Next": "ExecuteSegment"
    },
    "CheckIfAsyncRequired": {
      "Type": "Choice",
      "Comment": "Check if error type is AsyncLLMRequiredException",
      "Choices": [
        {
          "Variable": "$.async_error.Error",
          "StringEquals": "AsyncLLMRequiredException",
          "Next": "HandleAsyncLLM"
        }
      ],
      "Default": "NotifyExecutionFailure"
    },
    "HandleAsyncLLM": {
      "Type": "Task",
      "Resource": "arn:aws:states:::lambda:invoke.waitForTaskToken",
      "Comment": "ÎπÑÎèôÍ∏∞ LLM Ï≤òÎ¶¨Î•º ÏúÑÌï¥ Task TokenÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ ÎåÄÍ∏∞",
      "Parameters": {
        "FunctionName": "${AsyncLLMHandlerArn}",
        "InvocationType": "RequestResponse",
        "Payload": {
          "TaskToken.$": "$$.Task.Token",
          "execution_id.$": "$$.Execution.Id",
          "idempotency_key.$": "$.state_data.idempotency_key",
          "workflow_config.$": "$.state_data.workflow_config",
          "current_state.$": "$.state_data.current_state",
          "ownerId.$": "$.state_data.ownerId",
          "segment_to_run.$": "$.state_data.segment_to_run",
          "workflowId.$": "$.state_data.workflowId"
        }
      },
      "ResultPath": "$.async_result",
      "Next": "ProcessAsyncResult"
    },
    "ProcessAsyncResult": {
      "Type": "Pass",
      "Comment": "ÎπÑÎèôÍ∏∞ LLM Í≤∞Í≥ºÎ•º Ï≤òÎ¶¨ÌïòÍ≥† Îã§Ïùå ÏÑ∏Í∑∏Î®ºÌä∏Î°ú ÏßÑÌñâ. Resume Handler ÏùëÎãµÏóê ÎåÄÌïú Î∞©Ïñ¥Ï†Å Ï≤òÎ¶¨ Ìè¨Ìï®.",
      "Parameters": {
        "workflow_config.$": "$.state_data.workflow_config",
        "current_state.$": "States.JsonMerge($.state_data.current_state, $.async_result.Payload, false)",
        "state_s3_path.$": "$.state_data.state_s3_path",
        "partition_map.$": "$.state_data.partition_map",
        "partition_map_s3_path.$": "$.state_data.partition_map_s3_path",
        "segment_manifest.$": "$.state_data.segment_manifest",
        "segment_manifest_s3_path.$": "$.state_data.segment_manifest_s3_path",
        "total_segments.$": "$.state_data.total_segments",
        "ownerId.$": "$.state_data.ownerId",
        "segment_to_run.$": "States.MathAdd($.state_data.segment_to_run, 1)",
        "idempotency_key.$": "$.state_data.idempotency_key",
        "quota_reservation_id.$": "$.state_data.quota_reservation_id",
        "workflowId.$": "$.state_data.workflowId",
        "max_concurrency.$": "$.state_data.max_concurrency",
        "distributed_mode.$": "$.state_data.distributed_mode",
        "state_durations.$": "$.state_data.state_durations",
        "last_update_time.$": "$.state_data.last_update_time",
        "start_time.$": "$.state_data.start_time",
        "max_loop_iterations.$": "$.state_data.max_loop_iterations",
        "max_branch_iterations.$": "$.state_data.max_branch_iterations",
        "loop_counter.$": "$.state_data.loop_counter",
        "llm_segments.$": "$.state_data.llm_segments",
        "hitp_segments.$": "$.state_data.hitp_segments"
      },
      "ResultPath": "$.state_data",
      "Next": "CheckLoopLimit"
    },
    "PrepareNextSegment": {
      "Type": "Choice",
      "Comment": "Check if there is a next segment to run, or if workflow is complete",
      "Choices": [
        {
          "Variable": "$.execution_result.next_segment_to_run",
          "IsPresent": true,
          "Next": "UpdateSegmentToRun"
        }
      ],
      "Default": "PublishSucceededEvent"
    },
    "UpdateSegmentToRun": {
      "Type": "Pass",
      "Comment": "Advance to the next segment when ExecuteSegment signalled CONTINUE, and increment loop counter",
      "Parameters": {
        "workflow_config.$": "$.state_data.workflow_config",
        "current_state.$": "$.execution_result.final_state",
        "state_s3_path.$": "$.execution_result.final_state_s3_path",
        "partition_map.$": "$.state_data.partition_map",
        "partition_map_s3_path.$": "$.state_data.partition_map_s3_path",
        "segment_manifest.$": "$.state_data.segment_manifest",
        "segment_manifest_s3_path.$": "$.state_data.segment_manifest_s3_path",
        "total_segments.$": "$.state_data.total_segments",
        "ownerId.$": "$.state_data.ownerId",
        "segment_to_run.$": "$.execution_result.next_segment_to_run",
        "idempotency_key.$": "$.state_data.idempotency_key",
        "quota_reservation_id.$": "$.state_data.quota_reservation_id",
        "workflowId.$": "$.state_data.workflowId",
        "max_concurrency.$": "$.state_data.max_concurrency",
        "distributed_mode.$": "$.state_data.distributed_mode",
        "state_durations.$": "$.state_data.state_durations",
        "last_update_time.$": "$.state_data.last_update_time",
        "start_time.$": "$.state_data.start_time",
        "state_history.$": "$.state_data.state_history",
        "max_loop_iterations.$": "$.state_data.max_loop_iterations",
        "max_branch_iterations.$": "$.state_data.max_branch_iterations",
        "loop_counter.$": "States.MathAdd($.state_data.loop_counter, 1)",
        "llm_segments.$": "$.state_data.llm_segments",
        "hitp_segments.$": "$.state_data.hitp_segments"
      },
      "ResultPath": "$.state_data",
      "Next": "CheckLoopLimit"
    },
    "CheckLoopLimit": {
      "Type": "Choice",
      "Comment": "Safety valve: Check loop counter to prevent infinite loops (dynamic limit based on workflow complexity)",
      "Choices": [
        {
          "Variable": "$.state_data.loop_counter",
          "NumericGreaterThanPath": "$.state_data.max_loop_iterations",
          "Next": "LoopLimitExceeded"
        }
      ],
      "Default": "ExecuteSegment"
    },
    "LoopLimitExceeded": {
      "Type": "Fail",
      "Error": "LoopLimitExceeded",
      "CausePath": "States.Format('Workflow execution exceeded maximum loop iterations ({}). Possible infinite loop detected. Current: {}, Max: {}', $.state_data.max_loop_iterations, $.state_data.loop_counter, $.state_data.max_loop_iterations)"
    },
    "PublishSucceededEvent": {
      "Type": "Task",
      "Resource": "arn:aws:states:::events:putEvents",
      "Comment": "Publish a domain event to EventBridge indicating the workflow succeeded",
      "Parameters": {
        "Entries": [
          {
            "EventBusName": "${WorkflowEventBusArn}",
            "Source": "backend-workflow.lifecycle",
            "DetailType": "WorkflowLifecycleEvent",
            "Detail": {
              "execution_id.$": "$$.Execution.Id",
              "conversation_id.$": "$$.Execution.Id",
              "ownerId.$": "$.ownerId",
              "workflowId.$": "$.workflowId",
              "status": "COMPLETED",
              "notification_type": "execution_progress",
              "message": "Workflow completed successfully",
              "state_data.$": "$",
              "final_result.$": "$.state_data.current_state"
            }
          }
        ]
      },
      "ResultPath": "$.event_publish_result",
      "Next": "PrepareSuccessOutput"
    },
    "PrepareSuccessOutput": {
      "Type": "Pass",
      "Comment": "[Fix] ÏµúÏ¢Ö Ï∂úÎ†•Ïóê execution_result Î∞è Í∞ÄÎìúÎ†àÏùº Î©îÌä∏Î¶≠ Ìè¨Ìï®",
      "Parameters": {
        "status": "SUCCEEDED",
        "execution_id.$": "$$.Execution.Id",
        "ownerId.$": "$.state_data.ownerId",
        "workflowId.$": "$.state_data.workflowId",
        "final_state.$": "$.execution_result.final_state",
        "final_state_s3_path.$": "$.execution_result.final_state_s3_path",
        "state_s3_path.$": "$.execution_result.final_state_s3_path",
        "execution_result.$": "$.execution_result",
        "loop_counter.$": "$.state_data.loop_counter",
        "max_loop_iterations.$": "$.state_data.max_loop_iterations",
        "llm_segments.$": "$.state_data.llm_segments",
        "hitp_segments.$": "$.state_data.hitp_segments",
        "start_time.$": "$.state_data.start_time",
        "state_durations.$": "$.state_data.state_durations",
        "total_segments.$": "$.state_data.total_segments"
      },
      "Next": "WorkflowSucceeded"
    },
    "WorkflowSucceeded": {
      "Type": "Succeed",
      "Comment": "ÏõåÌÅ¨ÌîåÎ°úÏö∞Í∞Ä ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§. - ÏµúÏ¢Ö Ï∂úÎ†•Ïóê S3 Í≤ΩÎ°ú Ìè¨Ìï®"
    },
    "NotifyExecutionFailure": {
      "Type": "Task",
      "Resource": "arn:aws:states:::events:putEvents",
      "Comment": "üöÄ Fire-and-forget: Publish workflow failure event to EventBridge for async processing",
      "Parameters": {
        "Entries": [
          {
            "EventBusName": "${WorkflowEventBusArn}",
            "Source": "backend-workflow.lifecycle",
            "DetailType": "WorkflowLifecycleEvent",
            "Detail": {
              "event_type": "FAILED",
              "event_version": "1.0",
              "trace_id.$": "$$.Execution.Id",
              "timestamp.$": "$$.State.EnteredTime",
              "TaskToken": "EXECUTION_FAILURE",
              "notification_type": "execution_progress",
              "status": "FAILED",
              "message": "Workflow execution failed",
              "ownerId.$": "$.state_data.ownerId",
              "userId.$": "$.state_data.ownerId",
              "workflowId.$": "$.state_data.workflowId",
              "error_info.$": "$.execution_result.error_info",
              "partition_error.$": "$.partition_error",
              "async_error.$": "$.async_error"
            }
          }
        ]
      },
      "ResultPath": "$.failure_notification_result",
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Comment": "EventBridge publish failure should not stop workflow, ensure failure notification result exists",
          "ResultPath": "$.failure_notification_error",
          "Next": "WorkflowFailed"
        }
      ],
      "Next": "WorkflowFailed"
    },
    "WorkflowFailed": {
      "Type": "Fail",
      "Comment": "ÏõåÌÅ¨ÌîåÎ°úÏö∞Í∞Ä Ïã§Ìå®ÌñàÏäµÎãàÎã§."
    }
  }
}