# -*- coding: utf-8 -*-
"""
Draft Result Generator Service - Gemini Native Edition

Service that generates detailed drafts of expected results without actual execution.
Called when user clicks "View Details".

[Gemini Native Integration]
- Gemini 1.5 Flash: Draft generation (cost-effective, fast response)
- Gemini 2.0 Flash: Complex document/multimodal drafts
- Google Cloud DLP: ë¯¼ê° ì •ë³´ íƒì§€ (ì„ íƒì )

[í•µì‹¬ ê°€ì¹˜] Pre-execution Visibility
- Vertex AIê°€ ê°•ë ¥í•œ ì—”ì§„ì´ë¼ë©´, Draft GeneratorëŠ” ê·¸ ì—”ì§„ì´ ë§Œë“  ì—ë„ˆì§€ê°€
  ì˜ëª»ëœ ë°©í–¥ìœ¼ë¡œ ë¶„ì¶œë˜ì§€ ì•Šë„ë¡ ë§‰ëŠ” 'ì œì–´íŒ'ì…ë‹ˆë‹¤.
- ì‚¬ìš©ìê°€ 'ì‹¤í–‰' ë²„íŠ¼ì„ ëˆ„ë¥´ê¸° ì „, AIê°€ ë³´ë‚¼ ì´ë©”ì¼ì˜ ì–´ì¡°ì™€ 
  ëˆ„ë½ëœ ì •ë³´ë¥¼ ì™„ë²½íˆ íŒŒì•…í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import json
import os
import re
import logging
from typing import Dict, Any, List, Optional
from enum import Enum

try:
    from src.models.plan_briefing import DraftResult
except ImportError:
    from src.models.plan_briefing import DraftResult

logger = logging.getLogger(__name__)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Gemini Native í´ë¼ì´ì–¸íŠ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    from src.services.llm.gemini_service import (
        get_gemini_flash_service,
        get_gemini_pro_service,
        GeminiService,
    )
    HAS_GEMINI = True
except ImportError:
    HAS_GEMINI = False
    get_gemini_flash_service = None
    get_gemini_pro_service = None
    GeminiService = None

# Google Cloud DLP (ì„ íƒì )
try:
    from google.cloud import dlp_v2
    HAS_CLOUD_DLP = True
except ImportError:
    HAS_CLOUD_DLP = False
    dlp_v2 = None

# OpenAI í´ë°± (ë ˆê±°ì‹œ í˜¸í™˜)
try:
    from openai import AsyncOpenAI
    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False
    AsyncOpenAI = None

# í™˜ê²½ ë³€ìˆ˜
USE_GEMINI_NATIVE = os.environ.get("USE_GEMINI_NATIVE", "true").lower() == "true"
USE_CLOUD_DLP = os.environ.get("USE_CLOUD_DLP", "false").lower() == "true"
GCP_PROJECT_ID = os.environ.get("GCP_PROJECT_ID", "")


class DraftOutputType(Enum):
    """ì´ˆì•ˆ ì¶œë ¥ íƒ€ì…"""
    EMAIL = "email"
    DOCUMENT = "document"
    SLACK_MESSAGE = "slack_message"
    NOTIFICATION = "notification"
    API_CALL = "api_call"
    SMS = "sms"
    CHART = "chart"  # ë©€í‹°ëª¨ë‹¬: ì°¨íŠ¸ ë ˆì´ì•„ì›ƒ
    DIAGRAM = "diagram"  # ë©€í‹°ëª¨ë‹¬: ë¬¸ì„œ êµ¬ì¡°ë„
    GENERIC = "generic"


class DraftResultGenerator:
    """
    ì‹¤ì œ ì‹¤í–‰ ì—†ì´ ì˜ˆìƒ ê²°ê³¼ë¬¼ì˜ ìƒì„¸ ì´ˆì•ˆ ìƒì„± - Gemini Native
    
    ë…¸ë“œ íƒ€ì…ë³„ë¡œ ìµœì í™”ëœ ì´ˆì•ˆ ìƒì„± ë¡œì§ì„ ì œê³µí•©ë‹ˆë‹¤.
    
    [Gemini Native ì¥ì ]
    - Gemini 1.5 Flash: ì´ˆë‹¹ ìˆ˜ì²œ í† í° ì²˜ë¦¬, ë¹„ìš© íš¨ìœ¨ì 
    - Structured Output: JSON ìŠ¤í‚¤ë§ˆ ê°•ì œë¡œ íŒŒì‹± ì˜¤ë¥˜ ì—†ìŒ
    - ë©€í‹°ëª¨ë‹¬ ì§€ì›: ì°¨íŠ¸/ë‹¤ì´ì–´ê·¸ë¨ í”„ë¦¬ë·° ê°€ëŠ¥
    """
    
    # Gemini Structured Output ìŠ¤í‚¤ë§ˆ
    EMAIL_DRAFT_SCHEMA = {
        "type": "object",
        "properties": {
            "subject": {"type": "string", "description": "ì´ë©”ì¼ ì œëª©"},
            "body": {"type": "string", "description": "ì´ë©”ì¼ ë³¸ë¬¸ (ì „ë¬¸ì ì´ê³  ì™„ì„±ëœ í˜•íƒœ)"},
            "recipients": {
                "type": "array",
                "items": {"type": "string"},
                "description": "ìˆ˜ì‹ ì ì´ë©”ì¼ ëª©ë¡"
            },
            "tone": {
                "type": "string",
                "enum": ["formal", "friendly", "urgent", "neutral"],
                "description": "ì´ë©”ì¼ ì–´ì¡°"
            }
        },
        "required": ["subject", "body", "recipients"]
    }
    
    DOCUMENT_DRAFT_SCHEMA = {
        "type": "object",
        "properties": {
            "title": {"type": "string"},
            "content": {"type": "string"},
            "sections": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "heading": {"type": "string"},
                        "body": {"type": "string"}
                    }
                }
            },
            "structure_diagram": {
                "type": "string",
                "description": "ë¬¸ì„œ êµ¬ì¡°ë¥¼ ASCII ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ í‘œí˜„"
            }
        },
        "required": ["title", "content"]
    }
    
    def __init__(self, gemini_service: Optional['GeminiService'] = None):
        """
        Args:
            gemini_service: GeminiService ì¸ìŠ¤í„´ìŠ¤ (ì—†ìœ¼ë©´ ìë™ ì´ˆê¸°í™”)
        """
        # Gemini Native ìš°ì„  ì‚¬ìš©
        if gemini_service:
            self.gemini_service = gemini_service
        elif HAS_GEMINI and USE_GEMINI_NATIVE and get_gemini_flash_service:
            self.gemini_service = get_gemini_flash_service()
        else:
            self.gemini_service = None
        
        # OpenAI í´ë°± (ë ˆê±°ì‹œ)
        self.openai_client = None
        if not self.gemini_service and HAS_OPENAI:
            api_key = os.environ.get("OPENAI_API_KEY")
            if api_key and AsyncOpenAI:
                self.openai_client = AsyncOpenAI(api_key=api_key)
        
        # Google Cloud DLP í´ë¼ì´ì–¸íŠ¸ (PII íƒì§€)
        self.dlp_client = None
        if HAS_CLOUD_DLP and USE_CLOUD_DLP and GCP_PROJECT_ID:
            try:
                self.dlp_client = dlp_v2.DlpServiceClient()
                logger.info("Google Cloud DLP client initialized for PII detection")
            except Exception as e:
                logger.warning(f"Failed to initialize Cloud DLP: {e}")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ LLM ë¡œê¹…
        if self.gemini_service:
            logger.info("DraftResultGenerator using Gemini Native")
        elif self.openai_client:
            logger.info("DraftResultGenerator using OpenAI fallback")
        else:
            logger.warning("DraftResultGenerator: No LLM available, using template-based generation")

    async def generate_detailed_draft(
        self,
        node_config: Dict[str, Any],
        input_data: Dict[str, Any],
        output_type: str
    ) -> Dict[str, Any]:
        """
        íŠ¹ì • ë…¸ë“œì˜ ìƒì„¸ ì¶œë ¥ ì´ˆì•ˆ ìƒì„±
        
        Args:
            node_config: ë…¸ë“œ ì„¤ì •
            input_data: ì…ë ¥ ë°ì´í„°
            output_type: ì¶œë ¥ íƒ€ì… (email, document, slack_message, api_call ë“±)
            
        Returns:
            ìƒì„±ëœ ì´ˆì•ˆ ë° ê²½ê³  ì •ë³´
        """
        generators = {
            "email": self._generate_email_draft,
            "document": self._generate_document_draft,
            "slack_message": self._generate_slack_draft,
            "notification": self._generate_notification_draft,
            "api_call": self._generate_api_draft,
            "sms": self._generate_sms_draft,
            "chart": self._generate_chart_draft,  # ë©€í‹°ëª¨ë‹¬
            "diagram": self._generate_diagram_draft,  # ë©€í‹°ëª¨ë‹¬
        }
        
        generator = generators.get(output_type, self._generate_generic_draft)
        return await generator(node_config, input_data)

    async def _generate_email_draft(
        self,
        node_config: Dict[str, Any],
        input_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ì´ë©”ì¼ ì´ˆì•ˆ ìƒì„± - Gemini Native
        
        Gemini 1.5 Flashë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ê°€ ì£¼ì…ëœ ì‹¤ì œì ì¸ ì´ë©”ì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.
        Structured Outputìœ¼ë¡œ íŒŒì‹± ì˜¤ë¥˜ ì—†ì´ ì•ˆì •ì ì¸ JSON ë°˜í™˜.
        """
        
        template = node_config.get('template', '')
        variables = input_data
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Gemini Native (ìš°ì„ )
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.gemini_service:
            try:
                prompt = f"""ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ì´ë©”ì¼ ì‘ì„± ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ í…œí”Œë¦¿ê³¼ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ë°œì†¡ë  ì´ë©”ì¼ ì´ˆì•ˆì„ ìƒì„±í•˜ì„¸ìš”.

## í…œí”Œë¦¿
{template}

## ë³€ìˆ˜ ë°ì´í„°
{json.dumps(variables, ensure_ascii=False, indent=2)}

## ìš”êµ¬ì‚¬í•­
1. í…œí”Œë¦¿ì˜ ë³€ìˆ˜ í”Œë ˆì´ìŠ¤í™€ë”({{{{variable}}}} ë˜ëŠ” ${{variable}})ë¥¼ ì‹¤ì œ ê°’ìœ¼ë¡œ ì¹˜í™˜í•˜ì„¸ìš”.
2. ì´ë©”ì¼ì€ ì „ë¬¸ì ì´ê³  ì™„ì„±ëœ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤.
3. í…œí”Œë¦¿ê³¼ ë™ì¼í•œ ì–¸ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
4. ìˆ˜ì‹ ì ëª©ë¡ì´ ì—†ìœ¼ë©´ ë³€ìˆ˜ì—ì„œ ì´ë©”ì¼ ì£¼ì†Œë¥¼ ì¶”ë¡ í•˜ì„¸ìš”.

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."""

                response = self.gemini_service.invoke_model(
                    user_prompt=prompt,
                    max_output_tokens=1000,
                    temperature=0.5,
                    response_schema=self.EMAIL_DRAFT_SCHEMA
                )
                
                response_text = response.get('text', '{}')
                draft = json.loads(response_text)
                
            except Exception as e:
                logger.warning(f"Gemini email draft generation failed: {e}")
                draft = self._generate_email_fallback(node_config, input_data)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # OpenAI í´ë°± (ë ˆê±°ì‹œ)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        elif self.openai_client:
            try:
                response = await self.openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{
                        "role": "system",
                        "content": """Generate a realistic email draft based on the template and variables. 
Output JSON with: subject, body, recipients (array).
The email should be professional and complete.
Respond in the same language as the template."""
                    }, {
                        "role": "user",
                        "content": f"Template: {template}\nVariables: {json.dumps(variables, ensure_ascii=False)}"
                    }],
                    response_format={"type": "json_object"},
                    max_tokens=1000,
                    temperature=0.5
                )
                draft = json.loads(response.choices[0].message.content)
            except Exception as e:
                logger.warning(f"OpenAI email draft generation failed: {e}")
                draft = self._generate_email_fallback(node_config, input_data)
        else:
            draft = self._generate_email_fallback(node_config, input_data)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ë³´ì•ˆ ê²€ì‚¬: PII íƒì§€ (Cloud DLP ë˜ëŠ” ì •ê·œí‘œí˜„ì‹)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        warnings = await self._check_pii_and_warnings(
            content=draft.get('body', '') + ' ' + draft.get('subject', ''),
            recipients=draft.get('recipients', []),
            content_type='email'
        )
        
        return {
            "type": "email",
            "draft": {
                "to": draft.get('recipients', []),
                "subject": draft.get('subject', ''),
                "body": draft.get('body', ''),
                "tone": draft.get('tone', 'neutral'),
                "is_preview": True
            },
            "warnings": warnings,
            "can_edit": True,
            "llm_provider": "gemini" if self.gemini_service else "openai" if self.openai_client else "template"
        }

    def _generate_email_fallback(
        self,
        node_config: Dict[str, Any],
        input_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì´ë©”ì¼ ì´ˆì•ˆ í´ë°± (LLM ì—†ì´)"""
        template = node_config.get('template', '')
        
        # ê°„ë‹¨í•œ ë³€ìˆ˜ ì¹˜í™˜
        body = template
        for key, value in input_data.items():
            body = body.replace(f'{{{{{key}}}}}', str(value))
            body = body.replace(f'${{{key}}}', str(value))
        
        recipients = node_config.get('recipients', [])
        if isinstance(recipients, str):
            recipients = [r.strip() for r in recipients.split(',')]
        
        # ì…ë ¥ ë°ì´í„°ì—ì„œ ìˆ˜ì‹ ì ì°¾ê¸°
        if not recipients:
            for key in ['email', 'to', 'recipient', 'customer_email']:
                if key in input_data:
                    recipients = [input_data[key]]
                    break
        
        return {
            "recipients": recipients,
            "subject": node_config.get('subject', f"[Preview] {node_config.get('label', 'Email')}"),
            "body": body or f"[Preview content based on template]\n\nInput data:\n{json.dumps(input_data, indent=2, ensure_ascii=False)}"
        }

    def _check_email_warnings(self, draft: Dict) -> List[str]:
        """ì´ë©”ì¼ ì´ˆì•ˆì˜ ì ì¬ì  ë¬¸ì œì  ì²´í¬"""
        warnings = []
        
        body = draft.get('body', '')
        subject = draft.get('subject', '')
        recipients = draft.get('recipients', [])
        
        # ë³¸ë¬¸ ê¸¸ì´ ì²´í¬
        if len(body) > 5000:
            warnings.append("âš ï¸ ì´ë©”ì¼ ë³¸ë¬¸ì´ ë§¤ìš° ê¹ë‹ˆë‹¤ (5000ì ì´ˆê³¼)")
        
        # ìˆ˜ì‹ ì ìˆ˜ ì²´í¬
        if len(recipients) > 10:
            warnings.append(f"ğŸ“§ ë‹¤ìˆ˜ì˜ ìˆ˜ì‹ ìì—ê²Œ ë°œì†¡ë©ë‹ˆë‹¤ ({len(recipients)}ëª…)")
        
        # ë¯¼ê° ì •ë³´ íŒ¨í„´ ì²´í¬
        patterns = [
            (r'\b\d{3}-\d{2}-\d{4}\b', "SSN íŒ¨í„´"),
            (r'\b\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}\b', "ì‹ ìš©ì¹´ë“œ ë²ˆí˜¸ íŒ¨í„´"),
            (r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', None),  # ì´ë©”ì¼ì€ ê²½ê³  ì•ˆ í•¨
        ]
        
        for pattern, desc in patterns:
            if desc and re.search(pattern, body):
                warnings.append(f"âš ï¸ ë¯¼ê°í•œ ê°œì¸ì •ë³´({desc})ê°€ í¬í•¨ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        
        # ì œëª© ì—†ìŒ ì²´í¬
        if not subject.strip():
            warnings.append("ğŸ“ ì´ë©”ì¼ ì œëª©ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤")
        
        # ë¹ˆ ë³¸ë¬¸ ì²´í¬
        if not body.strip():
            warnings.append("ğŸ“ ì´ë©”ì¼ ë³¸ë¬¸ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤")
        
        return warnings

    async def _generate_document_draft(
        self,
        node_config: Dict[str, Any],
        input_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ë¬¸ì„œ ì´ˆì•ˆ ìƒì„±"""
        
        template = node_config.get('template', '')
        doc_type = node_config.get('document_type', 'general')
        
        if HAS_OPENAI and self.api_key:
            try:
                if hasattr(self, 'client') and self.client:
                    # AsyncOpenAI í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© (v1.0+)
                    response = await self.client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[{
                            "role": "system",
                            "content": f"""Generate a {doc_type} document draft based on the template and data.
Output JSON with: title, content, sections (array of {{heading, body}}).
Make it realistic and complete."""
                        }, {
                            "role": "user",
                            "content": f"Template: {template}\nData: {json.dumps(input_data, ensure_ascii=False)}"
                        }],
                        response_format={"type": "json_object"},
                        max_tokens=1500
                    )
                else:
                    # êµ¬ë²„ì „ í˜¸í™˜ì„± ìœ ì§€
                    response = await openai.ChatCompletion.acreate(
                        model="gpt-4o-mini",
                        messages=[{
                            "role": "system",
                            "content": f"""Generate a {doc_type} document draft based on the template and data.
Output JSON with: title, content, sections (array of {{heading, body}}).
Make it realistic and complete."""
                        }, {
                            "role": "user",
                            "content": f"Template: {template}\nData: {json.dumps(input_data, ensure_ascii=False)}"
                        }],
                        response_format={"type": "json_object"},
                        max_tokens=1500
                    )
                
                draft = json.loads(response.choices[0].message.content)
            except Exception as e:
                logger.warning(f"LLM document draft generation failed: {e}")
                draft = {
                    "title": node_config.get('label', 'Document'),
                    "content": f"[Preview document content]\n\n{template}",
                    "sections": []
                }
        else:
            draft = {
                "title": node_config.get('label', 'Document'),
                "content": f"[Preview document content]\n\n{template}",
                "sections": []
            }
        
        return {
            "type": "document",
            "draft": draft,
            "warnings": [],
            "can_edit": True
        }

    async def _generate_slack_draft(
        self,
        node_config: Dict[str, Any],
        input_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Slack ë©”ì‹œì§€ ì´ˆì•ˆ ìƒì„±"""
        
        template = node_config.get('template', node_config.get('message', ''))
        channel = node_config.get('channel', '#general')
        
        # ë³€ìˆ˜ ì¹˜í™˜
        message = template
        for key, value in input_data.items():
            message = message.replace(f'{{{{{key}}}}}', str(value))
            message = message.replace(f'${{{key}}}', str(value))
        
        warnings = []
        if '@channel' in message or '@here' in message:
            warnings.append("ğŸ“¢ ì±„ë„ ì „ì²´ ì•Œë¦¼ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
        
        return {
            "type": "slack_message",
            "draft": {
                "channel": channel,
                "message": message or f"[Preview Slack message]\n\nData: {json.dumps(input_data, ensure_ascii=False)[:500]}",
                "is_preview": True
            },
            "warnings": warnings,
            "can_edit": True
        }

    async def _generate_notification_draft(
        self,
        node_config: Dict[str, Any],
        input_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì•Œë¦¼ ì´ˆì•ˆ ìƒì„±"""
        
        title = node_config.get('title', 'Notification')
        body_template = node_config.get('body', node_config.get('message', ''))
        
        # ë³€ìˆ˜ ì¹˜í™˜
        body = body_template
        for key, value in input_data.items():
            body = body.replace(f'{{{{{key}}}}}', str(value))
            body = body.replace(f'${{{key}}}', str(value))
        
        return {
            "type": "notification",
            "draft": {
                "title": title,
                "body": body or "[Preview notification content]",
                "is_preview": True
            },
            "warnings": [],
            "can_edit": True
        }

    async def _generate_api_draft(
        self,
        node_config: Dict[str, Any],
        input_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """API í˜¸ì¶œ ì´ˆì•ˆ ìƒì„±"""
        
        method = node_config.get('method', 'POST')
        url = node_config.get('url', node_config.get('endpoint', ''))
        headers = node_config.get('headers', {})
        body_template = node_config.get('body', {})
        
        # ë³€ìˆ˜ ì¹˜í™˜
        if isinstance(body_template, str):
            body = body_template
            for key, value in input_data.items():
                body = body.replace(f'{{{{{key}}}}}', str(value))
        else:
            body = json.dumps(body_template, indent=2, ensure_ascii=False)
        
        warnings = []
        
        # í”„ë¡œë•ì…˜ URL ê²½ê³ 
        if 'prod' in url.lower() or 'production' in url.lower():
            warnings.append("âš ï¸ í”„ë¡œë•ì…˜ í™˜ê²½ APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤")
        
        # ê²°ì œ ê´€ë ¨ ê²½ê³ 
        if any(kw in url.lower() for kw in ['payment', 'charge', 'billing', 'invoice']):
            warnings.append("ğŸ’³ ê²°ì œ ê´€ë ¨ APIì…ë‹ˆë‹¤. ì‹¤ì œ ì²­êµ¬ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        
        return {
            "type": "api_call",
            "draft": {
                "method": method,
                "url": url,
                "headers": {k: v if 'key' not in k.lower() and 'secret' not in k.lower() else '***' 
                          for k, v in headers.items()},
                "body": body,
                "is_preview": True
            },
            "warnings": warnings,
            "can_edit": False  # API í˜¸ì¶œì€ ì§ì ‘ ìˆ˜ì • ë¶ˆê°€
        }

    async def _generate_sms_draft(
        self,
        node_config: Dict[str, Any],
        input_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """SMS ì´ˆì•ˆ ìƒì„±"""
        
        template = node_config.get('template', node_config.get('message', ''))
        phone = node_config.get('phone', input_data.get('phone', input_data.get('phone_number', '')))
        
        # ë³€ìˆ˜ ì¹˜í™˜
        message = template
        for key, value in input_data.items():
            message = message.replace(f'{{{{{key}}}}}', str(value))
            message = message.replace(f'${{{key}}}', str(value))
        
        warnings = []
        if len(message) > 160:
            warnings.append(f"ğŸ“± ë©”ì‹œì§€ê°€ 160ìë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤ ({len(message)}ì). ì—¬ëŸ¬ SMSë¡œ ë¶„í• ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        
        return {
            "type": "sms",
            "draft": {
                "to": phone,
                "message": message or "[Preview SMS content]",
                "character_count": len(message),
                "is_preview": True
            },
            "warnings": warnings,
            "can_edit": True
        }

    async def _generate_generic_draft(
        self,
        node_config: Dict[str, Any],
        input_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì¼ë°˜ ë…¸ë“œ ì¶œë ¥ ì´ˆì•ˆ ìƒì„±"""
        
        return {
            "type": "generic",
            "draft": {
                "node_label": node_config.get('label', node_config.get('id', 'Unknown')),
                "description": f"ì´ ë…¸ë“œëŠ” ì…ë ¥ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
                "input_preview": json.dumps(input_data, indent=2, ensure_ascii=False)[:500],
                "is_preview": True
            },
            "warnings": [],
            "can_edit": False
        }

    async def generate_multiple_drafts(
        self,
        nodes: List[Dict[str, Any]],
        statebag: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        ì—¬ëŸ¬ ë…¸ë“œì˜ ì´ˆì•ˆì„ í•œ ë²ˆì— ìƒì„±
        
        Args:
            nodes: ë…¸ë“œ ì„¤ì • ëª©ë¡
            statebag: í˜„ì¬ ìƒíƒœ ë°ì´í„°
            
        Returns:
            ê° ë…¸ë“œì˜ ì´ˆì•ˆ ëª©ë¡
        """
        drafts = []
        
        for node in nodes:
            node_id = node.get('id')
            node_type = node.get('type', 'generic')
            node_config = node.get('data', node)
            
            # ë…¸ë“œ íƒ€ì…ì„ ì¶œë ¥ íƒ€ì…ìœ¼ë¡œ ë§¤í•‘
            output_type_map = {
                'email': 'email',
                'sendEmail': 'email',
                'slack': 'slack_message',
                'notification': 'notification',
                'apiCall': 'api_call',
                'http': 'api_call',
                'sms': 'sms',
                'document': 'document',
            }
            output_type = output_type_map.get(node_type, 'generic')
            
            try:
                draft = await self.generate_detailed_draft(
                    node_config=node_config,
                    input_data=statebag,
                    output_type=output_type
                )
                draft['node_id'] = node_id
                drafts.append(draft)
            except Exception as e:
                logger.error(f"Failed to generate draft for node {node_id}: {e}")
                drafts.append({
                    "node_id": node_id,
                    "type": "error",
                    "error": str(e)
                })
        
        return drafts
