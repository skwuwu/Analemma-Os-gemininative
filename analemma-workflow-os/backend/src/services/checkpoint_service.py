# -*- coding: utf-8 -*-
"""
Checkpoint Service

Time Machine ë””ë²„ê¹…ì„ ìœ„í•œ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.
ê¸°ì¡´ execution ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì²´í¬í¬ì¸íŠ¸ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

Features:
- ì‹¤í–‰ íƒ€ì„ë¼ì¸ ì¡°íšŒ (GSI ê¸°ë°˜ query ìµœì í™”)
- ì²´í¬í¬ì¸íŠ¸ ë¹„êµ (State Diff)
- S3 ì˜¤í”„ë¡œë”© ëŒ€ì‘ (ëŒ€ìš©ëŸ‰ ìƒíƒœ ë°ì´í„°)
- Semantic Checkpoint Filtering (ì¤‘ìš” ì˜ì‚¬ê²°ì • ì§€ì  í•„í„°ë§)
- Snapshot Recovery (ì²´í¬í¬ì¸íŠ¸ ê¸°ë°˜ ì¬ì‹¤í–‰)
"""

import os
import logging
import json
import asyncio
import uuid
import hashlib
from functools import partial
from typing import Dict, Any, List, Optional, Set
from datetime import datetime, timezone

import boto3
from botocore.exceptions import ClientError

try:
    from src.common.aws_clients import get_dynamodb_resource, get_s3_client
except ImportError:
    try:
        from common.aws_clients import get_dynamodb_resource, get_s3_client
    except ImportError:
        def get_dynamodb_resource():
            return boto3.resource('dynamodb')
        def get_s3_client():
            return boto3.client('s3')

logger = logging.getLogger(__name__)

# ============================================================================
# ìƒìˆ˜ ì •ì˜
# ============================================================================

# GSI ì´ë¦„ (notifications í…Œì´ë¸”ì— execution_idë¡œ ì¡°íšŒí•˜ê¸° ìœ„í•œ ì¸ë±ìŠ¤)
# ğŸš¨ [Critical Fix] template.yamlì˜ ì‹¤ì œ GSI ì´ë¦„ê³¼ ì¼ì¹˜ì‹œí‚´
EXECUTION_ID_GSI = os.environ.get('EXECUTION_ID_INDEX', 'ExecutionIdIndex')

# S3 ë²„í‚· (ëŒ€ìš©ëŸ‰ ìƒíƒœ ë°ì´í„° ì˜¤í”„ë¡œë”©ìš©)
STATE_BUCKET = os.environ.get('STATE_BUCKET', os.environ.get('SKELETON_S3_BUCKET', ''))

# ì¤‘ìš” ì´ë²¤íŠ¸ íƒ€ì… (Semantic Filteringìš©)
IMPORTANT_EVENT_TYPES: Set[str] = {
    'workflow_started',
    'workflow_completed',
    'workflow_failed',
    'llm_response_received',
    'human_input_received',
    'condition_evaluated',
    'loop_iteration_start',
    'error_caught',
    'retry_attempted',
    'state_modified',
}


class CheckpointService:
    """
    ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ ì„œë¹„ìŠ¤
    
    ê¸°ì¡´ execution ë° notification ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬
    Time Machine ë””ë²„ê¹…ì„ ìœ„í•œ ì²´í¬í¬ì¸íŠ¸ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
    
    Features:
    - GSI ê¸°ë°˜ queryë¡œ ì„±ëŠ¥ ìµœì í™” (scan ì‚¬ìš© ì•ˆ í•¨)
    - S3 ì˜¤í”„ë¡œë”©ëœ ëŒ€ìš©ëŸ‰ ìƒíƒœ ë°ì´í„° ìë™ ë¡œë“œ
    - Semantic Checkpoint Filtering (ì¤‘ìš” ì´ë²¤íŠ¸ë§Œ í•„í„°ë§)
    - Snapshot Recovery (ì²´í¬í¬ì¸íŠ¸ ê¸°ë°˜ ì¬ì‹¤í–‰)
    """
    
    def __init__(
        self,
        executions_table: Optional[str] = None,
        notifications_table: Optional[str] = None,
        state_bucket: Optional[str] = None
    ):
        """
        Args:
            executions_table: ì‹¤í–‰ í…Œì´ë¸” ì´ë¦„
            notifications_table: ì•Œë¦¼ í…Œì´ë¸” ì´ë¦„
            state_bucket: ìƒíƒœ ë°ì´í„° S3 ë²„í‚·
        """
        self.executions_table_name = executions_table or os.environ.get(
            'EXECUTION_TABLE', 'executions'
        )
        self.notifications_table_name = notifications_table or os.environ.get(
            'NOTIFICATION_TABLE', 'notifications'
        )
        self.state_bucket = state_bucket or STATE_BUCKET
        self._executions_table = None
        self._notifications_table = None
        self._s3_client = None
    
    @property
    def executions_table(self):
        """ì§€ì—° ì´ˆê¸°í™”ëœ ì‹¤í–‰ í…Œì´ë¸”"""
        if self._executions_table is None:
            dynamodb_resource = get_dynamodb_resource()
            self._executions_table = dynamodb_resource.Table(self.executions_table_name)
        return self._executions_table

    @property
    def notifications_table(self):
        """ì§€ì—° ì´ˆê¸°í™”ëœ ì•Œë¦¼ í…Œì´ë¸”"""
        if self._notifications_table is None:
            dynamodb_resource = get_dynamodb_resource()
            self._notifications_table = dynamodb_resource.Table(self.notifications_table_name)
        return self._notifications_table

    @property
    def s3_client(self):
        """ì§€ì—° ì´ˆê¸°í™”ëœ S3 í´ë¼ì´ì–¸íŠ¸"""
        if self._s3_client is None:
            self._s3_client = get_s3_client()
        return self._s3_client

    # =========================================================================
    # ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œ
    # =========================================================================

    def _generate_checkpoint_id(
        self,
        timestamp: str,
        notification_id: Optional[str] = None
    ) -> str:
        """
        ê³ ìœ í•œ ì²´í¬í¬ì¸íŠ¸ ID ìƒì„±
        
        ë™ì¼ ë°€ë¦¬ì´ˆ ë‚´ ì—¬ëŸ¬ ì´ë²¤íŠ¸ ë°œìƒ ì‹œ ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´
        notification_id ë˜ëŠ” UUIDë¥¼ ê²°í•©í•©ë‹ˆë‹¤.
        
        Args:
            timestamp: ì´ë²¤íŠ¸ íƒ€ì„ìŠ¤íƒ¬í”„
            notification_id: ì•Œë¦¼ ê³ ìœ  ID (ìˆëŠ” ê²½ìš°)
            
        Returns:
            ê³ ìœ í•œ ì²´í¬í¬ì¸íŠ¸ ID
        """
        if notification_id:
            # notification_idê°€ ìˆìœ¼ë©´ í•´ì‹œí•˜ì—¬ ì‚¬ìš©
            hash_suffix = hashlib.sha256(notification_id.encode()).hexdigest()[:8]
            return f"cp_{timestamp}_{hash_suffix}"
        else:
            # ì—†ìœ¼ë©´ UUID ì‚¬ìš©
            return f"cp_{timestamp}_{uuid.uuid4().hex[:8]}"

    async def _load_state_from_s3(self, s3_path: str) -> Dict[str, Any]:
        """
        S3ì—ì„œ ì˜¤í”„ë¡œë”©ëœ ìƒíƒœ ë°ì´í„° ë¡œë“œ
        
        Args:
            s3_path: S3 ê²½ë¡œ (s3://bucket/key ë˜ëŠ” keyë§Œ)
            
        Returns:
            ìƒíƒœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        try:
            # s3:// ì ‘ë‘ì‚¬ ì²˜ë¦¬
            if s3_path.startswith('s3://'):
                parts = s3_path[5:].split('/', 1)
                bucket = parts[0]
                key = parts[1] if len(parts) > 1 else ''
            else:
                bucket = self.state_bucket
                key = s3_path
            
            if not bucket:
                logger.warning(f"No S3 bucket configured for state loading")
                return {}
            
            get_func = partial(
                self.s3_client.get_object,
                Bucket=bucket,
                Key=key
            )
            response = await asyncio.get_event_loop().run_in_executor(None, get_func)
            body = response['Body'].read().decode('utf-8')
            return json.loads(body)
            
        except ClientError as e:
            logger.error(f"Failed to load state from S3: {e}")
            return {}
        except json.JSONDecodeError as e:
            logger.error(f"Invalid JSON in S3 state data: {e}")
            return {}

    def _is_important_checkpoint(self, event_type: str, payload: Dict[str, Any]) -> bool:
        """
        ì¤‘ìš”í•œ ì²´í¬í¬ì¸íŠ¸ì¸ì§€ íŒë‹¨ (Semantic Filtering)
        
        Args:
            event_type: ì´ë²¤íŠ¸ íƒ€ì…
            payload: ì´ë²¤íŠ¸ í˜ì´ë¡œë“œ
            
        Returns:
            ì¤‘ìš” ì²´í¬í¬ì¸íŠ¸ ì—¬ë¶€
        """
        # ëª…ì‹œì ìœ¼ë¡œ ì¤‘ìš”í•œ ì´ë²¤íŠ¸ íƒ€ì…
        if event_type in IMPORTANT_EVENT_TYPES:
            return True
        
        # ìƒíƒœ ë³€ê²½ì´ ìˆëŠ” ê²½ìš°
        if payload.get('state_modified') or payload.get('step_function_state'):
            return True
        
        # ì—ëŸ¬ ë˜ëŠ” ê²½ê³ ê°€ ìˆëŠ” ê²½ìš°
        status = payload.get('status', '').lower()
        if status in {'error', 'failed', 'warning', 'timeout'}:
            return True
        
        # LLM ê´€ë ¨ ì´ë²¤íŠ¸
        if 'llm' in event_type.lower() or 'model' in event_type.lower():
            return True
        
        return False

    async def get_execution_timeline(
        self,
        thread_id: str,
        include_state: bool = True,
        only_important: bool = False
    ) -> List[Dict[str, Any]]:
        """
        ì‹¤í–‰ íƒ€ì„ë¼ì¸ ì¡°íšŒ
        
        GSIë¥¼ í™œìš©í•œ queryë¡œ ì„±ëŠ¥ ìµœì í™”.
        ê¸°ì¡´ notification ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ íƒ€ì„ë¼ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            thread_id: ì‹¤í–‰ ìŠ¤ë ˆë“œ ID (execution_id)
            include_state: ìƒíƒœ ì •ë³´ í¬í•¨ ì—¬ë¶€
            only_important: ì¤‘ìš” ì²´í¬í¬ì¸íŠ¸ë§Œ í•„í„°ë§ (Semantic Filtering)
            
        Returns:
            íƒ€ì„ë¼ì¸ í•­ëª© ëª©ë¡
        """
        try:
            from boto3.dynamodb.conditions import Key
            
            # GSIë¥¼ ì‚¬ìš©í•œ query (scan ëŒ€ì‹ )
            # execution_idë¥¼ íŒŒí‹°ì…˜ í‚¤ë¡œ í•˜ëŠ” GSI í™œìš©
            query_func = partial(
                self.notifications_table.query,
                IndexName=EXECUTION_ID_GSI,
                KeyConditionExpression=Key('execution_id').eq(thread_id),
                ScanIndexForward=True,  # ì‹œê°„ìˆœ ì •ë ¬
                Limit=500
            )
            
            try:
                response = await asyncio.get_event_loop().run_in_executor(None, query_func)
            except ClientError as e:
                # GSIê°€ ì—†ëŠ” ê²½ìš° fallback (ê°œë°œ í™˜ê²½ìš©)
                if e.response['Error']['Code'] == 'ValidationException':
                    logger.warning(f"GSI '{EXECUTION_ID_GSI}' not found, falling back to scan")
                    response = await self._fallback_scan(thread_id)
                else:
                    raise
            
            items = response.get('Items', [])
            timeline = []
            
            for item in items:
                notification = item.get('notification', {})
                if isinstance(notification, str):
                    try:
                        notification = json.loads(notification)
                    except json.JSONDecodeError:
                        notification = {}
                
                payload = notification.get('payload', {})
                event_type = notification.get('type', 'execution_event')
                notification_id = item.get('notification_id') or item.get('id', '')
                timestamp = item.get('timestamp', '')
                
                # Semantic Filtering
                if only_important and not self._is_important_checkpoint(event_type, payload):
                    continue
                
                timeline_item = {
                    "checkpoint_id": self._generate_checkpoint_id(timestamp, notification_id),
                    "notification_id": notification_id,
                    "timestamp": timestamp,
                    "event_type": event_type,
                    "node_id": payload.get('current_step_label', payload.get('node_id', '')),
                    "status": payload.get('status', ''),
                    "message": payload.get('message', ''),
                    "is_important": self._is_important_checkpoint(event_type, payload),
                }
                
                # ìƒíƒœ ë°ì´í„° ë¡œë“œ
                if include_state:
                    state_data = payload.get('step_function_state', {})
                    s3_path = payload.get('state_s3_path')
                    
                    # S3 ì˜¤í”„ë¡œë”©ëœ ê²½ìš° ë¡œë“œ
                    if s3_path and not state_data:
                        state_data = await self._load_state_from_s3(s3_path)
                    
                    timeline_item['state'] = state_data
                    timeline_item['state_s3_path'] = s3_path
                
                timeline.append(timeline_item)
            
            # ì‹œê°„ìˆœ ì •ë ¬ (ì´ë¯¸ ì •ë ¬ë˜ì–´ ìˆì§€ë§Œ ì•ˆì „ì„ ìœ„í•´)
            timeline.sort(key=lambda x: x.get('timestamp', ''))
            
            return timeline
            
        except ClientError as e:
            logger.error(f"Failed to get execution timeline: {e}")
            return []

    async def _fallback_scan(self, thread_id: str) -> Dict[str, Any]:
        """
        GSIê°€ ì—†ëŠ” ê²½ìš° fallback scan (ê°œë°œ í™˜ê²½ìš©)
        
        WARNING: í”„ë¡œë•ì…˜ì—ì„œëŠ” GSI ì‚¬ìš© í•„ìˆ˜
        """
        from boto3.dynamodb.conditions import Attr
        
        logger.warning("Using scan fallback - configure GSI for production!")
        
        scan_func = partial(
            self.notifications_table.scan,
            FilterExpression=Attr('execution_id').eq(thread_id),
            Limit=100
        )
        return await asyncio.get_event_loop().run_in_executor(None, scan_func)

    async def list_checkpoints(
        self,
        thread_id: str,
        limit: int = 50,
        only_important: bool = False
    ) -> List[Dict[str, Any]]:
        """
        ì²´í¬í¬ì¸íŠ¸ ëª©ë¡ ì¡°íšŒ
        
        Args:
            thread_id: ì‹¤í–‰ ìŠ¤ë ˆë“œ ID
            limit: ìµœëŒ€ ì¡°íšŒ ê°œìˆ˜
            only_important: ì¤‘ìš” ì²´í¬í¬ì¸íŠ¸ë§Œ í•„í„°ë§
            
        Returns:
            ì²´í¬í¬ì¸íŠ¸ ëª©ë¡
        """
        try:
            # íƒ€ì„ë¼ì¸ì—ì„œ ì²´í¬í¬ì¸íŠ¸ ì¶”ì¶œ
            timeline = await self.get_execution_timeline(
                thread_id,
                include_state=False,
                only_important=only_important
            )
            
            checkpoints = []
            for item in timeline[:limit]:
                checkpoint = {
                    "checkpoint_id": item.get('checkpoint_id'),
                    "thread_id": thread_id,
                    "notification_id": item.get('notification_id'),
                    "created_at": item.get('timestamp'),
                    "node_id": item.get('node_id'),
                    "event_type": item.get('event_type'),
                    "status": item.get('status'),
                    "message": item.get('message', ''),
                    "is_important": item.get('is_important', False),
                    "has_state": item.get('state_s3_path') is not None or 'state' in item,
                }
                checkpoints.append(checkpoint)
            
            return checkpoints
            
        except Exception as e:
            logger.error(f"Failed to list checkpoints: {e}")
            return []

    async def get_checkpoint_detail(
        self,
        thread_id: str,
        checkpoint_id: str
    ) -> Optional[Dict[str, Any]]:
        """
        ì²´í¬í¬ì¸íŠ¸ ìƒì„¸ ì¡°íšŒ
        
        S3 ì˜¤í”„ë¡œë”©ëœ ìƒíƒœ ë°ì´í„°ë„ ìë™ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.
        
        Args:
            thread_id: ì‹¤í–‰ ìŠ¤ë ˆë“œ ID
            checkpoint_id: ì²´í¬í¬ì¸íŠ¸ ID
            
        Returns:
            ì²´í¬í¬ì¸íŠ¸ ìƒì„¸ ì •ë³´
        """
        try:
            # íƒ€ì„ë¼ì¸ì—ì„œ í•´ë‹¹ ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°
            timeline = await self.get_execution_timeline(thread_id, include_state=True)
            
            for item in timeline:
                if item.get('checkpoint_id') == checkpoint_id:
                    # ìƒíƒœ ë°ì´í„° í™•ë³´
                    state_snapshot = item.get('state', {})
                    s3_path = item.get('state_s3_path')
                    
                    # S3ì—ì„œ ìƒíƒœê°€ ì˜¤í”„ë¡œë”©ëœ ê²½ìš° ë¡œë“œ
                    if s3_path and not state_snapshot:
                        state_snapshot = await self._load_state_from_s3(s3_path)
                    
                    checkpoint_detail = {
                        "checkpoint_id": checkpoint_id,
                        "thread_id": thread_id,
                        "notification_id": item.get('notification_id'),
                        "created_at": item.get('timestamp'),
                        "node_id": item.get('node_id'),
                        "event_type": item.get('event_type'),
                        "status": item.get('status'),
                        "message": item.get('message', ''),
                        "is_important": item.get('is_important', False),
                        "state_snapshot": state_snapshot,
                        "state_s3_path": s3_path,
                        "execution_context": {
                            "workflow_id": state_snapshot.get('workflow_id'),
                            "owner_id": state_snapshot.get('owner_id'),
                            "started_at": state_snapshot.get('started_at'),
                        },
                        "metadata": {
                            "state_size_bytes": len(json.dumps(state_snapshot)) if state_snapshot else 0,
                            "is_s3_offloaded": bool(s3_path),
                        },
                    }
                    return checkpoint_detail
            
            return None
            
        except Exception as e:
            logger.error(f"Failed to get checkpoint detail: {e}")
            return None

    async def compare_checkpoints(
        self,
        thread_id: str,
        checkpoint_id_a: str,
        checkpoint_id_b: str
    ) -> Dict[str, Any]:
        """
        ì²´í¬í¬ì¸íŠ¸ ë¹„êµ (State Diff)
        
        ë‘ ì²´í¬í¬ì¸íŠ¸ ê°„ì˜ ìƒíƒœ ë³€í™”ë¥¼ ë¶„ì„í•˜ì—¬
        UIì—ì„œ ì‹œê°í™”í•˜ê¸° ì í•©í•œ diff í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Args:
            thread_id: ì‹¤í–‰ ìŠ¤ë ˆë“œ ID
            checkpoint_id_a: ì²« ë²ˆì§¸ ì²´í¬í¬ì¸íŠ¸ ID (ì´ì „)
            checkpoint_id_b: ë‘ ë²ˆì§¸ ì²´í¬í¬ì¸íŠ¸ ID (ì´í›„)
            
        Returns:
            ë¹„êµ ê²°ê³¼ (added, removed, modified êµ¬ë¶„)
        """
        try:
            # ë‘ ì²´í¬í¬ì¸íŠ¸ ì¡°íšŒ (S3 ì˜¤í”„ë¡œë”© ìë™ ì²˜ë¦¬)
            checkpoint_a = await self.get_checkpoint_detail(thread_id, checkpoint_id_a)
            checkpoint_b = await self.get_checkpoint_detail(thread_id, checkpoint_id_b)
            
            if not checkpoint_a or not checkpoint_b:
                raise ValueError("One or both checkpoints not found")
            
            # ìƒíƒœ ë¹„êµ
            state_a = checkpoint_a.get('state_snapshot', {})
            state_b = checkpoint_b.get('state_snapshot', {})
            
            # ì¬ê·€ì  diff ê³„ì‚°
            diff_result = self._compute_deep_diff(state_a, state_b)
            
            comparison = {
                "checkpoint_a": {
                    "id": checkpoint_id_a,
                    "timestamp": checkpoint_a.get('created_at'),
                    "node_id": checkpoint_a.get('node_id'),
                },
                "checkpoint_b": {
                    "id": checkpoint_id_b,
                    "timestamp": checkpoint_b.get('created_at'),
                    "node_id": checkpoint_b.get('node_id'),
                },
                "summary": {
                    "added_count": len(diff_result['added']),
                    "removed_count": len(diff_result['removed']),
                    "modified_count": len(diff_result['modified']),
                },
                "state_diff": diff_result,
            }
            
            return comparison
            
        except Exception as e:
            logger.error(f"Failed to compare checkpoints: {e}")
            raise

    def _compute_deep_diff(
        self,
        state_a: Dict[str, Any],
        state_b: Dict[str, Any],
        path: str = ""
    ) -> Dict[str, Any]:
        """
        ì¬ê·€ì  ìƒíƒœ diff ê³„ì‚°
        
        Args:
            state_a: ì´ì „ ìƒíƒœ
            state_b: ì´í›„ ìƒíƒœ
            path: í˜„ì¬ ê²½ë¡œ (ì¤‘ì²©ëœ í‚¤ í‘œì‹œìš©)
            
        Returns:
            {added: {...}, removed: {...}, modified: {...}}
        """
        added = {}
        removed = {}
        modified = {}
        
        keys_a = set(state_a.keys()) if isinstance(state_a, dict) else set()
        keys_b = set(state_b.keys()) if isinstance(state_b, dict) else set()
        
        # ì¶”ê°€ëœ í‚¤
        for key in keys_b - keys_a:
            full_path = f"{path}.{key}" if path else key
            added[full_path] = state_b[key]
        
        # ì œê±°ëœ í‚¤
        for key in keys_a - keys_b:
            full_path = f"{path}.{key}" if path else key
            removed[full_path] = state_a[key]
        
        # ìˆ˜ì •ëœ í‚¤ (ì¬ê·€ì  ë¹„êµ)
        for key in keys_a & keys_b:
            full_path = f"{path}.{key}" if path else key
            val_a = state_a[key]
            val_b = state_b[key]
            
            if val_a != val_b:
                # ë‘˜ ë‹¤ ë”•ì…”ë„ˆë¦¬ë©´ ì¬ê·€ì ìœ¼ë¡œ ë¹„êµ
                if isinstance(val_a, dict) and isinstance(val_b, dict):
                    nested_diff = self._compute_deep_diff(val_a, val_b, full_path)
                    added.update(nested_diff['added'])
                    removed.update(nested_diff['removed'])
                    modified.update(nested_diff['modified'])
                else:
                    modified[full_path] = {
                        "from": val_a,
                        "to": val_b,
                        "type_changed": type(val_a).__name__ != type(val_b).__name__
                    }
        
        return {
            "added": added,
            "removed": removed,
            "modified": modified,
        }

    # =========================================================================
    # Snapshot Recovery (ì²´í¬í¬ì¸íŠ¸ ê¸°ë°˜ ì¬ì‹¤í–‰)
    # =========================================================================

    async def restore_from_checkpoint(
        self,
        thread_id: str,
        checkpoint_id: str,
        workflow_id: Optional[str] = None,
        owner_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì›Œí¬í”Œë¡œìš° ì¬ì‹¤í–‰
        
        íŠ¹ì • ì²´í¬í¬ì¸íŠ¸ì˜ ìƒíƒœë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ì„ íŠ¸ë¦¬ê±°í•©ë‹ˆë‹¤.
        
        Args:
            thread_id: ì›ë³¸ ì‹¤í–‰ ìŠ¤ë ˆë“œ ID
            checkpoint_id: ë³µì›í•  ì²´í¬í¬ì¸íŠ¸ ID
            workflow_id: ì›Œí¬í”Œë¡œìš° ID (ì—†ìœ¼ë©´ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¶”ì¶œ)
            owner_id: ì†Œìœ ì ID (ì—†ìœ¼ë©´ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¶”ì¶œ)
            
        Returns:
            ìƒˆ ì‹¤í–‰ ì •ë³´ {new_execution_id, status, restored_from}
        """
        try:
            # ì²´í¬í¬ì¸íŠ¸ ìƒì„¸ ì¡°íšŒ
            checkpoint = await self.get_checkpoint_detail(thread_id, checkpoint_id)
            if not checkpoint:
                raise ValueError(f"Checkpoint not found: {checkpoint_id}")
            
            state_snapshot = checkpoint.get('state_snapshot', {})
            if not state_snapshot:
                raise ValueError(f"No state snapshot available for checkpoint: {checkpoint_id}")
            
            # ì›Œí¬í”Œë¡œìš°/ì†Œìœ ì ì •ë³´ ì¶”ì¶œ
            exec_context = checkpoint.get('execution_context', {})
            wf_id = workflow_id or exec_context.get('workflow_id') or state_snapshot.get('workflow_id')
            o_id = owner_id or exec_context.get('owner_id') or state_snapshot.get('owner_id')
            
            if not wf_id:
                raise ValueError("Cannot determine workflow_id for restoration")
            
            # ìƒˆ ì‹¤í–‰ ID ìƒì„±
            new_execution_id = f"restored_{uuid.uuid4().hex[:12]}"
            
            # ë³µì›ëœ ìƒíƒœ ì¤€ë¹„
            restored_state = {
                **state_snapshot,
                "execution_id": new_execution_id,
                "restored_from": {
                    "original_execution_id": thread_id,
                    "checkpoint_id": checkpoint_id,
                    "checkpoint_timestamp": checkpoint.get('created_at'),
                    "restored_at": datetime.now(timezone.utc).isoformat(),
                },
                "is_restored": True,
            }
            
            # Step Functions ì‹¤í–‰ íŠ¸ë¦¬ê±°
            new_execution_arn = await self._trigger_step_function_execution(
                workflow_id=wf_id,
                execution_id=new_execution_id,
                initial_state=restored_state,
                owner_id=o_id
            )
            
            return {
                "status": "success",
                "new_execution_id": new_execution_id,
                "new_execution_arn": new_execution_arn,
                "workflow_id": wf_id,
                "owner_id": o_id,
                "restored_from": {
                    "original_execution_id": thread_id,
                    "checkpoint_id": checkpoint_id,
                    "checkpoint_timestamp": checkpoint.get('created_at'),
                },
                "message": f"Workflow restored from checkpoint {checkpoint_id}",
            }
            
        except Exception as e:
            logger.error(f"Failed to restore from checkpoint: {e}")
            return {
                "status": "error",
                "error": str(e),
                "restored_from": {
                    "original_execution_id": thread_id,
                    "checkpoint_id": checkpoint_id,
                },
            }

    async def _trigger_step_function_execution(
        self,
        workflow_id: str,
        execution_id: str,
        initial_state: Dict[str, Any],
        owner_id: Optional[str] = None
    ) -> Optional[str]:
        """
        Step Functions ì‹¤í–‰ íŠ¸ë¦¬ê±°
        
        Args:
            workflow_id: ì›Œí¬í”Œë¡œìš° ID
            execution_id: ìƒˆ ì‹¤í–‰ ID
            initial_state: ì´ˆê¸° ìƒíƒœ
            owner_id: ì†Œìœ ì ID
            
        Returns:
            ìƒˆ ì‹¤í–‰ ARN
        """
        try:
            sfn_client = boto3.client('stepfunctions')
            
            # State Machine ARN ì¡°íšŒ (workflow_idë¡œ ë§¤í•‘)
            state_machine_arn = os.environ.get(
                'STATE_MACHINE_ARN',
                f"arn:aws:states:{os.environ.get('AWS_REGION', 'us-east-1')}:"
                f"{os.environ.get('AWS_ACCOUNT_ID', '')}:stateMachine:{workflow_id}"
            )
            
            start_func = partial(
                sfn_client.start_execution,
                stateMachineArn=state_machine_arn,
                name=execution_id,
                input=json.dumps(initial_state, ensure_ascii=False, default=str)
            )
            
            response = await asyncio.get_event_loop().run_in_executor(None, start_func)
            
            return response.get('executionArn')
            
        except ClientError as e:
            logger.error(f"Failed to trigger Step Functions execution: {e}")
            raise


# ============================================================================
# Singleton ì¸ìŠ¤í„´ìŠ¤
# ============================================================================

_checkpoint_service_instance: Optional[CheckpointService] = None


def get_checkpoint_service() -> CheckpointService:
    """CheckpointService ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _checkpoint_service_instance
    if _checkpoint_service_instance is None:
        _checkpoint_service_instance = CheckpointService()
    return _checkpoint_service_instance