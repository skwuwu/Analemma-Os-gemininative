# backend/workflow_builder.py
# Dynamic Workflow Builder for runtime graph construction from src.JSON config
# Replaces S3 pickle loading with on-demand LangGraph compilation
# Extended with Sub-graph Abstraction support for hierarchical workflows
#
# [v2.0 Production Hardening]
# - Template rendering safety with missing variable detection
# - MAX_SUBGRAPH_DEPTH limit to prevent stack overflow
# - Graph completeness validation (leaf nodes â†’ END)
# - Lightweight state schema for subgraphs (memory optimization)

import logging
import json
import hashlib
import os
from typing import Dict, Any, Callable, Optional, List, Set, TypedDict, Annotated
from langgraph.graph import StateGraph, END

logger = logging.getLogger(__name__)

# Import existing node functions and state schema from src.handlers.core.main.py
from src.handlers.core.main import NODE_REGISTRY, WorkflowState

# ============================================================================
# [Critical Fix #2] ì¬ê·€ ê¹Šì´ ì œí•œ ìƒìˆ˜
# ============================================================================
MAX_SUBGRAPH_DEPTH = int(os.environ.get("MAX_SUBGRAPH_DEPTH", "10"))


# ============================================================================
# [Critical Fix #1] í…œí”Œë¦¿ ë Œë”ë§ ì·¨ì•½ì„± í•´ê²°
# ============================================================================
class TemplateRenderingError(Exception):
    """í…œí”Œë¦¿ ë Œë”ë§ ì¤‘ í•„ìˆ˜ ë³€ìˆ˜ ëˆ„ë½ ì‹œ ë°œìƒí•˜ëŠ” ì˜ˆì™¸"""
    def __init__(self, missing_vars: List[str], template: str):
        self.missing_vars = missing_vars
        self.template = template
        super().__init__(
            f"Template rendering failed: missing required variables {missing_vars} "
            f"in template '{template[:100]}...'"
        )


# ============================================================================
# [Performance Optimization] ì„œë¸Œê·¸ë˜í”„ ì „ìš© ê²½ëŸ‰ ìƒíƒœ ìŠ¤í‚¤ë§ˆ
# ============================================================================
class LightweightSubgraphState(TypedDict, total=False):
    """
    ì„œë¸Œê·¸ë˜í”„ ì‹¤í–‰ì„ ìœ„í•œ ê²½ëŸ‰ ìƒíƒœ ìŠ¤í‚¤ë§ˆ.
    ë¶€ëª¨ ìƒíƒœì˜ ëª¨ë“  í•„ë“œë¥¼ ìƒì†ë°›ì§€ ì•Šê³  í•„ìš”í•œ ê²ƒë§Œ ì „ë‹¬í•˜ì—¬
    ì¤‘ì²© ì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
    """
    # í•„ìˆ˜ ì»¨í…ìŠ¤íŠ¸
    user_api_keys: Dict[str, str]
    step_history: List[str]
    # ì‹¤í–‰ ê²°ê³¼
    result: Any
    # ìŠ¤í‚¬ í†µí•© (í•„ìš” ì‹œ)
    skill_execution_log: List[Dict[str, Any]]


# ì„œë¸Œê·¸ë˜í”„ì—ì„œ ë¶€ëª¨ë¡œ ì „íŒŒí•´ì•¼ í•˜ëŠ” ëˆ„ì  í•„ë“œ ëª©ë¡
SUBGRAPH_ACCUMULATOR_FIELDS = frozenset({"step_history", "skill_execution_log"})
# ì„œë¸Œê·¸ë˜í”„ ì…ë ¥ ì‹œ ìë™ ìƒì†ë˜ëŠ” ê³µí†µ í•„ë“œ
SUBGRAPH_INHERIT_FIELDS = frozenset({"user_api_keys", "step_history", "skill_execution_log"})


def _render_template(
    template: Any, 
    state: Dict[str, Any],
    strict_mode: bool = False,
    required_vars: Optional[Set[str]] = None
) -> Any:
    """
    Render {{variable}} templates against the provided state.
    
    [v2.0 Production Hardening]
    - strict_mode=True: ë³€ìˆ˜ ëˆ„ë½ ì‹œ TemplateRenderingError ë°œìƒ
    - strict_mode=False: ë³€ìˆ˜ ëˆ„ë½ ì‹œ {{MISSING:var}} í”Œë ˆì´ìŠ¤í™€ë” ë°˜í™˜ (ë””ë²„ê¹…ìš©)
    - required_vars: í•„ìˆ˜ ë³€ìˆ˜ ì§‘í•© - ì´ ë³€ìˆ˜ë“¤ì´ ëˆ„ë½ë˜ë©´ í•­ìƒ ì—ëŸ¬
    - json.dumps ì‹¤íŒ¨ ì‹œ ì•ˆì „í•˜ê²Œ str() í´ë°±
    
    Args:
        template: ë Œë”ë§í•  í…œí”Œë¦¿ (str, dict, list, ë˜ëŠ” ê¸°íƒ€)
        state: ë³€ìˆ˜ ê°’ì„ ê°€ì ¸ì˜¬ ìƒíƒœ ë”•ì…”ë„ˆë¦¬
        strict_mode: Trueë©´ ëˆ„ë½ ë³€ìˆ˜ ì‹œ ì˜ˆì™¸ ë°œìƒ
        required_vars: í•„ìˆ˜ ë³€ìˆ˜ ì§‘í•© (ëˆ„ë½ ì‹œ í•­ìƒ ì˜ˆì™¸)
        
    Returns:
        ë Œë”ë§ëœ í…œí”Œë¦¿
        
    Raises:
        TemplateRenderingError: strict_modeì´ê±°ë‚˜ required_vars ëˆ„ë½ ì‹œ
    """
    import re
    
    if template is None:
        return None
    
    if required_vars is None:
        required_vars = set()
    
    missing_vars: List[str] = []
    
    if isinstance(template, str):
        def _repl(m: re.Match) -> str:
            key = m.group(1).strip()
            parts = key.split('.')
            cur: Any = state
            
            for p in parts:
                if isinstance(cur, dict) and p in cur:
                    cur = cur[p]
                else:
                    # ë³€ìˆ˜ë¥¼ ì°¾ì§€ ëª»í•¨
                    missing_vars.append(key)
                    
                    # í•„ìˆ˜ ë³€ìˆ˜ì´ê±°ë‚˜ strict_modeë©´ ë‚˜ì¤‘ì— ì˜ˆì™¸ ë°œìƒ
                    if key in required_vars or strict_mode:
                        return f"{{{{MISSING:{key}}}}}"
                    
                    # ë””ë²„ê¹…ì„ ìœ„í•œ í”Œë ˆì´ìŠ¤í™€ë” ë°˜í™˜
                    logger.warning(f"Template variable not found: {key} (returning placeholder)")
                    return f"{{{{MISSING:{key}}}}}"
            
            # ê°’ì„ ì°¾ìŒ - íƒ€ì…ì— ë”°ë¼ ë³€í™˜
            if isinstance(cur, (dict, list)):
                try:
                    return json.dumps(cur, ensure_ascii=False)
                except (TypeError, ValueError) as e:
                    logger.warning(f"json.dumps failed for key '{key}': {e}, using str()")
                    return str(cur)
            
            return str(cur) if cur is not None else ""
        
        rendered = re.sub(r"\{\{\s*([\w\.]+)\s*\}\}", _repl, template)
        
        # í•„ìˆ˜ ë³€ìˆ˜ ëˆ„ë½ ì²´í¬
        required_missing = set(missing_vars) & required_vars
        if required_missing:
            raise TemplateRenderingError(list(required_missing), template)
        
        # strict_modeì—ì„œ ëˆ„ë½ ë³€ìˆ˜ ìˆìœ¼ë©´ ì˜ˆì™¸
        if strict_mode and missing_vars:
            raise TemplateRenderingError(missing_vars, template)
        
        return rendered
    
    if isinstance(template, dict):
        return {k: _render_template(v, state, strict_mode, required_vars) for k, v in template.items()}
    
    if isinstance(template, list):
        return [_render_template(v, state, strict_mode, required_vars) for v in template]
    
    return template


class DynamicWorkflowBuilder:
    """
    Builds LangGraph workflows dynamically from src.JSON configuration at runtime.
    This replaces the need for pre-compiled S3 pickle files.
    
    Extended with Sub-graph Abstraction:
    - Supports 'subgraph' node type
    - Recursively compiles nested sub-graphs
    - Handles state mapping between parent and child graphs
    """

    def __init__(
        self, 
        config: Dict[str, Any], 
        parent_path: List[str] = None,
        use_lightweight_state: bool = False
    ):
        """
        Initialize builder with workflow configuration.

        Args:
            config: Workflow configuration dict with 'nodes', 'edges', and optionally 'subgraphs'
            parent_path: Path from src.root (for nested subgraphs), e.g., ["root", "group1"]
            use_lightweight_state: Trueë©´ LightweightSubgraphState ì‚¬ìš© (ë©”ëª¨ë¦¬ ìµœì í™”)
            
        Raises:
            ValueError: ì„œë¸Œê·¸ë˜í”„ ê¹Šì´ê°€ MAX_SUBGRAPH_DEPTH ì´ˆê³¼ ì‹œ
        """
        self.config = config
        self.parent_path = parent_path or ["root"]
        self.use_lightweight_state = use_lightweight_state
        
        # [Critical Fix #2] ì¬ê·€ ê¹Šì´ ì œí•œ ê²€ì¦
        current_depth = len(self.parent_path)
        if current_depth > MAX_SUBGRAPH_DEPTH:
            raise ValueError(
                f"Subgraph nesting depth ({current_depth}) exceeds maximum allowed "
                f"({MAX_SUBGRAPH_DEPTH}). Path: {' > '.join(self.parent_path)}. "
                f"Consider flattening your workflow structure or increasing MAX_SUBGRAPH_DEPTH."
            )
        
        # Cache for compiled subgraphs (avoid recompilation)
        self._subgraph_cache: Dict[str, Any] = {}
        
        # [Performance Optimization] ì„œë¸Œê·¸ë˜í”„ëŠ” ê²½ëŸ‰ ìƒíƒœ ìŠ¤í‚¤ë§ˆ ì‚¬ìš©
        if use_lightweight_state:
            self.graph = StateGraph(LightweightSubgraphState)
            logger.debug(f"Using LightweightSubgraphState for: {' > '.join(self.parent_path)}")
        else:
            self.graph = StateGraph(WorkflowState)
    
    def _get_subgraph_definition(self, node_def: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Resolve subgraph definition from src.node config.
        
        Supports:
        - subgraph_ref: Reference to subgraphs dict
        - subgraph_inline: Inline definition
        - skill_ref: Reference to a saved Skill (requires SkillRepository)
        """
        # 1. Inline definition
        if node_def.get("subgraph_inline"):
            return node_def["subgraph_inline"]
        
        # 2. Reference to subgraphs dict
        subgraph_ref = node_def.get("subgraph_ref")
        if subgraph_ref:
            subgraphs = self.config.get("subgraphs", {})
            if subgraph_ref in subgraphs:
                return subgraphs[subgraph_ref]
            raise ValueError(f"Subgraph reference not found: {subgraph_ref}")
        
        # 3. Skill reference (requires repository lookup)
        skill_ref = node_def.get("skill_ref")
        if skill_ref:
            try:
                from src.services.skill_repository import get_skill_repository
                repo = get_skill_repository()
                skill = repo.get_latest_skill(skill_ref)
                if skill and skill.get("skill_type") == "subgraph_based":
                    return skill.get("subgraph_config")
                elif skill:
                    raise ValueError(f"Skill {skill_ref} is not subgraph_based")
                else:
                    raise ValueError(f"Skill not found: {skill_ref}")
            except ImportError:
                raise ValueError(f"SkillRepository not available for skill_ref: {skill_ref}")
        
        return None
    
    def _detect_cycle(self, subgraph_id: str, visited: Set[str] = None) -> None:
        """Detect circular subgraph references to prevent infinite recursion."""
        if visited is None:
            visited = set()
        
        if subgraph_id in visited:
            raise ValueError(f"Circular subgraph reference detected: {subgraph_id} in path {visited}")
        
        visited.add(subgraph_id)
        
        # Check nested subgraphs
        subgraph_def = self.config.get("subgraphs", {}).get(subgraph_id, {})
        for node in subgraph_def.get("nodes", []):
            if node.get("type") == "subgraph":
                nested_ref = node.get("subgraph_ref")
                if nested_ref:
                    self._detect_cycle(nested_ref, visited.copy())
    
    def _build_subgraph(self, subgraph_def: Dict[str, Any], node_id: str) -> Any:
        """
        Recursively compile a subgraph definition.
        
        [v2.0 Production Hardening]
        - ê¹Šì´ ì œí•œ ê²€ì¦ (MAX_SUBGRAPH_DEPTH)
        - ê²½ëŸ‰ ìƒíƒœ ìŠ¤í‚¤ë§ˆ ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ ìµœì í™”
        
        Args:
            subgraph_def: The subgraph definition dict
            node_id: ID of the parent subgraph node
            
        Returns:
            Compiled LangGraph app for the subgraph
            
        Raises:
            ValueError: ê¹Šì´ ì œí•œ ì´ˆê³¼ ì‹œ
        """
        # Cache key based on content hash
        cache_key = hashlib.md5(
            json.dumps(subgraph_def, sort_keys=True).encode()
        ).hexdigest()[:16]
        
        if cache_key in self._subgraph_cache:
            logger.debug(f"Using cached subgraph: {node_id}")
            return self._subgraph_cache[cache_key]
        
        # Build child path for logging
        child_path = self.parent_path + [node_id]
        
        # [Critical Fix #2] ê¹Šì´ ì‚¬ì „ ì²´í¬ (ë” ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€)
        if len(child_path) > MAX_SUBGRAPH_DEPTH:
            raise ValueError(
                f"Cannot build subgraph '{node_id}': nesting depth ({len(child_path)}) "
                f"would exceed MAX_SUBGRAPH_DEPTH ({MAX_SUBGRAPH_DEPTH}). "
                f"Current path: {' > '.join(self.parent_path)}"
            )
        
        logger.info(f"ğŸ“¦ Building subgraph: {' > '.join(child_path)} (depth: {len(child_path)})")
        
        # [Performance Optimization] ìì‹ ì„œë¸Œê·¸ë˜í”„ëŠ” ê²½ëŸ‰ ìƒíƒœ ì‚¬ìš©
        child_builder = DynamicWorkflowBuilder(
            subgraph_def, 
            parent_path=child_path,
            use_lightweight_state=True  # ì„œë¸Œê·¸ë˜í”„ëŠ” í•­ìƒ ê²½ëŸ‰ ìƒíƒœ ì‚¬ìš©
        )
        compiled = child_builder.build()
        
        self._subgraph_cache[cache_key] = compiled
        return compiled
    
    def _create_subgraph_handler(
        self, 
        node_def: Dict[str, Any], 
        compiled_subgraph: Any
    ) -> Callable:
        """
        Create a node handler that executes a subgraph with state mapping.
        
        State Mapping Flow:
        1. Extract fields from src.parent state using input_mapping
        2. Execute subgraph with extracted state
        3. Map subgraph output back to parent state using output_mapping
        """
        node_id = node_def.get("id", "unknown_subgraph")
        input_mapping = node_def.get("input_mapping", {})
        output_mapping = node_def.get("output_mapping", {})
        timeout = node_def.get("timeout_seconds", 300)
        error_handling = node_def.get("error_handling", "fail")
        metadata = node_def.get("metadata", {})
        
        def subgraph_handler(state: WorkflowState, config=None) -> Dict[str, Any]:
            import time
            import copy
            from datetime import datetime, timezone
            
            subgraph_name = metadata.get("name", node_id)
            logger.info(f"ğŸ“¦ Entering subgraph: {subgraph_name}")
            start_time = time.time()
            
            try:
                # 1. Input Mapping: Parent state â†’ Child input (ê²½ëŸ‰í™”)
                # [Performance Optimization] í•„ìš”í•œ í•„ë“œë§Œ ë³µì‚¬í•˜ì—¬ ë©”ëª¨ë¦¬ ì ˆì•½
                child_input: Dict[str, Any] = {}
                
                for parent_key, child_key in input_mapping.items():
                    # Support template syntax: {"query": "{{user_input}}"}
                    if isinstance(child_key, str) and "{{" in child_key:
                        # [Critical Fix #1] í…œí”Œë¦¿ ë Œë”ë§ ì‹œ í•„ìˆ˜ ë³€ìˆ˜ ê²€ì¦
                        try:
                            child_input[parent_key] = _render_template(
                                child_key, 
                                state,
                                strict_mode=False,  # ê²½ê³ ë§Œ (ì„œë¸Œê·¸ë˜í”„ ë‚´ë¶€ì—ì„œëŠ” ìœ ì—°í•˜ê²Œ)
                                required_vars=None
                            )
                        except TemplateRenderingError as e:
                            logger.error(f"Subgraph {node_id} input mapping failed: {e}")
                            raise
                    else:
                        # Direct key mapping - ê°’ì´ ìˆì„ ë•Œë§Œ ë³µì‚¬
                        if parent_key in state:
                            # [Performance] ëŒ€ìš©ëŸ‰ ê°ì²´ëŠ” ì–•ì€ ë³µì‚¬ë§Œ ìˆ˜í–‰
                            val = state[parent_key]
                            if isinstance(val, (list, dict)):
                                child_input[child_key] = copy.copy(val)  # shallow copy
                            else:
                                child_input[child_key] = val
                
                # [Performance Optimization] ê³µí†µ í•„ë“œëŠ” í•„ìš”í•œ ê²ƒë§Œ ìƒì†
                for key in SUBGRAPH_INHERIT_FIELDS:
                    if key not in child_input and key in state:
                        # ëˆ„ì  í•„ë“œëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™” (ê²°ê³¼ì—ì„œ ë³‘í•©)
                        if key in SUBGRAPH_ACCUMULATOR_FIELDS:
                            child_input[key] = []  # ë¶€ëª¨ íˆìŠ¤í† ë¦¬ë¥¼ ë³µì‚¬í•˜ì§€ ì•ŠìŒ (ë‚˜ì¤‘ì— ë³‘í•©)
                        else:
                            child_input[key] = state[key]
                
                logger.debug(f"Subgraph {node_id} input keys: {list(child_input.keys())} (lightweight)")
                
                # 2. Execute Subgraph
                child_output = compiled_subgraph.invoke(child_input)
                
                # 3. Output Mapping: Child output â†’ Parent state
                result = {}
                for child_key, parent_key in output_mapping.items():
                    if child_key in child_output:
                        result[parent_key] = child_output[child_key]
                
                # Merge accumulated fields (step_history, logs)
                if "step_history" in child_output:
                    parent_history = state.get("step_history", [])
                    result["step_history"] = parent_history + child_output["step_history"]
                
                if "skill_execution_log" in child_output:
                    parent_log = state.get("skill_execution_log", [])
                    result["skill_execution_log"] = parent_log + child_output["skill_execution_log"]
                
                execution_time_ms = int((time.time() - start_time) * 1000)
                logger.info(f"ğŸ“¦ Exiting subgraph: {subgraph_name} ({execution_time_ms}ms)")
                
                # Add subgraph execution log
                subgraph_log = {
                    "type": "subgraph_execution",
                    "subgraph_id": node_id,
                    "subgraph_name": subgraph_name,
                    "execution_time_ms": execution_time_ms,
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "input_keys": list(child_input.keys()),
                    "output_keys": list(result.keys()),
                }
                current_log = result.get("skill_execution_log", state.get("skill_execution_log", []))
                result["skill_execution_log"] = current_log + [subgraph_log]
                
                return result
                
            except Exception as e:
                execution_time_ms = int((time.time() - start_time) * 1000)
                logger.error(f"ğŸš¨ Subgraph {subgraph_name} failed after {execution_time_ms}ms: {e}")
                
                if error_handling == "skip":
                    logger.warning(f"Skipping failed subgraph: {node_id}")
                    return {f"{node_id}_error": str(e), f"{node_id}_skipped": True}
                elif error_handling == "isolate":
                    # Return error but don't propagate
                    return {f"{node_id}_error": str(e)}
                else:
                    raise
        
        return subgraph_handler

    def _get_node_handler(self, node_type: str, node_def: Dict[str, Any]) -> Callable:
        """
        Get the appropriate node handler function for a given node type.
        Uses standardized interface: (state, config=None)

        Args:
            node_type: String identifier for node type (e.g., 'llm_chat')
            node_def: Full node definition dict

        Returns:
            Callable node function with signature (state, config=None)

        Raises:
            ValueError: If node type is not registered
        """
        # First, try NODE_REGISTRY for registered handlers
        registry_func = NODE_REGISTRY.get(node_type)
        if registry_func and callable(registry_func):
            def _registry_node(state: WorkflowState, config=None) -> Any:
                node_id = node_def.get('id', f'unknown_{node_type}')
                logger.info(f"ğŸ”§ Executing {node_type} node: {node_id}")
                try:
                    # Standard interface: pass state and node_def as config
                    result = registry_func(state, node_def)
                    logger.info(f"âœ… {node_type} node {node_id} completed")
                    return result
                except Exception as e:
                    logger.error(f"ğŸš¨ {node_type} node {node_id} failed: {e}")
                    raise
            return _registry_node

        # Fallback for special cases or legacy types
        if node_type in ("llm_chat", "aiModel"):
            # Direct import for llm_chat if not in registry
            try:
                from src.handlers.core.main import llm_chat_runner
                def _llm_node(state: WorkflowState, config=None) -> Any:
                    node_id = node_def.get('id', 'unknown_llm')
                    node_config = node_def.get('config', {}).copy()  # Avoid mutation
                    node_config['id'] = node_id
                    logger.info(f"ğŸ”§ Executing {node_type} node: {node_id}")
                    try:
                        result = llm_chat_runner(state, node_config)
                        logger.info(f"âœ… {node_type} node {node_id} completed")
                        return result
                    except Exception as e:
                        logger.error(f"ğŸš¨ {node_type} node {node_id} failed: {e}")
                        raise
                return _llm_node
            except ImportError:
                pass

        elif node_type == "operator":
            try:
                from src.handlers.core.main import operator_runner
                def _operator_node(state: WorkflowState, config=None) -> Any:
                    node_id = node_def.get('id', 'unknown_operator')
                    logger.info(f"ğŸ”§ Executing operator node: {node_id}")
                    try:
                        result = operator_runner(state, node_def)
                        logger.info(f"âœ… Operator node {node_id} completed")
                        return result
                    except Exception as e:
                        logger.error(f"ğŸš¨ Operator node {node_id} failed: {e}")
                        raise
                return _operator_node
            except ImportError:
                pass

        elif node_type == "trigger":
            # Triggers are handled like operators
            try:
                from src.handlers.core.main import operator_runner
                def _trigger_node(state: WorkflowState, config=None) -> Any:
                    return operator_runner(state, node_def)
                return _trigger_node
            except ImportError:
                pass
        
        elif node_type == "subgraph":
            # Handle subgraph nodes - delegate to subgraph handler creation
            # This is handled specially in _add_nodes, so shouldn't reach here
            raise ValueError(f"Subgraph nodes should be handled in _add_nodes, not _get_node_handler")

        # If no handler found
        available_types = list(NODE_REGISTRY.keys()) + ["subgraph"]
        raise ValueError(f"Unknown node type: {node_type}. Available types: {available_types}")

    def _add_nodes(self):
        """Add all nodes from src.config to the graph, including subgraph nodes."""
        nodes = self.config.get("nodes", [])
        
        for node_def in nodes:
            node_id = node_def.get("id")
            node_type = node_def.get("type")

            if not node_id or not node_type:
                raise ValueError(f"Node missing required fields 'id' or 'type': {node_def}")
            
            # Special handling for subgraph nodes
            if node_type == "subgraph":
                # Get subgraph definition
                subgraph_def = self._get_subgraph_definition(node_def)
                if not subgraph_def:
                    raise ValueError(f"Subgraph node {node_id} has no valid definition")
                
                # Check for circular references
                subgraph_ref = node_def.get("subgraph_ref")
                if subgraph_ref:
                    self._detect_cycle(subgraph_ref)
                
                # Recursively build the subgraph
                compiled_subgraph = self._build_subgraph(subgraph_def, node_id)
                
                # Create handler with state mapping
                handler = self._create_subgraph_handler(node_def, compiled_subgraph)
                self.graph.add_node(node_id, handler)
                
                metadata = node_def.get("metadata", {})
                logger.info(f"Added subgraph node: {node_id} ({metadata.get('name', 'unnamed')})")
            else:
                # Standard node handling
                handler = self._get_node_handler(node_type, node_def)
                self.graph.add_node(node_id, handler)
                logger.debug(f"Added node: {node_id} ({node_type})")

    def _validate_conditional_edge_routers(self, edges: List[Dict[str, Any]]) -> None:
        """Validate that all conditional edge routers are registered before processing.
        
        This pre-validation catches undefined routers early, providing clear error 
        messages before attempting to build the graph.
        
        Raises:
            ValueError: If any conditional edge references an undefined router function
        """
        undefined_routers = []
        for edge in edges:
            if edge.get("type") == "conditional_edge":
                router_name = edge.get("router_func", "route_draft_quality")
                router = NODE_REGISTRY.get(router_name)
                if not router or not callable(router):
                    undefined_routers.append({
                        "source": edge.get("source"),
                        "router_func": router_name
                    })
        
        if undefined_routers:
            details = ", ".join([f"'{r['router_func']}' (from {r['source']})" for r in undefined_routers])
            raise ValueError(f"Undefined router functions for conditional_edges: {details}")

    def _add_edges(self):
        """Add all edges from src.config to the graph."""
        edges = self.config.get("edges", [])
        
        # [ìˆ˜ì •] ë¼ìš°í„° ì‚¬ì „ ê²€ì¦ - compile() ì „ì— ëª¨ë“  ë¼ìš°í„° í•¨ìˆ˜ê°€ ë“±ë¡ë˜ì—ˆëŠ”ì§€ í™•ì¸
        self._validate_conditional_edge_routers(edges)
        
        # [ìˆ˜ì •] í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ì— í¬í•¨ëœ ìœ íš¨í•œ ë…¸ë“œ ID ëª©ë¡ ì¶”ì¶œ
        valid_node_ids = {n["id"] for n in self.config.get("nodes", [])}
        
        entrypoint_assigned = False

        for edge in edges:
            edge_type = edge.get("type", "edge")
            source = edge.get("source")
            target = edge.get("target")

            # [ìˆ˜ì •] ë°©ì–´ ë¡œì§: ì†ŒìŠ¤ë‚˜ íƒ€ê²Ÿ ì¤‘ í•˜ë‚˜ë¼ë„ í˜„ì¬ ê·¸ë˜í”„ì— ì—†ìœ¼ë©´ 
            # ì´ëŠ” 'í¬ë¡œìŠ¤ ì„¸ê·¸ë¨¼íŠ¸ ì—£ì§€'ì´ë¯€ë¡œ ë¬´ì‹œí•´ì•¼ í•¨.
            # (ë°ì´í„° ì „ë‹¬ì€ state_dataë¡œ ì´ë¯¸ ë˜ì—ˆê³ , íë¦„ ì œì–´ëŠ” Step Functionsê°€ í•˜ë¯€ë¡œ ë¬´ì‹œí•´ë„ ë¨)
            if source not in valid_node_ids or target not in valid_node_ids:
                # ë‹¨, START/END ê°™ì€ íŠ¹ìˆ˜ ë…¸ë“œëŠ” ì˜ˆì™¸ì¼ ìˆ˜ ìˆìœ¼ë‚˜, 
                # LangGraphì—ì„œëŠ” ë³´í†µ ëª…ì‹œì  ë…¸ë“œê°€ í•„ìš”í•˜ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ìŠ¤í‚µ
                # START -> Node ì—°ê²°ì€ ì•„ë˜ ë¡œì§ì—ì„œ ì²˜ë¦¬ë¨
                if source != "START": 
                    logger.debug(f"Skipping cross-segment edge: {source} -> {target}")
                    continue

            # hitp, human_in_the_loop, pause edge types are treated as normal edges
            # (segmentation uses them for splitting, but LangGraph execution is the same)
            if edge_type in ("edge", "normal", "flow", "hitp", "human_in_the_loop", "pause"):
                if source == "START":
                    # Special handling for START -> target as entry point
                    if target and target in valid_node_ids: # target ìœ íš¨ì„± ì²´í¬ ì¶”ê°€
                        self.graph.set_entry_point(target)
                        entrypoint_assigned = True
                        logger.debug(f"Set entry point: {target}")
                else:
                    # sourceì™€ targetì´ ëª¨ë‘ valid_node_idsì— ìˆëŠ” ê²½ìš°ë§Œ ì—¬ê¸° ë„ë‹¬í•¨
                    if source and target:
                        self.graph.add_edge(source, target)
                        logger.debug(f"Added edge: {source} -> {target}")

            elif edge_type == "conditional_edge":
                # Conditional edgeì˜ sourceëŠ” ë°˜ë“œì‹œ í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ì— ìˆì–´ì•¼ í•¨
                if source not in valid_node_ids:
                    continue
                    
                # Handle conditional edges with router functions
                mapping = edge.get("mapping", {})
                router_name = edge.get("router_func", "route_draft_quality")
                router = NODE_REGISTRY.get(router_name)

                if not router or not callable(router):
                    raise ValueError(f"Undefined router for conditional_edge: {router_name}")

                self.graph.add_conditional_edges(source, router, mapping)
                logger.debug(f"Added conditional edge from {source} with router {router_name}")
                logger.debug(f"Added conditional edge from {source} with router {router_name}")

            elif edge_type == "start":
                if source:
                    self.graph.set_entry_point(source)
                    entrypoint_assigned = True
                    logger.debug(f"Set entry point: {source}")

            elif edge_type == "end":
                if source:
                    # Use add_edge(source, END) for LangGraph 1.0+ compatibility
                    from langgraph.graph import END
                    self.graph.add_edge(source, END)
                    logger.debug(f"Set finish point via add_edge: {source} -> END")

            else:
                raise ValueError(f"Unknown edge type: {edge_type}")

        # Default entry point if none assigned
        # [Critical Fix] Use topological analysis instead of nodes[0]
        # Find nodes with in-degree 0 (no incoming edges) as entry point candidates
        if not entrypoint_assigned:
            nodes = self.config.get("nodes", [])
            if nodes:
                # Build in-degree map
                node_ids = {n.get("id") for n in nodes}
                in_degree = {nid: 0 for nid in node_ids}
                
                for edge in edges:
                    target = edge.get("target")
                    if target in in_degree:
                        in_degree[target] += 1
                
                # Find entry point candidates (in-degree 0)
                entry_candidates = [nid for nid, deg in in_degree.items() if deg == 0]
                
                if entry_candidates:
                    # If multiple candidates, prefer the first one in node order
                    # (maintains backward compatibility with sorted nodes)
                    node_order = [n.get("id") for n in nodes]
                    for nid in node_order:
                        if nid in entry_candidates:
                            self.graph.set_entry_point(nid)
                            logger.debug(f"Entry point set via topological analysis: {nid}")
                            break
                else:
                    # Fallback to first node if no clear entry point (isolated nodes or cycles)
                    first_node_id = nodes[0].get("id")
                    if first_node_id:
                        self.graph.set_entry_point(first_node_id)
                        logger.debug(f"Default entry point set (fallback): {first_node_id}")

    def _validate_graph_completeness(self) -> None:
        """
        [Critical Fix #3] ê·¸ë˜í”„ ì™„ê²°ì„± ê²€ì¦.
        
        ëª¨ë“  ë¦¬í”„ ë…¸ë“œ(ë‚˜ê°€ëŠ” ì—£ì§€ê°€ ì—†ëŠ” ë…¸ë“œ)ê°€ ëª…ì‹œì ìœ¼ë¡œ ENDë¡œ ì—°ê²°ë˜ê±°ë‚˜
        Step Functions ì „ì´ë¥¼ ë‹´ë‹¹í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        
        Raises:
            ValueError: ë¦¬í”„ ë…¸ë“œê°€ ENDë¡œ ì—°ê²°ë˜ì§€ ì•Šì€ ê²½ìš°
        """
        nodes = self.config.get("nodes", [])
        edges = self.config.get("edges", [])
        
        if not nodes:
            return  # ë¹ˆ ê·¸ë˜í”„ëŠ” ê²€ì¦ ë¶ˆí•„ìš”
        
        node_ids = {n["id"] for n in nodes}
        
        # ê° ë…¸ë“œë³„ ë‚˜ê°€ëŠ” ì—£ì§€ ìˆ˜ ê³„ì‚°
        outgoing_count: Dict[str, int] = {nid: 0 for nid in node_ids}
        has_end_edge: Set[str] = set()
        
        for edge in edges:
            source = edge.get("source")
            target = edge.get("target")
            edge_type = edge.get("type", "edge")
            
            # í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ ë‚´ë¶€ ì—£ì§€ë§Œ ì¹´ìš´íŠ¸
            if source in node_ids:
                if target in node_ids:
                    outgoing_count[source] = outgoing_count.get(source, 0) + 1
                elif edge_type == "end" or target == "END":
                    has_end_edge.add(source)
                # conditional_edgeë„ outgoingìœ¼ë¡œ ì¹´ìš´íŠ¸
                if edge_type == "conditional_edge":
                    mapping = edge.get("mapping", {})
                    # ë§¤í•‘ì˜ íƒ€ê²Ÿë“¤ ì¤‘ í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ ë‚´ë¶€ ë…¸ë“œê°€ ìˆìœ¼ë©´ ì¹´ìš´íŠ¸
                    for mapped_target in mapping.values():
                        if mapped_target in node_ids or mapped_target == "END":
                            outgoing_count[source] = outgoing_count.get(source, 0) + 1
                            if mapped_target == "END":
                                has_end_edge.add(source)
        
        # ë¦¬í”„ ë…¸ë“œ ì‹ë³„ (ë‚˜ê°€ëŠ” ì—£ì§€ê°€ 0ê°œ)
        leaf_nodes = [
            nid for nid, count in outgoing_count.items() 
            if count == 0 and nid not in has_end_edge
        ]
        
        if leaf_nodes:
            # ê²½ê³  ìˆ˜ì¤€ìœ¼ë¡œ ì²˜ë¦¬ (Step Functionsê°€ ì„¸ê·¸ë¨¼íŠ¸ ê°„ ì „ì´ë¥¼ ë‹´ë‹¹í•˜ë¯€ë¡œ)
            # ë‹¨, ë£¨íŠ¸ ì›Œí¬í”Œë¡œìš°ì—ì„œëŠ” ë” ì—„ê²©í•˜ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŒ
            if len(self.parent_path) == 1:  # ë£¨íŠ¸ ë ˆë²¨
                logger.warning(
                    f"âš ï¸ Graph completeness warning: Leaf nodes without explicit END edge detected: "
                    f"{leaf_nodes}. These nodes may rely on Step Functions for segment transitions. "
                    f"Consider adding explicit 'end' edges for clarity."
                )
            else:
                # ì„œë¸Œê·¸ë˜í”„ì—ì„œëŠ” ë” ìœ ì—°í•˜ê²Œ ì²˜ë¦¬
                logger.debug(
                    f"Subgraph leaf nodes without END: {leaf_nodes} "
                    f"(path: {' > '.join(self.parent_path)})"
                )
        
        # ë…¸ë“œê°€ 1ê°œë¿ì´ê³  END ì—°ê²°ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ì¶”ê°€í•´ì•¼ í•¨ì„ ê²½ê³ 
        if len(nodes) == 1 and not has_end_edge:
            single_node_id = nodes[0]["id"]
            logger.info(
                f"Single-node graph detected ({single_node_id}). "
                f"Implicitly connecting to END."
            )
            # ì‹¤ì œë¡œ END ì—°ê²° ì¶”ê°€
            from langgraph.graph import END
            self.graph.add_edge(single_node_id, END)

    def build(self) -> Any:
        """
        Build and compile the LangGraph workflow.
        
        [v2.0 Production Hardening]
        - ê·¸ë˜í”„ ì™„ê²°ì„± ê²€ì¦ (ë¦¬í”„ ë…¸ë“œ â†’ END)
        - ê¹Šì´ ì œí•œ ê²€ì¦ (MAX_SUBGRAPH_DEPTH)

        Returns:
            Compiled LangGraph app ready for execution

        Raises:
            ValueError: If configuration is invalid or graph incomplete
            ImportError: If required dependencies are missing
        """
        depth = len(self.parent_path)
        schema_type = "Lightweight" if self.use_lightweight_state else "Full"
        logger.info(
            f"ğŸ—ï¸ Building workflow dynamically from config "
            f"(depth: {depth}/{MAX_SUBGRAPH_DEPTH}, schema: {schema_type})"
        )

        try:
            self._add_nodes()
            self._add_edges()
            
            # [Critical Fix #3] ê·¸ë˜í”„ ì™„ê²°ì„± ê²€ì¦
            self._validate_graph_completeness()

            # Compile the graph
            compiled_app = self.graph.compile()
            logger.info(
                f"âœ… Workflow built successfully "
                f"(path: {' > '.join(self.parent_path)})"
            )
            return compiled_app

        except Exception as e:
            logger.error(
                f"ğŸš¨ Failed to build workflow at depth {depth}: {e} "
                f"(path: {' > '.join(self.parent_path)})"
            )
            raise
