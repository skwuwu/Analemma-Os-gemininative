"""
Concurrency Controller - 4ë‹¨ê³„ ì•„í‚¤í…ì²˜ êµ¬í˜„

1ë‹¨ê³„: Reserved Concurrency (RC) - Lambda ë ˆë²¨ (template.yaml)
2ë‹¨ê³„: ì»¤ë„ ìŠ¤ì¼€ì¤„ë§ ë° ë¶€í•˜ í‰íƒ„í™” (Scheduling Layer)
3ë‹¨ê³„: ì§€ëŠ¥í˜• í’ˆì§ˆ ë° ì¬ì‹œë„ ì œì–´ (Execution Layer)  
4ë‹¨ê³„: ë¹„ìš© ë° ë“œë¦¬í”„íŠ¸ ëª¨ë‹ˆí„°ë§ (Guardrail Layer)

ì´ ëª¨ë“ˆì€ 2~4ë‹¨ê³„ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

v2.0 ì¶”ê°€ ê¸°ëŠ¥:
  - ë¶„ì‚° í™˜ê²½ ìƒíƒœ ë™ê¸°í™” (DynamoDB Atomic Counter)
  - Fast Track ê²½ë¡œ (priority: realtime)
"""

import os
import time
import json
import logging
import hashlib
from enum import Enum
from dataclasses import dataclass, field
from typing import Dict, Any, List, Optional, Callable, Tuple
from collections import deque
import threading
from decimal import Decimal

logger = logging.getLogger(__name__)


# ============================================================
# ğŸŒ ë¶„ì‚° ìƒíƒœ ê´€ë¦¬ì (DynamoDB Atomic Counter)
# ============================================================

@dataclass
class DistributedStateConfig:
    """ë¶„ì‚° ìƒíƒœ ê´€ë¦¬ ì„¤ì •"""
    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ í…Œì´ë¸” ì´ë¦„ ê°€ì ¸ì˜¤ê¸° (template.yamlì—ì„œ ì„¤ì •)
    table_name: str = field(
        default_factory=lambda: os.getenv("KERNEL_STATE_TABLE", "analemma-kernel-state")
    )
    state_key: str = "global-concurrency-state"
    # [Critical] DynamoDB í…Œì´ë¸”ì´ composite key (pk + sk)ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° sk ì¶”ê°€
    sort_key: str = "CONCURRENCY_STATE"  # Sort key for composite key tables
    ttl_seconds: int = 3600  # 1ì‹œê°„
    enable_distributed: bool = True  # Falseë©´ ë¡œì»¬ ëª¨ë“œ
    sync_interval_ms: int = 500  # ë™ê¸°í™” ì£¼ê¸°
    

class DistributedStateManager:
    """
    ë¶„ì‚° í™˜ê²½ ìƒíƒœ ê´€ë¦¬ì
    
    Lambda Scale-out ì‹œì—ë„ ì „ì—­ ê°€ë“œë ˆì¼ì´ ì‘ë™í•˜ë„ë¡
    DynamoDB Atomic Counterë¥¼ í™œìš©í•œ ìƒíƒœ ë™ê¸°í™”ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    
    ì €ì¥ í•­ëª©:
        - global_active_executions: ì „ì—­ ë™ì‹œ ì‹¤í–‰ ìˆ˜
        - global_accumulated_cost: ì „ì—­ ëˆ„ì  ë¹„ìš©
        - last_updated: ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°„
    """
    
    def __init__(self, config: Optional[DistributedStateConfig] = None):
        self.config = config or DistributedStateConfig()
        self._local_cache = {
            'active_executions': 0,
            'accumulated_cost': 0.0,
            'last_sync': 0
        }
        self._dynamodb = None
        self._table = None
        self._initialized = False
        self._lock = threading.Lock()
        
    def _ensure_initialized(self) -> bool:
        """DynamoDB ì—°ê²° ì´ˆê¸°í™” (Lazy Loading)"""
        if self._initialized:
            return True
            
        if not self.config.enable_distributed:
            logger.debug("[DistributedState] Running in local mode")
            return False
            
        try:
            import boto3
            from botocore.exceptions import ClientError
            
            self._dynamodb = boto3.resource('dynamodb')
            self._table = self._dynamodb.Table(self.config.table_name)
            
            # í…Œì´ë¸” ì¡´ì¬ í™•ì¸
            self._table.load()
            self._initialized = True
            logger.info(f"[DistributedState] Connected to {self.config.table_name}")
            return True
            
        except Exception as e:
            logger.warning(f"[DistributedState] Failed to connect: {e}. Falling back to local mode.")
            self.config.enable_distributed = False
            return False
    
    def _should_sync(self) -> bool:
        """ë™ê¸°í™” í•„ìš” ì—¬ë¶€ í™•ì¸"""
        elapsed_ms = (time.time() - self._local_cache['last_sync']) * 1000
        return elapsed_ms >= self.config.sync_interval_ms
    
    def increment_executions(self, delta: int = 1) -> int:
        """
        ì „ì—­ ì‹¤í–‰ ìˆ˜ ì¦ê°€ (Atomic)
        
        Returns:
            ì—…ë°ì´íŠ¸ í›„ ì „ì—­ ì‹¤í–‰ ìˆ˜
        """
        with self._lock:
            self._local_cache['active_executions'] += delta
            
            if not self._ensure_initialized():
                return self._local_cache['active_executions']
            
            try:
                # [Critical] Composite key support
                key = {'pk': self.config.state_key}
                if hasattr(self.config, 'sort_key') and self.config.sort_key:
                    key['sk'] = self.config.sort_key
                
                response = self._table.update_item(
                    Key=key,
                    UpdateExpression='SET active_executions = if_not_exists(active_executions, :zero) + :delta, '
                                     'last_updated = :now',
                    ExpressionAttributeValues={
                        ':delta': delta,
                        ':zero': 0,
                        ':now': Decimal(str(time.time()))
                    },
                    ReturnValues='UPDATED_NEW'
                )
                global_count = int(response['Attributes'].get('active_executions', 0))
                self._local_cache['last_sync'] = time.time()
                return global_count
                
            except Exception as e:
                logger.warning(f"[DistributedState] Atomic increment failed: {e}")
                return self._local_cache['active_executions']
    
    def decrement_executions(self, delta: int = 1) -> int:
        """
        ì „ì—­ ì‹¤í–‰ ìˆ˜ ê°ì†Œ (Atomic)
        """
        return self.increment_executions(-delta)
    
    def add_cost(self, cost_usd: float, workflow_id: str = "unknown") -> float:
        """
        ì „ì—­ ë¹„ìš© ëˆ„ì  (Atomic)
        
        Returns:
            ì—…ë°ì´íŠ¸ í›„ ì „ì—­ ëˆ„ì  ë¹„ìš©
        """
        with self._lock:
            self._local_cache['accumulated_cost'] += cost_usd
            
            if not self._ensure_initialized():
                return self._local_cache['accumulated_cost']
            
            try:
                # [Critical] Composite key support
                key = {'pk': self.config.state_key}
                if hasattr(self.config, 'sort_key') and self.config.sort_key:
                    key['sk'] = self.config.sort_key
                
                response = self._table.update_item(
                    Key=key,
                    UpdateExpression='SET accumulated_cost = if_not_exists(accumulated_cost, :zero) + :cost, '
                                     'last_updated = :now, '
                                     'last_workflow = :wf',
                    ExpressionAttributeValues={
                        ':cost': Decimal(str(round(cost_usd, 8))),
                        ':zero': Decimal('0'),
                        ':now': Decimal(str(time.time())),
                        ':wf': workflow_id
                    },
                    ReturnValues='UPDATED_NEW'
                )
                global_cost = float(response['Attributes'].get('accumulated_cost', 0))
                self._local_cache['last_sync'] = time.time()
                return global_cost
                
            except Exception as e:
                logger.warning(f"[DistributedState] Atomic cost add failed: {e}")
                return self._local_cache['accumulated_cost']
    
    def get_global_state(self) -> Dict[str, Any]:
        """
        ì „ì—­ ìƒíƒœ ì¡°íšŒ
        
        Returns:
            {
                'active_executions': int,
                'accumulated_cost': float,
                'is_distributed': bool,
                'last_sync_age_ms': float
            }
        """
        if not self._ensure_initialized() or not self._should_sync():
            return {
                'active_executions': self._local_cache['active_executions'],
                'accumulated_cost': self._local_cache['accumulated_cost'],
                'is_distributed': False,
                'last_sync_age_ms': (time.time() - self._local_cache['last_sync']) * 1000
            }
        
        try:
            # [Critical] Composite key support (pk + sk)
            # Try with sort key first, fallback to pk-only
            key = {'pk': self.config.state_key}
            if hasattr(self.config, 'sort_key') and self.config.sort_key:
                key['sk'] = self.config.sort_key
            
            response = self._table.get_item(Key=key)
            item = response.get('Item', {})
            
            global_state = {
                'active_executions': int(item.get('active_executions', 0)),
                'accumulated_cost': float(item.get('accumulated_cost', 0)),
                'is_distributed': True,
                'last_sync_age_ms': 0
            }
            
            # ë¡œì»¬ ìºì‹œ ë™ê¸°í™”
            self._local_cache['active_executions'] = global_state['active_executions']
            self._local_cache['accumulated_cost'] = global_state['accumulated_cost']
            self._local_cache['last_sync'] = time.time()
            
            return global_state
            
        except Exception as e:
            # [Debug] Log actual error for schema mismatch diagnosis
            error_type = type(e).__name__
            if 'ValidationException' in str(e):
                logger.error(f"[DistributedState] DynamoDB key schema mismatch: {e}. "
                           f"Table may use composite key (pk+sk). Key used: {key}")
            else:
                logger.warning(f"[DistributedState] Get state failed ({error_type}): {e}")
            
            return {
                'active_executions': self._local_cache['active_executions'],
                'accumulated_cost': self._local_cache['accumulated_cost'],
                'is_distributed': False,
                'last_sync_age_ms': (time.time() - self._local_cache['last_sync']) * 1000
            }
    
    def reset_global_state(self) -> bool:
        """
        ì „ì—­ ìƒíƒœ ì´ˆê¸°í™” (ê´€ë¦¬ ëª©ì )
        """
        with self._lock:
            self._local_cache = {
                'active_executions': 0,
                'accumulated_cost': 0.0,
                'last_sync': time.time()
            }
            
            if not self._ensure_initialized():
                return True
            
            try:
                # [Critical] Composite key support
                item = {
                    'pk': self.config.state_key,
                    'active_executions': 0,
                    'accumulated_cost': Decimal('0'),
                    'last_updated': Decimal(str(time.time())),
                    'reset_at': Decimal(str(time.time()))
                }
                if hasattr(self.config, 'sort_key') and self.config.sort_key:
                    item['sk'] = self.config.sort_key
                
                self._table.put_item(Item=item)
                return True
            except Exception as e:
                logger.error(f"[DistributedState] Reset failed: {e}")
                return False


# ì‹±ê¸€í†¤ ë¶„ì‚° ìƒíƒœ ê´€ë¦¬ì
_distributed_state_manager: Optional[DistributedStateManager] = None

def get_distributed_state_manager() -> DistributedStateManager:
    """ë¶„ì‚° ìƒíƒœ ê´€ë¦¬ì ì‹±ê¸€í†¤ íšë“"""
    global _distributed_state_manager
    if _distributed_state_manager is None:
        _distributed_state_manager = DistributedStateManager()
    return _distributed_state_manager


# ============================================================
# ğŸ›¡ï¸ 2ë‹¨ê³„: ì»¤ë„ ìŠ¤ì¼€ì¤„ë§ ë° ë¶€í•˜ í‰íƒ„í™” (Scheduling Layer)
# ============================================================

class LoadLevel(Enum):
    """ì‹œìŠ¤í…œ ë¶€í•˜ ìˆ˜ì¤€"""
    LOW = "low"           # ë™ì‹œì„± < 30%
    NORMAL = "normal"     # 30% <= ë™ì‹œì„± < 60%
    HIGH = "high"         # 60% <= ë™ì‹œì„± < 85%
    CRITICAL = "critical" # ë™ì‹œì„± >= 85%


@dataclass
class ConcurrencySnapshot:
    """ë™ì‹œì„± ìŠ¤ëƒ…ìƒ·"""
    timestamp: float
    active_executions: int
    reserved_concurrency: int
    utilization_ratio: float  # 0.0 ~ 1.0
    load_level: LoadLevel
    
    @property
    def is_throttle_risk(self) -> bool:
        """ì“°ë¡œí‹€ë§ ìœ„í—˜ ì—¬ë¶€"""
        return self.utilization_ratio >= 0.85


class TaskPriority(Enum):
    """ì‘ì—… ìš°ì„ ìˆœìœ„"""
    REALTIME = "realtime"    # ì¦‰ì‹œ ì‹¤í–‰ (Fast Track)
    HIGH = "high"            # ìš°ì„  ì²˜ë¦¬
    NORMAL = "normal"        # ì¼ë°˜ ì²˜ë¦¬
    LOW = "low"              # ë°°ì¹˜ ëŒ€ê¸° ê°€ëŠ¥
    BACKGROUND = "background"  # ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬


@dataclass 
class TaskBatch:
    """ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì‘ì—… ê·¸ë£¹"""
    batch_id: str
    tasks: List[Dict[str, Any]] = field(default_factory=list)
    created_at: float = field(default_factory=time.time)
    max_size: int = 10
    max_wait_ms: int = 100  # ìµœëŒ€ ëŒ€ê¸° ì‹œê°„
    
    @property
    def is_full(self) -> bool:
        return len(self.tasks) >= self.max_size
    
    @property
    def is_expired(self) -> bool:
        elapsed_ms = (time.time() - self.created_at) * 1000
        return elapsed_ms >= self.max_wait_ms
    
    @property
    def should_flush(self) -> bool:
        return self.is_full or self.is_expired


class KernelTaskScheduler:
    """
    ì»¤ë„ ë ˆë²¨ ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬
    
    í­ë°œì ì¸ ìš”ì²­ì„ OSê°€ ê°ë‹¹í•  ìˆ˜ ìˆëŠ” ì†ë„ë¡œ ì •ì œí•©ë‹ˆë‹¤.
    
    Features:
        1. Task Buffering: ì¦‰ì‹œ ì‹¤í–‰ ëŒ€ì‹  ë²„í¼ë§
        2. Batching: ì§§ì€ ì—°ì‚° ë…¸ë“œë“¤ì„ ë¬¶ì–´ì„œ ì²˜ë¦¬
        3. Throttling: ë¶€í•˜ ê¸°ë°˜ ì†ë„ ì¡°ì ˆ
        4. Priority Queue: ì¤‘ìš”ë„ ê¸°ë°˜ ìš°ì„ ìˆœìœ„
        5. Fast Track: priority=realtime ì‹œ ë°°ì¹˜ bypass (v2.0)
        6. Distributed State: ë¶„ì‚° í™˜ê²½ ë™ì‹œì„± ì¶”ì  (v2.0)
    """
    
    # ë¶€í•˜ ë ˆë²¨ë³„ ì²˜ë¦¬ ì§€ì—° (ms)
    THROTTLE_DELAYS = {
        LoadLevel.LOW: 0,
        LoadLevel.NORMAL: 10,
        LoadLevel.HIGH: 50,
        LoadLevel.CRITICAL: 200
    }
    
    # Fast Track ìš°ì„ ìˆœìœ„ëŠ” ì“°ë¡œí‹€ë§ ë©´ì œ
    FAST_TRACK_PRIORITIES = {TaskPriority.REALTIME, TaskPriority.HIGH}
    
    # ë¶€í•˜ ë ˆë²¨ë³„ ë°°ì¹˜ í¬ê¸°
    BATCH_SIZES = {
        LoadLevel.LOW: 5,
        LoadLevel.NORMAL: 10,
        LoadLevel.HIGH: 20,
        LoadLevel.CRITICAL: 50  # ë” ë§ì´ ë¬¶ì–´ì„œ í˜¸ì¶œ ì¤„ì„
    }
    
    def __init__(
        self,
        reserved_concurrency: int = 200,
        enable_batching: bool = True,
        enable_throttling: bool = True,
        enable_distributed_state: bool = True
    ):
        self.reserved_concurrency = reserved_concurrency
        self.enable_batching = enable_batching
        self.enable_throttling = enable_throttling
        self.enable_distributed_state = enable_distributed_state
        
        # ìƒíƒœ ì¶”ì  (ë¡œì»¬)
        self._active_executions = 0
        self._lock = threading.Lock()
        
        # ë¶„ì‚° ìƒíƒœ ê´€ë¦¬ì (Scale-out ëŒ€ì‘)
        self._distributed_state = get_distributed_state_manager() if enable_distributed_state else None
        
        # ë°°ì¹˜ ë²„í¼
        self._pending_batches: Dict[str, TaskBatch] = {}
        
        # í†µê³„
        self._stats = {
            'total_scheduled': 0,
            'batched_executions': 0,
            'throttle_delays_ms': 0,
            'peak_concurrency': 0,
            'fast_track_executions': 0,
            'distributed_sync_count': 0
        }
    
    def get_concurrency_snapshot(self, use_distributed: bool = True) -> ConcurrencySnapshot:
        """
        í˜„ì¬ ë™ì‹œì„± ìƒíƒœ ìŠ¤ëƒ…ìƒ·
        
        Args:
            use_distributed: Trueë©´ ë¶„ì‚° ìƒíƒœ ê¸°ë°˜, Falseë©´ ë¡œì»¬ ìƒíƒœë§Œ
        """
        with self._lock:
            # ë¶„ì‚° ìƒíƒœ ì‚¬ìš© ì‹œ ì „ì—­ ë™ì‹œì„± ì¡°íšŒ
            if use_distributed and self._distributed_state:
                global_state = self._distributed_state.get_global_state()
                active = global_state['active_executions']
                self._stats['distributed_sync_count'] += 1
            else:
                active = self._active_executions
            
            ratio = active / max(self.reserved_concurrency, 1)
            
            if ratio < 0.3:
                level = LoadLevel.LOW
            elif ratio < 0.6:
                level = LoadLevel.NORMAL
            elif ratio < 0.85:
                level = LoadLevel.HIGH
            else:
                level = LoadLevel.CRITICAL
            
            return ConcurrencySnapshot(
                timestamp=time.time(),
                active_executions=active,
                reserved_concurrency=self.reserved_concurrency,
                utilization_ratio=ratio,
                load_level=level
            )
    
    def acquire_execution_slot(self) -> bool:
        """
        ì‹¤í–‰ ìŠ¬ë¡¯ íšë“ ì‹œë„
        
        ë¶„ì‚° í™˜ê²½ì—ì„œëŠ” ì „ì—­ ë™ì‹œì„±ì„ ì¶”ì í•©ë‹ˆë‹¤.
        """
        with self._lock:
            # ë¶„ì‚° ìƒíƒœ ì‚¬ìš© ì‹œ
            if self._distributed_state:
                global_count = self._distributed_state.increment_executions(1)
                if global_count > self.reserved_concurrency:
                    # ë¡¤ë°±
                    self._distributed_state.decrement_executions(1)
                    logger.warning(f"[Scheduler] Global concurrency limit reached: {global_count}/{self.reserved_concurrency}")
                    return False
                self._active_executions = global_count
            else:
                if self._active_executions >= self.reserved_concurrency:
                    logger.warning(f"[Scheduler] Concurrency limit reached: {self._active_executions}/{self.reserved_concurrency}")
                    return False
                self._active_executions += 1
            
            self._stats['peak_concurrency'] = max(
                self._stats['peak_concurrency'],
                self._active_executions
            )
            return True
    
    def release_execution_slot(self):
        """
        ì‹¤í–‰ ìŠ¬ë¡¯ í•´ì œ
        
        ë¶„ì‚° í™˜ê²½ì—ì„œëŠ” ì „ì—­ ë™ì‹œì„±ì„ ê°ì†Œì‹œí‚µë‹ˆë‹¤.
        """
        with self._lock:
            if self._distributed_state:
                self._distributed_state.decrement_executions(1)
            self._active_executions = max(0, self._active_executions - 1)
    
    def apply_throttling(
        self, 
        snapshot: Optional[ConcurrencySnapshot] = None,
        priority: TaskPriority = TaskPriority.NORMAL
    ) -> int:
        """
        ë¶€í•˜ ê¸°ë°˜ ì“°ë¡œí‹€ë§ ì ìš©
        
        Args:
            snapshot: ë™ì‹œì„± ìŠ¤ëƒ…ìƒ·
            priority: ì‘ì—… ìš°ì„ ìˆœìœ„ (REALTIME/HIGHëŠ” ì“°ë¡œí‹€ë§ ë©´ì œ)
        
        Returns:
            ì ìš©ëœ ì§€ì—° ì‹œê°„ (ms)
        """
        # Fast Track: ì‹¤ì‹œê°„ ìš°ì„ ìˆœìœ„ëŠ” ì“°ë¡œí‹€ë§ bypass
        if priority in self.FAST_TRACK_PRIORITIES:
            logger.debug(f"[Scheduler] Fast Track: {priority.value} priority bypasses throttling")
            return 0
        
        if not self.enable_throttling:
            return 0
        
        snapshot = snapshot or self.get_concurrency_snapshot()
        delay_ms = self.THROTTLE_DELAYS.get(snapshot.load_level, 0)
        
        if delay_ms > 0:
            time.sleep(delay_ms / 1000.0)
            self._stats['throttle_delays_ms'] += delay_ms
            logger.debug(f"[Scheduler] Throttle applied: {delay_ms}ms (load: {snapshot.load_level.value})")
        
        return delay_ms
    
    def _get_task_priority(self, task_config: Dict[str, Any], state: Dict[str, Any]) -> TaskPriority:
        """
        ì‘ì—…ì˜ ìš°ì„ ìˆœìœ„ ì¶”ì¶œ
        
        ìš°ì„ ìˆœìœ„ ê²°ì • ìˆœì„œ:
            1. task_config.priority
            2. state.workflow_priority
            3. state.metadata.priority
            4. ê¸°ë³¸ê°’: NORMAL
        """
        # task_configì—ì„œ ì§ì ‘ ì§€ì •
        priority_str = task_config.get('priority', '').lower()
        
        # stateì—ì„œ ì›Œí¬í”Œë¡œìš° ë ˆë²¨ ìš°ì„ ìˆœìœ„
        if not priority_str:
            priority_str = state.get('workflow_priority', '').lower()
        
        # metadataì—ì„œ ì¶”ì¶œ
        if not priority_str:
            # [Fix] None defense: state['metadata']ê°€ Noneì¼ ìˆ˜ ìˆìŒ
            metadata = state.get('metadata') or {}
            priority_str = metadata.get('priority', '').lower()
        
        # ë¬¸ìì—´ -> Enum ë³€í™˜
        priority_map = {
            'realtime': TaskPriority.REALTIME,
            'high': TaskPriority.HIGH,
            'normal': TaskPriority.NORMAL,
            'low': TaskPriority.LOW,
            'background': TaskPriority.BACKGROUND
        }
        
        return priority_map.get(priority_str, TaskPriority.NORMAL)
    
    def should_batch(
        self, 
        task_config: Dict[str, Any],
        priority: TaskPriority = TaskPriority.NORMAL
    ) -> bool:
        """
        í•´ë‹¹ ì‘ì—…ì„ ë°°ì¹˜ ì²˜ë¦¬í•´ì•¼ í•˜ëŠ”ì§€ íŒë‹¨
        
        ë°°ì¹˜ ëŒ€ìƒ:
            - operator íƒ€ì… ë…¸ë“œ (ì§§ì€ ì—°ì‚°)
            - ì˜ˆìƒ ì‹¤í–‰ ì‹œê°„ < 100ms
            - LLM í˜¸ì¶œ ì—†ìŒ
            - priorityê°€ REALTIME/HIGHê°€ ì•„ë‹˜ (Fast Track bypass)
        """
        if not self.enable_batching:
            return False
        
        # Fast Track: ì‹¤ì‹œê°„/ë†’ì€ ìš°ì„ ìˆœìœ„ëŠ” ë°°ì¹˜ bypass
        if priority in self.FAST_TRACK_PRIORITIES:
            logger.debug(f"[Scheduler] Fast Track: {priority.value} priority bypasses batching")
            return False
        
        node_type = task_config.get('type', 'unknown')
        if node_type != 'operator':
            return False
        
        # LLM ë…¸ë“œëŠ” ë°°ì¹˜ ë¶ˆê°€
        config = task_config.get('config', {})
        if config.get('model') or config.get('llm'):
            return False
        
        # ì½”ë“œê°€ ë³µì¡í•˜ë©´ ë°°ì¹˜ ë¶ˆê°€ (íœ´ë¦¬ìŠ¤í‹±)
        code = config.get('code', '')
        if len(code) > 500:  # ê¸´ ì½”ë“œëŠ” ë³µì¡í•  ê°€ëŠ¥ì„±
            return False
        
        return True
    
    def add_to_batch(
        self,
        workflow_id: str,
        task_config: Dict[str, Any],
        state: Dict[str, Any]
    ) -> Optional[TaskBatch]:
        """
        ì‘ì—…ì„ ë°°ì¹˜ì— ì¶”ê°€
        
        Returns:
            flushê°€ í•„ìš”í•œ ë°°ì¹˜ (ì¤€ë¹„ ì™„ë£Œ ì‹œ)
        """
        snapshot = self.get_concurrency_snapshot()
        batch_size = self.BATCH_SIZES.get(snapshot.load_level, 10)
        
        batch_key = f"{workflow_id}_batch"
        
        with self._lock:
            if batch_key not in self._pending_batches:
                import uuid
                self._pending_batches[batch_key] = TaskBatch(
                    batch_id=f"batch_{uuid.uuid4().hex[:8]}",
                    max_size=batch_size
                )
            
            batch = self._pending_batches[batch_key]
            batch.tasks.append({
                'config': task_config,
                'state': state,
                'added_at': time.time()
            })
            
            if batch.should_flush:
                del self._pending_batches[batch_key]
                self._stats['batched_executions'] += len(batch.tasks)
                return batch
        
        return None
    
    def execute_batch(
        self,
        batch: TaskBatch,
        executor: Callable[[Dict[str, Any], Dict[str, Any]], Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        ë°°ì¹˜ ë‚´ ëª¨ë“  ì‘ì—… ìˆœì°¨ ì‹¤í–‰
        
        ë‹¨ì¼ Lambda ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì—¬ëŸ¬ ì‘ì—… ì²˜ë¦¬
        """
        results = []
        merged_state = {}
        
        logger.info(f"[Scheduler] Executing batch {batch.batch_id} with {len(batch.tasks)} tasks")
        
        for task in batch.tasks:
            try:
                # ìƒíƒœ ë³‘í•© (ì´ì „ ê²°ê³¼ë¥¼ ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ)
                task_state = {**task['state'], **merged_state}
                result = executor(task['config'], task_state)
                
                if isinstance(result, dict):
                    merged_state.update(result)
                
                results.append({
                    'success': True,
                    'result': result
                })
            except Exception as e:
                logger.error(f"[Scheduler] Batch task failed: {e}")
                results.append({
                    'success': False,
                    'error': str(e)
                })
        
        return results
    
    def schedule_task(
        self,
        workflow_id: str,
        task_config: Dict[str, Any],
        state: Dict[str, Any],
        executor: Callable[[Dict[str, Any], Dict[str, Any]], Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        ì‘ì—… ìŠ¤ì¼€ì¤„ë§ ë° ì‹¤í–‰
        
        ì „ì²´ íë¦„:
            1. ìš°ì„ ìˆœìœ„ ì¶”ì¶œ (Fast Track íŒë‹¨)
            2. ë™ì‹œì„± í™•ì¸ ë° ì“°ë¡œí‹€ë§ (Fast Trackì€ bypass)
            3. ë°°ì¹˜ ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨ (Fast Trackì€ bypass)
            4. ë°°ì¹˜ ë˜ëŠ” ì¦‰ì‹œ ì‹¤í–‰
        """
        self._stats['total_scheduled'] += 1
        
        # 0. ìš°ì„ ìˆœìœ„ ì¶”ì¶œ
        priority = self._get_task_priority(task_config, state)
        is_fast_track = priority in self.FAST_TRACK_PRIORITIES
        
        if is_fast_track:
            self._stats['fast_track_executions'] += 1
            logger.info(f"[Scheduler] ğŸš€ Fast Track activated: priority={priority.value}")
        
        # 1. ë™ì‹œì„± ìŠ¤ëƒ…ìƒ·
        snapshot = self.get_concurrency_snapshot()
        
        # 2. ì“°ë¡œí‹€ë§ ì ìš© (Fast Trackì€ bypass)
        self.apply_throttling(snapshot, priority)
        
        # 3. ìŠ¬ë¡¯ íšë“
        if not self.acquire_execution_slot():
            raise RuntimeError(
                f"Concurrency limit exceeded ({self._active_executions}/{self.reserved_concurrency}). "
                "System is under heavy load."
            )
        
        try:
            # 4. ë°°ì¹˜ ì²˜ë¦¬ ê²€í†  (Fast Trackì€ bypass)
            if self.should_batch(task_config, priority):
                batch = self.add_to_batch(workflow_id, task_config, state)
                if batch:
                    results = self.execute_batch(batch, executor)
                    # ë§ˆì§€ë§‰ ê²°ê³¼ ë°˜í™˜ (ìƒíƒœ ì—°ì‡„)
                    return results[-1].get('result', {}) if results else {}
                else:
                    # ë°°ì¹˜ì— ì¶”ê°€ë¨, ì•„ì§ ì‹¤í–‰ ì•ˆ í•¨
                    return {'__batched': True, '__batch_pending': True}
            
            # 5. ì¦‰ì‹œ ì‹¤í–‰
            return executor(task_config, state)
            
        finally:
            self.release_execution_slot()
    
    def get_stats(self) -> Dict[str, Any]:
        """ìŠ¤ì¼€ì¤„ëŸ¬ í†µê³„"""
        snapshot = self.get_concurrency_snapshot()
        
        # ë¶„ì‚° ìƒíƒœ ì •ë³´ ì¶”ê°€
        distributed_info = {}
        if self._distributed_state:
            global_state = self._distributed_state.get_global_state()
            distributed_info = {
                'distributed_active': global_state['active_executions'],
                'distributed_cost': global_state['accumulated_cost'],
                'is_distributed': global_state['is_distributed']
            }
        
        return {
            **self._stats,
            'current_concurrency': snapshot.active_executions,
            'concurrency_utilization': round(snapshot.utilization_ratio * 100, 1),
            'load_level': snapshot.load_level.value,
            'pending_batches': len(self._pending_batches),
            **distributed_info
        }


# ============================================================
# ğŸ›¡ï¸ 3ë‹¨ê³„: ì§€ëŠ¥í˜• í’ˆì§ˆ ë° ì¬ì‹œë„ ì œì–´ (Execution Layer)
# ============================================================

@dataclass
class AdaptiveThresholdConfig:
    """ì ì‘í˜• ì„ê³„ê°’ ì„¤ì •"""
    # ê¸°ë³¸ ì„ê³„ê°’
    base_quality_threshold: float = 0.6
    
    # ë¶€í•˜ ë ˆë²¨ë³„ ì™„í™” ì •ë„
    threshold_reduction_per_level: float = 0.1
    
    # ì¬ì‹œë„ íšŸìˆ˜ë³„ ì™„í™”
    threshold_reduction_per_retry: float = 0.1
    
    # ìµœì†Œ í’ˆì§ˆ ì„ê³„ê°’ (ì•„ë¬´ë¦¬ ì™„í™”í•´ë„ ì´ ì´í•˜ë¡œ ë‚´ë ¤ê°€ì§€ ì•ŠìŒ)
    min_quality_threshold: float = 0.3
    
    def get_effective_threshold(
        self,
        load_level: LoadLevel,
        retry_count: int
    ) -> float:
        """
        í˜„ì¬ ìƒí™©ì— ë§ëŠ” ì‹¤íš¨ ì„ê³„ê°’ ê³„ì‚°
        
        ë†’ì€ ë¶€í•˜ + ë§ì€ ì¬ì‹œë„ â†’ ì„ê³„ê°’ ì™„í™” â†’ ë¹ ë¥¸ í†µê³¼
        """
        load_reduction = {
            LoadLevel.LOW: 0,
            LoadLevel.NORMAL: 1,
            LoadLevel.HIGH: 2,
            LoadLevel.CRITICAL: 3
        }.get(load_level, 0) * self.threshold_reduction_per_level
        
        retry_reduction = retry_count * self.threshold_reduction_per_retry
        
        effective = self.base_quality_threshold - load_reduction - retry_reduction
        return max(self.min_quality_threshold, effective)


class IntelligentRetryController:
    """
    ì§€ëŠ¥í˜• ì¬ì‹œë„ ì œì–´ê¸°
    
    í’ˆì§ˆ ì €í•˜ê°€ ë¹„ìš© í­ì¦ìœ¼ë¡œ ì´ì–´ì§€ëŠ” 'ë£¨í”„'ë¥¼ ëŠìŠµë‹ˆë‹¤.
    
    Features:
        1. Quality Gate Interceptor: ì €í’ˆì§ˆ ì‹œ ì •ë³´ ì¦ë¥˜ë¡œ ë¶€ë¶„ ìˆ˜ìˆ 
        2. Adaptive Threshold: ë¶€í•˜/ì¬ì‹œë„ì— ë”°ë¥¸ ë‹¨ê³„ì  ì™„í™”
        3. Best-Effort Mode: ì‹œìŠ¤í…œ ë³´í˜¸ë¥¼ ìœ„í•œ ìµœì„  ê²°ê³¼ ë°˜í™˜
    """
    
    def __init__(
        self,
        scheduler: Optional[KernelTaskScheduler] = None,
        threshold_config: Optional[AdaptiveThresholdConfig] = None,
        max_retries: int = 3,
        enable_distillation: bool = True
    ):
        self.scheduler = scheduler
        self.threshold_config = threshold_config or AdaptiveThresholdConfig()
        self.max_retries = max_retries
        self.enable_distillation = enable_distillation
        
        # ì¬ì‹œë„ ê¸°ë¡
        self._retry_history: Dict[str, List[Dict[str, Any]]] = {}
    
    def get_current_threshold(self, node_id: str) -> float:
        """í˜„ì¬ ë…¸ë“œì˜ ì‹¤íš¨ í’ˆì§ˆ ì„ê³„ê°’"""
        retry_count = len(self._retry_history.get(node_id, []))
        
        if self.scheduler:
            snapshot = self.scheduler.get_concurrency_snapshot()
            load_level = snapshot.load_level
        else:
            load_level = LoadLevel.NORMAL
        
        return self.threshold_config.get_effective_threshold(load_level, retry_count)
    
    def should_distill_instead_of_retry(
        self,
        node_id: str,
        quality_score: float,
        slop_issues: List[str]
    ) -> Tuple[bool, str]:
        """
        ì¬ì‹œë„ ëŒ€ì‹  ì¦ë¥˜(Distillation)ë¥¼ ìˆ˜í–‰í•´ì•¼ í•˜ëŠ”ì§€ íŒë‹¨
        
        Returns:
            (should_distill, reason)
        """
        retry_count = len(self._retry_history.get(node_id, []))
        
        # ì¬ì‹œë„ í•œë„ ë„ë‹¬ ì‹œ ì¦ë¥˜ë¡œ ì „í™˜
        if retry_count >= self.max_retries:
            return True, f"Max retries ({self.max_retries}) reached"
        
        # ë¶€ë¶„ì  ë¬¸ì œë§Œ ìˆìœ¼ë©´ ì¦ë¥˜ê°€ íš¨ìœ¨ì 
        minor_issues = ['redundant_phrases', 'filler_words', 'slight_repetition']
        if all(issue in minor_issues for issue in slop_issues):
            return True, "Minor issues only - distillation more efficient"
        
        # ê³ ë¶€í•˜ ì‹œ ì¦ë¥˜ ìš°ì„ 
        if self.scheduler:
            snapshot = self.scheduler.get_concurrency_snapshot()
            if snapshot.load_level in [LoadLevel.HIGH, LoadLevel.CRITICAL]:
                return True, f"High load ({snapshot.load_level.value}) - conserving resources"
        
        # í’ˆì§ˆì´ ì„ê³„ê°’ ê·¼ì²˜ë©´ ì¦ë¥˜ ì‹œë„
        threshold = self.get_current_threshold(node_id)
        if quality_score >= threshold * 0.8:
            return True, f"Score {quality_score:.2f} close to threshold {threshold:.2f}"
        
        return False, "Retry recommended"
    
    def record_retry(
        self,
        node_id: str,
        quality_score: float,
        action_taken: str,
        success: bool
    ):
        """ì¬ì‹œë„ ê¸°ë¡"""
        if node_id not in self._retry_history:
            self._retry_history[node_id] = []
        
        self._retry_history[node_id].append({
            'timestamp': time.time(),
            'quality_score': quality_score,
            'action': action_taken,
            'success': success,
            'threshold_used': self.get_current_threshold(node_id)
        })
    
    def evaluate_and_act(
        self,
        node_id: str,
        text: str,
        quality_score: float,
        slop_issues: List[str],
        regenerate_func: Callable[[], str],
        distill_func: Callable[[str, List[str]], str]
    ) -> Tuple[str, str, bool]:
        """
        í’ˆì§ˆ í‰ê°€ í›„ ì ì ˆí•œ ì¡°ì¹˜ ìˆ˜í–‰
        
        Returns:
            (final_text, action_taken, passed_quality)
        """
        threshold = self.get_current_threshold(node_id)
        
        # í’ˆì§ˆ í†µê³¼
        if quality_score >= threshold:
            self.record_retry(node_id, quality_score, "PASS", True)
            return text, "PASS", True
        
        # ì¦ë¥˜ vs ì¬ì‹œë„ ê²°ì •
        should_distill, reason = self.should_distill_instead_of_retry(
            node_id, quality_score, slop_issues
        )
        
        if should_distill and self.enable_distillation:
            # ì •ë³´ ì¦ë¥˜ (ë¶€ë¶„ ìˆ˜ìˆ )
            try:
                distilled_text = distill_func(text, slop_issues)
                self.record_retry(node_id, quality_score, f"DISTILL: {reason}", True)
                return distilled_text, f"DISTILL: {reason}", True
            except Exception as e:
                logger.warning(f"[RetryController] Distillation failed: {e}")
        
        # ì¬ìƒì„± ì‹œë„
        try:
            new_text = regenerate_func()
            self.record_retry(node_id, quality_score, "REGENERATE", True)
            return new_text, "REGENERATE", False  # ì¬í‰ê°€ í•„ìš”
        except Exception as e:
            logger.error(f"[RetryController] Regeneration failed: {e}")
            # Best-Effort: ì›ë³¸ ë°˜í™˜
            self.record_retry(node_id, quality_score, "BEST_EFFORT", False)
            return text, "BEST_EFFORT (regeneration failed)", True
    
    def get_retry_stats(self, node_id: Optional[str] = None) -> Dict[str, Any]:
        """ì¬ì‹œë„ í†µê³„"""
        if node_id:
            history = self._retry_history.get(node_id, [])
            return {
                'node_id': node_id,
                'retry_count': len(history),
                'history': history
            }
        
        return {
            'total_nodes': len(self._retry_history),
            'total_retries': sum(len(h) for h in self._retry_history.values()),
            'nodes': {k: len(v) for k, v in self._retry_history.items()}
        }


# ============================================================
# ğŸ›¡ï¸ 4ë‹¨ê³„: ë¹„ìš© ë° ë“œë¦¬í”„íŠ¸ ëª¨ë‹ˆí„°ë§ (Guardrail Layer)
# ============================================================

@dataclass
class BudgetWatchdogConfig:
    """ë¹„ìš© ê°ì‹œ ì„¤ì •"""
    max_budget_usd: float = 10.0
    warning_threshold: float = 0.7   # 70%ì—ì„œ ê²½ê³ 
    critical_threshold: float = 0.9  # 90%ì—ì„œ ê°•ì œ ì „í™˜
    halt_threshold: float = 1.0      # 100%ì—ì„œ ì¤‘ë‹¨
    
    # ëª¨ë¸ ë‹¤ìš´ê·¸ë ˆì´ë“œ ê²½ë¡œ
    model_downgrade_path: List[str] = field(default_factory=lambda: [
        'gemini-1.5-pro',      # ìµœê³ ê¸‰
        'gemini-1.5-flash',    # ì¤‘ê¸‰
        'gemini-2.0-flash',    # ì¤‘ê¸‰ (ìµœì‹ )
        'gemini-1.5-flash-8b'  # ìµœì €ê°€
    ])


class BudgetWatchdog:
    """
    ë¹„ìš© ì„œí‚· ë¸Œë ˆì´ì»¤
    
    ê²½ì œì  íŒŒë©¸ì„ ë§‰ëŠ” ìµœí›„ì˜ ë³´ë£¨ì…ë‹ˆë‹¤.
    
    Actions:
        - WARNING (70%): ë¡œê·¸ ë° ì•Œë¦¼
        - CRITICAL (90%): ì €ë¹„ìš© ëª¨ë¸ë¡œ ê°•ì œ ì „í™˜
        - HALT (100%): ì‹¤í–‰ ì¤‘ë‹¨
    
    v2.0: ë¶„ì‚° í™˜ê²½ì—ì„œ ì „ì—­ ë¹„ìš© ì¶”ì  ì§€ì›
    """
    
    def __init__(
        self, 
        config: Optional[BudgetWatchdogConfig] = None,
        enable_distributed: bool = True,
        workflow_id: str = "unknown"
    ):
        self.config = config or BudgetWatchdogConfig()
        self._accumulated_cost: float = 0.0
        self._cost_history: List[Dict[str, Any]] = []
        self._model_override: Optional[str] = None
        self._halted: bool = False
        self._workflow_id = workflow_id
        
        # ë¶„ì‚° ìƒíƒœ ì—°ë™ (ì „ì—­ ë¹„ìš© ì¶”ì )
        self._distributed_state = get_distributed_state_manager() if enable_distributed else None
    
    def record_cost(
        self,
        model: str,
        input_tokens: int,
        output_tokens: int,
        node_id: str = "unknown"
    ) -> Dict[str, Any]:
        """
        ë¹„ìš© ê¸°ë¡ ë° ê°€ë“œë ˆì¼ í™•ì¸
        
        ë¶„ì‚° í™˜ê²½ì—ì„œëŠ” ì „ì—­ ë¹„ìš©ì„ ê¸°ì¤€ìœ¼ë¡œ ê°€ë“œë ˆì¼ì„ ì ìš©í•©ë‹ˆë‹¤.
        
        Returns:
            {
                'cost_usd': float,
                'total_cost_usd': float,
                'global_cost_usd': float (v2.0),
                'budget_ratio': float,
                'action': str,  # 'CONTINUE', 'WARNING', 'DOWNGRADE', 'HALT'
                'new_model': Optional[str],
                'is_distributed': bool (v2.0)
            }
        """
        # ëª¨ë¸ë³„ ê°€ê²© (per 1K tokens)
        PRICING = {
            'gemini-1.5-pro': {'input': 0.00125, 'output': 0.005},
            'gemini-1.5-flash': {'input': 0.000075, 'output': 0.0003},
            'gemini-2.0-flash': {'input': 0.0001, 'output': 0.0004},
            'gemini-1.5-flash-8b': {'input': 0.0000375, 'output': 0.00015},
            'gpt-4o': {'input': 0.005, 'output': 0.015},
            'gpt-4o-mini': {'input': 0.00015, 'output': 0.0006},
            'claude-3.5-sonnet': {'input': 0.003, 'output': 0.015},
        }
        
        pricing = PRICING.get(model, {'input': 0.001, 'output': 0.002})
        cost = (input_tokens / 1000 * pricing['input']) + \
               (output_tokens / 1000 * pricing['output'])
        
        # ë¡œì»¬ ë¹„ìš© ëˆ„ì 
        self._accumulated_cost += cost
        self._cost_history.append({
            'timestamp': time.time(),
            'model': model,
            'input_tokens': input_tokens,
            'output_tokens': output_tokens,
            'cost_usd': cost,
            'node_id': node_id
        })
        
        # ë¶„ì‚° í™˜ê²½: ì „ì—­ ë¹„ìš© ëˆ„ì  ë° ì¡°íšŒ
        global_cost = self._accumulated_cost
        is_distributed = False
        
        if self._distributed_state:
            global_cost = self._distributed_state.add_cost(cost, self._workflow_id)
            is_distributed = True
        
        # ì „ì—­ ë¹„ìš© ê¸°ì¤€ìœ¼ë¡œ ê°€ë“œë ˆì¼ ì ìš©
        budget_ratio = global_cost / self.config.max_budget_usd
        
        result = {
            'cost_usd': round(cost, 6),
            'total_cost_usd': round(self._accumulated_cost, 4),
            'global_cost_usd': round(global_cost, 4),
            'budget_ratio': round(budget_ratio, 3),
            'action': 'CONTINUE',
            'new_model': None,
            'is_distributed': is_distributed
        }
        
        # ê°€ë“œë ˆì¼ ì²´í¬
        if budget_ratio >= self.config.halt_threshold:
            self._halted = True
            result['action'] = 'HALT'
            logger.critical(f"[BudgetWatchdog] ğŸš¨ HALT: Budget exhausted (${self._accumulated_cost:.2f}/${self.config.max_budget_usd})")
        
        elif budget_ratio >= self.config.critical_threshold:
            # ìµœì €ê°€ ëª¨ë¸ë¡œ ê°•ì œ ì „í™˜
            self._model_override = self.config.model_downgrade_path[-1]
            result['action'] = 'DOWNGRADE'
            result['new_model'] = self._model_override
            logger.warning(f"[BudgetWatchdog] âš ï¸ CRITICAL: Forcing model downgrade to {self._model_override}")
        
        elif budget_ratio >= self.config.warning_threshold:
            result['action'] = 'WARNING'
            logger.warning(f"[BudgetWatchdog] âš ï¸ WARNING: Budget at {budget_ratio*100:.1f}%")
        
        return result
    
    def get_effective_model(self, requested_model: str) -> str:
        """ê°•ì œ ë‹¤ìš´ê·¸ë ˆì´ë“œ ì ìš©ëœ ì‹¤ì œ ëª¨ë¸ ë°˜í™˜"""
        if self._model_override:
            return self._model_override
        return requested_model
    
    def is_halted(self) -> bool:
        """ì‹¤í–‰ ì¤‘ë‹¨ ìƒíƒœ ì—¬ë¶€"""
        return self._halted
    
    def get_budget_status(self) -> Dict[str, Any]:
        """
        ì˜ˆì‚° ìƒíƒœ ìš”ì•½
        
        v2.0: ë¶„ì‚° í™˜ê²½ì—ì„œ ì „ì—­ ë¹„ìš© ì •ë³´ í¬í•¨
        """
        # ë¶„ì‚° ìƒíƒœì—ì„œ ì „ì—­ ë¹„ìš© ì¡°íšŒ
        global_cost = self._accumulated_cost
        is_distributed = False
        
        if self._distributed_state:
            global_state = self._distributed_state.get_global_state()
            global_cost = global_state['accumulated_cost']
            is_distributed = global_state['is_distributed']
        
        return {
            'local_cost_usd': round(self._accumulated_cost, 4),
            'global_cost_usd': round(global_cost, 4),
            'accumulated_cost_usd': round(global_cost, 4),  # í˜¸í™˜ì„± ìœ ì§€
            'max_budget_usd': self.config.max_budget_usd,
            'budget_ratio': round(global_cost / self.config.max_budget_usd, 3),
            'is_halted': self._halted,
            'model_override': self._model_override,
            'total_requests': len(self._cost_history),
            'is_distributed': is_distributed
        }


@dataclass
class SemanticDriftResult:
    """ì‹œë§¨í‹± ë“œë¦¬í”„íŠ¸ ê°ì§€ ê²°ê³¼"""
    is_drifting: bool
    similarity_score: float  # 0.0 ~ 1.0 (1.0 = ì™„ì „ ë™ì¼)
    consecutive_similar_count: int
    recommendation: str  # 'CONTINUE', 'WARN', 'HALT_FOR_HITL'


class SemanticDriftDetector:
    """
    ì‹œë§¨í‹± ë“œë¦¬í”„íŠ¸ ê°ì§€ê¸°
    
    AIê°€ ë˜‘ê°™ì€ ëŒ€ë‹µì„ ë°˜ë³µí•˜ë©° ë£¨í”„ë¥¼ ëŒê³  ìˆë‹¤ë©´,
    ì¸í”„ë¼ ìì›ì„ ë” ë‚­ë¹„í•˜ê¸° ì „ì— ì‹¤í–‰ì„ ì¤‘ë‹¨í•˜ê³ 
    ì¸ê°„(HITL)ì—ê²Œ ì œì–´ê¶Œì„ ë„˜ê¹ë‹ˆë‹¤.
    """
    
    def __init__(
        self,
        similarity_threshold: float = 0.95,
        max_consecutive_similar: int = 3,
        history_size: int = 10
    ):
        self.similarity_threshold = similarity_threshold
        self.max_consecutive_similar = max_consecutive_similar
        self.history_size = history_size
        
        self._output_history: deque = deque(maxlen=history_size)
        self._consecutive_similar = 0
    
    def _compute_similarity(self, text1: str, text2: str) -> float:
        """
        ë‘ í…ìŠ¤íŠ¸ì˜ ìœ ì‚¬ë„ ê³„ì‚° (Jaccard + Length)
        
        ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” ì„ë² ë”© ê¸°ë°˜ ìœ ì‚¬ë„ ì‚¬ìš© ê¶Œì¥
        """
        if not text1 or not text2:
            return 0.0
        
        # ì •ê·œí™”
        t1 = text1.lower().strip()
        t2 = text2.lower().strip()
        
        # ì™„ì „ ë™ì¼
        if t1 == t2:
            return 1.0
        
        # ê¸¸ì´ ìœ ì‚¬ë„
        len_sim = min(len(t1), len(t2)) / max(len(t1), len(t2))
        
        # ë‹¨ì–´ ê¸°ë°˜ Jaccard ìœ ì‚¬ë„
        words1 = set(t1.split())
        words2 = set(t2.split())
        
        if not words1 or not words2:
            return len_sim
        
        intersection = len(words1 & words2)
        union = len(words1 | words2)
        jaccard = intersection / union if union > 0 else 0
        
        # ê°€ì¤‘ í‰ê· 
        return 0.3 * len_sim + 0.7 * jaccard
    
    def _compute_hash(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ í•´ì‹œ (ë¹ ë¥¸ ì¤‘ë³µ ì²´í¬ìš©)"""
        return hashlib.md5(text.encode()).hexdigest()[:16]
    
    def check_drift(self, output_text: str) -> SemanticDriftResult:
        """
        ìƒˆ ì¶œë ¥ì˜ ë“œë¦¬í”„íŠ¸ ì—¬ë¶€ í™•ì¸
        """
        if not self._output_history:
            self._output_history.append(output_text)
            return SemanticDriftResult(
                is_drifting=False,
                similarity_score=0.0,
                consecutive_similar_count=0,
                recommendation='CONTINUE'
            )
        
        # ë§ˆì§€ë§‰ ì¶œë ¥ê³¼ ë¹„êµ
        last_output = self._output_history[-1]
        similarity = self._compute_similarity(output_text, last_output)
        
        if similarity >= self.similarity_threshold:
            self._consecutive_similar += 1
        else:
            self._consecutive_similar = 0
        
        self._output_history.append(output_text)
        
        # ë“œë¦¬í”„íŠ¸ íŒì •
        is_drifting = self._consecutive_similar >= self.max_consecutive_similar
        
        if is_drifting:
            recommendation = 'HALT_FOR_HITL'
            logger.warning(
                f"[DriftDetector] ğŸ”„ Semantic drift detected! "
                f"{self._consecutive_similar} consecutive similar outputs (threshold: {self.similarity_threshold})"
            )
        elif self._consecutive_similar >= 2:
            recommendation = 'WARN'
        else:
            recommendation = 'CONTINUE'
        
        return SemanticDriftResult(
            is_drifting=is_drifting,
            similarity_score=similarity,
            consecutive_similar_count=self._consecutive_similar,
            recommendation=recommendation
        )
    
    def reset(self):
        """íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
        self._output_history.clear()
        self._consecutive_similar = 0


# ============================================================
# ğŸ›¡ï¸ í†µí•© ì»¨íŠ¸ë¡¤ëŸ¬: 4ë‹¨ê³„ ì•„í‚¤í…ì²˜ í†µí•©
# ============================================================

class ConcurrencyControllerV2:
    """
    4ë‹¨ê³„ ì•„í‚¤í…ì²˜ í†µí•© ì»¨íŠ¸ë¡¤ëŸ¬
    
    1ë‹¨ê³„: Reserved Concurrency (Lambda ë ˆë²¨ - template.yaml)
    2ë‹¨ê³„: ì»¤ë„ ìŠ¤ì¼€ì¤„ë§ (KernelTaskScheduler)
    3ë‹¨ê³„: ì§€ëŠ¥í˜• ì¬ì‹œë„ (IntelligentRetryController)
    4ë‹¨ê³„: ë¹„ìš©/ë“œë¦¬í”„íŠ¸ ê°€ë“œë ˆì¼ (BudgetWatchdog, SemanticDriftDetector)
    """
    
    def __init__(
        self,
        workflow_id: str = "default",
        reserved_concurrency: int = 200,
        max_budget_usd: float = 10.0,
        enable_batching: bool = True,
        enable_throttling: bool = True,
        enable_distillation: bool = True
    ):
        self.workflow_id = workflow_id
        
        # 2ë‹¨ê³„: ìŠ¤ì¼€ì¤„ëŸ¬
        self.scheduler = KernelTaskScheduler(
            reserved_concurrency=reserved_concurrency,
            enable_batching=enable_batching,
            enable_throttling=enable_throttling
        )
        
        # 3ë‹¨ê³„: ì¬ì‹œë„ ì»¨íŠ¸ë¡¤ëŸ¬
        self.retry_controller = IntelligentRetryController(
            scheduler=self.scheduler,
            enable_distillation=enable_distillation
        )
        
        # 4ë‹¨ê³„: ê°€ë“œë ˆì¼
        self.budget_watchdog = BudgetWatchdog(
            BudgetWatchdogConfig(max_budget_usd=max_budget_usd)
        )
        self.drift_detector = SemanticDriftDetector()
    
    def pre_execution_check(self) -> Dict[str, Any]:
        """
        ì‹¤í–‰ ì „ ì²´í¬
        
        Returns:
            {
                'can_proceed': bool,
                'reason': str,
                'snapshot': ConcurrencySnapshot,
                'budget_status': dict
            }
        """
        # ì˜ˆì‚° ì²´í¬
        if self.budget_watchdog.is_halted():
            return {
                'can_proceed': False,
                'reason': 'Budget exhausted - execution halted',
                'budget_status': self.budget_watchdog.get_budget_status()
            }
        
        # ë™ì‹œì„± ì²´í¬
        snapshot = self.scheduler.get_concurrency_snapshot()
        if snapshot.is_throttle_risk:
            # ì“°ë¡œí‹€ë§ì€ í•˜ë˜ ì§„í–‰ì€ ê°€ëŠ¥
            self.scheduler.apply_throttling(snapshot)
        
        return {
            'can_proceed': True,
            'reason': 'OK',
            'snapshot': snapshot,
            'budget_status': self.budget_watchdog.get_budget_status()
        }
    
    def post_execution_check(
        self,
        output_text: str,
        model: str,
        input_tokens: int,
        output_tokens: int,
        node_id: str
    ) -> Dict[str, Any]:
        """
        ì‹¤í–‰ í›„ ì²´í¬
        
        Returns:
            {
                'should_halt': bool,
                'halt_reason': Optional[str],
                'cost_result': dict,
                'drift_result': SemanticDriftResult,
                'effective_model': str
            }
        """
        # ë¹„ìš© ê¸°ë¡
        cost_result = self.budget_watchdog.record_cost(
            model=model,
            input_tokens=input_tokens,
            output_tokens=output_tokens,
            node_id=node_id
        )
        
        # ë“œë¦¬í”„íŠ¸ ì²´í¬
        drift_result = self.drift_detector.check_drift(output_text)
        
        should_halt = False
        halt_reason = None
        
        if cost_result['action'] == 'HALT':
            should_halt = True
            halt_reason = 'Budget exhausted'
        elif drift_result.recommendation == 'HALT_FOR_HITL':
            should_halt = True
            halt_reason = f"Semantic drift detected ({drift_result.consecutive_similar_count} similar outputs)"
        
        return {
            'should_halt': should_halt,
            'halt_reason': halt_reason,
            'cost_result': cost_result,
            'drift_result': drift_result,
            'effective_model': self.budget_watchdog.get_effective_model(model)
        }
    
    def get_comprehensive_stats(self) -> Dict[str, Any]:
        """ì „ì²´ í†µê³„"""
        return {
            'workflow_id': self.workflow_id,
            'scheduler': self.scheduler.get_stats(),
            'retry': self.retry_controller.get_retry_stats(),
            'budget': self.budget_watchdog.get_budget_status()
        }


# Singleton ì¸ìŠ¤í„´ìŠ¤ (Lambda warm start í™œìš©)
_controller_instance: Optional[ConcurrencyControllerV2] = None


def get_concurrency_controller(
    workflow_id: str = "default",
    **kwargs
) -> ConcurrencyControllerV2:
    """ì‹±ê¸€í†¤ ì»¨íŠ¸ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ íšë“"""
    global _controller_instance
    
    if _controller_instance is None or _controller_instance.workflow_id != workflow_id:
        _controller_instance = ConcurrencyControllerV2(workflow_id=workflow_id, **kwargs)
    
    return _controller_instance
