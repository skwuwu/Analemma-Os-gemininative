import logging
import os
import json
from typing import Dict, Any

from src.services.execution.segment_runner_service import SegmentRunnerService

# Set up logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# ğŸš¨ [Critical] Validate S3 bucket at module load time (Cold Start)
_S3_BUCKET = os.environ.get("S3_BUCKET") or os.environ.get("SKELETON_S3_BUCKET") or ""
_S3_BUCKET = _S3_BUCKET.strip() if _S3_BUCKET else ""
if not _S3_BUCKET:
    logger.error("ğŸš¨ [CRITICAL CONFIG ERROR] S3_BUCKET or SKELETON_S3_BUCKET environment variable is NOT SET! "
                f"S3_BUCKET='{os.environ.get('S3_BUCKET')}', "
                f"SKELETON_S3_BUCKET='{os.environ.get('SKELETON_S3_BUCKET')}'. "
                "Payloads exceeding 256KB will cause Step Functions failures.")
else:
    logger.info(f"âœ… S3 bucket configured for state offloading: {_S3_BUCKET}")

def lambda_handler(event: Dict[str, Any], context: Any = None) -> Dict[str, Any]:
    """
    Entry point for Segment Executions.
    
    Refactored to "Tiny Handler" pattern.
    Logic delegated to:
    - src.services.execution.segment_runner_service.SegmentRunnerService
    """
    try:
        # PII / Logging safety check
        # Limit log size
        event_str = json.dumps(event)
        log_size = len(event_str)
        if log_size > 10000:
             logger.info("ğŸš€ Segment Runner started. Event size: %s (large event truncated)", log_size)
        else:
             logger.info("ğŸš€ Segment Runner started. Event: %s", event_str)
        
        # ğŸ›¡ï¸ [v2.5] S3 bucket ê°•ì œ ë™ê¸°í™” - í•¸ë“¤ëŸ¬ì—ì„œ ì„œë¹„ìŠ¤ë¡œ ì „ë‹¬
        service = SegmentRunnerService(s3_bucket=_S3_BUCKET)
        result = service.execute_segment(event)
        
        # ğŸ›¡ï¸ [v2.5] TypeError ë°©ì–´ ì½”ë“œ - total_segments ë³´ì¥ (ê°•ì œ ìºìŠ¤íŒ…)
        if result and isinstance(result, dict):
            # ğŸ›¡ï¸ [Critical Fix] ì–´ë–¤ íƒ€ì…ì´ë“  intë¡œ ê°•ì œ ë³€í™˜ ì‹œë„
            raw_total = result.get('total_segments')
            if raw_total is None:
                raw_total = event.get('total_segments')
            
            try:
                # Dict, List ë“± ì˜ëª»ëœ íƒ€ì…ì´ ë“¤ì–´ì™€ë„ int()ë¡œ ë³€í™˜ ì‹œë„
                if isinstance(raw_total, (int, float)):
                    result['total_segments'] = max(1, int(raw_total))
                elif isinstance(raw_total, str) and raw_total.strip().isdigit():
                    result['total_segments'] = max(1, int(raw_total.strip()))
                elif raw_total is None:
                    # ìµœí›„ì˜ ë³´ë£¨: partition_map í¬ê¸° ì²´í¬ ë˜ëŠ” 1ë¡œ ê°•ì œ
                    p_map = event.get('partition_map', [])
                    result['total_segments'] = len(p_map) if isinstance(p_map, list) and p_map else 1
                    logger.info(f"ğŸ›¡ï¸ [v2.5] total_segments forced to {result['total_segments']}")
                else:
                    # Dict, List ë“± ì˜ˆìƒì¹˜ ëª»í•œ íƒ€ì…
                    logger.error(f"ğŸš¨ Invalid total_segments type: {type(raw_total).__name__} = {raw_total}")
                    p_map = event.get('partition_map', [])
                    result['total_segments'] = len(p_map) if isinstance(p_map, list) and p_map else 1
            except (TypeError, ValueError) as e:
                # ëª¨ë“  ë³€í™˜ ì‹œë„ ì‹¤íŒ¨ ì‹œ
                logger.error(f"ğŸš¨ Failed to convert total_segments: {e}, raw_value={raw_total}")
                result['total_segments'] = 1
            
            # ğŸ›¡ï¸ [v2.5] thresholdë„ resultì— í¬í•¨ (ë””ë²„ê¹…ìš©)
            if 'state_size_threshold' not in result:
                result['state_size_threshold'] = service.threshold
        
        logger.info("âœ… Segment Runner finished successfully.")
        return result

    except Exception as e:
        logger.exception("âŒ Segment Runner failed")
        # Return error state that Step Functions can catch
        # [Fix] ASL ResultSelectorê°€ ê¸°ëŒ€í•˜ëŠ” ëª¨ë“  í•„ë“œë¥¼ í¬í•¨í•´ì•¼ JSONPath ì—ëŸ¬ ë°©ì§€
        error_info = {
            "error": str(e),
            "error_type": type(e).__name__
        }
        
        # ğŸ›¡ï¸ [P0 Fix] total_segments ì•ˆì „ ì¶”ì¶œ - TypeError ë°©ì§€
        p_map = event.get('partition_map', [])
        raw_total = event.get('total_segments')
        if raw_total is not None and isinstance(raw_total, (int, float)):
            safe_total_segments = max(1, int(raw_total))
        elif isinstance(p_map, list) and p_map:
            safe_total_segments = len(p_map)
        else:
            safe_total_segments = 1
        
        return {
            "status": "FAILED",
            "error": str(e),
            "error_type": type(e).__name__,
            # ASLì´ í•„ìˆ˜ë¡œ ìš”êµ¬í•˜ëŠ” í•„ë“œë“¤ - None/ë¹ˆê°’ìœ¼ë¡œ ì œê³µ
            "final_state": event.get('current_state', {}),  # ë§ˆì§€ë§‰ ì•Œë ¤ì§„ ìƒíƒœ ë³´ì¡´
            "final_state_s3_path": None,
            "next_segment_to_run": None,
            "new_history_logs": [],
            "error_info": error_info,
            "branches": None,
            "segment_type": "ERROR",
            # ğŸ›¡ï¸ [P0 Fix] Step Functions Choiceì—ì„œ ì°¸ì¡°í•˜ëŠ” í•„ìˆ˜ í•„ë“œ
            "total_segments": safe_total_segments,
            "segment_id": event.get('segment_id', 0)
        }

# --- Legacy Helper Imports Preservation ---
# To avoid breaking other files that import from here during transition
# (though ideally they should import from src.services now)
from src.services.state.state_manager import StateManager
from src.services.workflow.repository import WorkflowRepository
# We re-export run_workflow from main to keep interface if used as lib
from src.handlers.core.main import run_workflow, partition_workflow, _build_segment_config

