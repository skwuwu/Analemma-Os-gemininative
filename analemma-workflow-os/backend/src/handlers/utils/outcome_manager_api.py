# -*- coding: utf-8 -*-
"""
Outcome Manager API Handler

ê²°ê³¼ë¬¼ ì¤‘ì‹¬(Outcome-First) UIë¥¼ ìœ„í•œ API ì—”ë“œí¬ì¸íŠ¸ì…ë‹ˆë‹¤.

í•µì‹¬ ì›ì¹™: "ì‚¬ìš©ìëŠ” ê²°ê³¼ì— ì§‘ì¤‘í•˜ê³ , ê³¼ì •ì€ í•„ìš”í•  ë•Œë§Œ ë³¸ë‹¤"

ê¸°ëŠ¥:
1. ê²°ê³¼ë¬¼ ëª©ë¡ ì¡°íšŒ (ì™„ì„±ëœ ì•„í‹°íŒ©íŠ¸ ìš°ì„ )
2. ì¶•ì•½ëœ íˆìŠ¤í† ë¦¬ ì œê³µ
3. ìƒì„¸ íˆìŠ¤í† ë¦¬ëŠ” on-demand ë¡œë”©

ì—”ë“œí¬ì¸íŠ¸:
- GET /tasks/{taskId}/outcomes - ê²°ê³¼ë¬¼ ëª©ë¡
- GET /tasks/{taskId}/outcomes/{artifactId}/reasoning - ì‚¬ê³  ê³¼ì • ì¡°íšŒ
"""

import os
import json
import logging
from datetime import datetime, timezone
from typing import Dict, Any, List, Optional
from decimal import Decimal

import boto3
from botocore.exceptions import ClientError
from pydantic import BaseModel, Field

logger = logging.getLogger()
logger.setLevel(logging.INFO)

# í™˜ê²½ ë³€ìˆ˜ - ğŸš¨ [Critical Fix] ê¸°ë³¸ê°’ì„ template.yamlê³¼ ì¼ì¹˜ì‹œí‚´
EXECUTIONS_TABLE = os.environ.get("EXECUTIONS_TABLE", "ExecutionsTableV3")
S3_BUCKET = os.environ.get("WORKFLOW_STATE_BUCKET", "")
PRESIGNED_URL_EXPIRY_SECONDS = int(os.environ.get("PRESIGNED_URL_EXPIRY_SECONDS", "3600"))  # 1ì‹œê°„

# ì¸ë©”ëª¨ë¦¬ ìºì‹œ (Lambda warm start ê°„ ê³µìœ )
_reasoning_cache: Dict[str, tuple] = {}  # {cache_key: (data, timestamp)}
CACHE_TTL_SECONDS = 300  # 5ë¶„

# AWS í´ë¼ì´ì–¸íŠ¸
dynamodb = boto3.resource("dynamodb", region_name=os.environ.get("AWS_REGION", "us-east-1"))
executions_table = dynamodb.Table(EXECUTIONS_TABLE)
s3_client = boto3.client("s3", region_name=os.environ.get("AWS_REGION", "us-east-1"))


# =============================================================================
# Pydantic ìŠ¤í‚¤ë§ˆ
# =============================================================================

class OutcomeItem(BaseModel):
    """ë‹¨ì¼ ê²°ê³¼ë¬¼"""
    artifact_id: str
    artifact_type: str
    title: str
    preview_text: Optional[str] = None
    content_ref: Optional[str] = None
    download_url: Optional[str] = None
    is_final: bool = False
    version: int = 1
    created_at: str
    logic_trace_id: Optional[str] = None
    word_count: Optional[int] = None
    file_size_bytes: Optional[int] = None


class CollapsedHistoryResponse(BaseModel):
    """ì¶•ì•½ëœ íˆìŠ¤í† ë¦¬"""
    summary: str
    node_count: int = 0
    llm_call_count: int = 0
    total_duration_seconds: Optional[float] = None
    key_decisions: List[str] = []
    full_trace_available: bool = False


class OutcomesResponse(BaseModel):
    """ê²°ê³¼ë¬¼ ëª©ë¡ ì‘ë‹µ"""
    task_id: str
    task_title: str
    status: str
    outcomes: List[OutcomeItem]
    collapsed_history: CollapsedHistoryResponse
    correction_applied: bool = False
    last_updated: str


class ReasoningStep(BaseModel):
    """ì‚¬ê³  ê³¼ì • ë‹¨ê³„"""
    step_id: str
    timestamp: str
    step_type: str  # decision, observation, action, reasoning
    content: str
    node_id: Optional[str] = None
    confidence: Optional[float] = None


class ReasoningPathResponse(BaseModel):
    """ìƒì„¸ ì‚¬ê³  ê³¼ì • ì‘ë‹µ"""
    artifact_id: str
    artifact_title: str
    reasoning_steps: List[ReasoningStep]
    total_steps: int
    total_duration_seconds: Optional[float] = None


# =============================================================================
# ë©”ì¸ í•¸ë“¤ëŸ¬
# =============================================================================

def lambda_handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:
    """
    API Gateway ìš”ì²­ ì²˜ë¦¬
    """
    try:
        http_method = event.get("httpMethod") or event.get("requestContext", {}).get("http", {}).get("method", "GET")
        path = event.get("path") or event.get("rawPath", "")
        path_params = event.get("pathParameters", {}) or {}
        
        task_id = path_params.get("taskId") or path_params.get("task_id")
        artifact_id = path_params.get("artifactId") or path_params.get("artifact_id")
        
        # ì†Œìœ ì ID ì¶”ì¶œ (Cognito JWT claims)
        # HTTP API v2 format: requestContext.authorizer.jwt.claims.sub
        # REST API v1 format: requestContext.authorizer.claims.sub
        authorizer = event.get("requestContext", {}).get("authorizer", {})
        claims = authorizer.get("jwt", {}).get("claims", {}) or authorizer.get("claims", {})
        request_owner_id = claims.get("sub")
        
        if not request_owner_id:
            logger.error(f"No owner_id found. Event structure: {json.dumps(event.get('requestContext', {}), default=str)}")
            return _error_response(401, "Unauthorized: missing owner_id")
        
        if not task_id:
            return _error_response(400, "task_id is required")
        
        # ë¼ìš°íŒ…
        if artifact_id and "reasoning" in path:
            # GET /tasks/{taskId}/outcomes/{artifactId}/reasoning
            return _get_reasoning_path(task_id, artifact_id, request_owner_id)
        else:
            # GET /tasks/{taskId}/outcomes
            return _get_outcomes(task_id, request_owner_id)
        
    except Exception as e:
        logger.error(f"Error in outcome manager: {e}", exc_info=True)
        return _error_response(500, str(e))


def _get_outcomes(task_id: str, request_owner_id: str) -> Dict[str, Any]:
    """
    ê²°ê³¼ë¬¼ ëª©ë¡ ì¡°íšŒ (Outcome-First)
    """
    try:
        # DynamoDBì—ì„œ Task ì¡°íšŒ
        response = executions_table.get_item(Key={"execution_id": task_id})
        task = response.get("Item")
        
        if not task:
            return _error_response(404, f"Task not found: {task_id}")
        
        # ì†Œìœ ê¶Œ ê²€ì¦
        task_owner_id = task.get("ownerId") or task.get("user_id") or task.get("created_by")
        if task_owner_id != request_owner_id:
            logger.warning(f"Unauthorized access attempt: user {request_owner_id} tried to access task {task_id}")
            return _error_response(403, "You do not have permission to access this task")
        
        # ê²°ê³¼ë¬¼ ì¶”ì¶œ ë° ì •ë ¬ (ìµœì¢… ê²°ê³¼ë¬¼ ìš°ì„ )
        artifacts = task.get("artifacts", [])
        outcomes = []
        
        for artifact in artifacts:
            is_final = artifact.get("is_final", False)
            extended = artifact.get("extended_metadata", {})
            
            outcome = OutcomeItem(
                artifact_id=artifact.get("artifact_id", ""),
                artifact_type=artifact.get("artifact_type", "text"),
                title=artifact.get("title", "ê²°ê³¼ë¬¼"),
                preview_text=artifact.get("preview_content", "")[:300] if artifact.get("preview_content") else None,
                content_ref=extended.get("content_ref"),
                download_url=_generate_presigned_url(extended.get("content_ref")),  # Presigned URL ìƒì„±
                is_final=is_final,
                version=extended.get("version", 1),
                created_at=artifact.get("created_at", datetime.now(timezone.utc).isoformat()),
                logic_trace_id=artifact.get("logic_trace_id") or extended.get("logic_trace_id"),
                word_count=extended.get("word_count"),
                file_size_bytes=extended.get("file_size_bytes"),
            )
            outcomes.append(outcome)
        
        # ìµœì¢… ê²°ê³¼ë¬¼ ìš°ì„  ì •ë ¬
        outcomes.sort(key=lambda x: (not x.is_final, x.created_at), reverse=True)
        
        # ì¶•ì•½ëœ íˆìŠ¤í† ë¦¬ ìƒì„±
        collapsed_history = _build_collapsed_history(task)
        
        # ì‘ë‹µ êµ¬ì„±
        response_data = OutcomesResponse(
            task_id=task_id,
            task_title=task.get("execution_alias") or task.get("task_summary") or f"ì‘ì—… #{task_id[:8]}",
            status=task.get("status", "UNKNOWN"),
            outcomes=[o.model_dump() for o in outcomes],
            collapsed_history=collapsed_history.model_dump(),
            correction_applied=task.get("correction_delta") is not None,
            last_updated=task.get("updated_at", datetime.now(timezone.utc).isoformat()),
        )
        
        return {
            "statusCode": 200,
            "body": json.dumps(response_data.model_dump(), ensure_ascii=False, default=str)
        }
        
    except ClientError as e:
        logger.error(f"DynamoDB error: {e}")
        return _error_response(500, "Database error")


def _build_collapsed_history(task: Dict[str, Any]) -> CollapsedHistoryResponse:
    """
    ì¶•ì•½ëœ íˆìŠ¤í† ë¦¬ êµ¬ì¶•
    """
    # ê¸°ì¡´ collapsed_historyê°€ ìˆìœ¼ë©´ ì‚¬ìš©
    existing = task.get("collapsed_history", {})
    if existing:
        return CollapsedHistoryResponse(
            summary=existing.get("summary", ""),
            node_count=existing.get("node_count", 0),
            llm_call_count=existing.get("llm_call_count", 0),
            total_duration_seconds=existing.get("total_duration_seconds"),
            key_decisions=existing.get("key_decisions", [])[:3],
            full_trace_available=bool(existing.get("full_trace_ref")),
        )
    
    # íˆìŠ¤í† ë¦¬ì—ì„œ ë™ì  ìƒì„±
    state_history = task.get("state_history", [])
    thought_history = task.get("thought_history", [])
    
    node_count = len(set(s.get("state_name", "") for s in state_history))
    llm_call_count = sum(1 for t in thought_history if "llm" in t.get("thought_type", "").lower())
    
    # ì´ ì†Œìš” ì‹œê°„ ê³„ì‚°
    started_at = task.get("started_at")
    completed_at = task.get("completed_at") or task.get("updated_at")
    duration = None
    
    if started_at and completed_at:
        try:
            start = datetime.fromisoformat(started_at.replace("Z", "+00:00"))
            end = datetime.fromisoformat(completed_at.replace("Z", "+00:00"))
            duration = (end - start).total_seconds()
        except (ValueError, TypeError):
            pass
    
    # í•µì‹¬ ì˜ì‚¬ê²°ì • ì¶”ì¶œ (ì¤‘ìš” í‘œì‹œëœ thought)
    key_decisions = [
        t.get("message", "")[:100]
        for t in thought_history
        if t.get("is_important") or t.get("thought_type") == "decision"
    ][:3]
    
    # ìš”ì•½ ìƒì„±
    status = task.get("status", "UNKNOWN")
    if status in ("COMPLETED", "SUCCEEDED", "COMPLETE"):
        summary = f"{node_count}ê°œì˜ ë‹¨ê³„ë¥¼ ê±°ì³ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
    elif status in ("FAILED", "ERROR"):
        summary = f"{node_count}ê°œì˜ ë‹¨ê³„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    elif status == "PAUSED_FOR_HITP":
        summary = f"{node_count}ê°œì˜ ë‹¨ê³„ë¥¼ ì§„í–‰ ì¤‘, ìŠ¹ì¸ ëŒ€ê¸°ì…ë‹ˆë‹¤."
    else:
        summary = f"{node_count}ê°œì˜ ë‹¨ê³„ë¥¼ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤."
    
    return CollapsedHistoryResponse(
        summary=summary,
        node_count=node_count,
        llm_call_count=llm_call_count,
        total_duration_seconds=duration,
        key_decisions=key_decisions,
        full_trace_available=len(state_history) > 0,
    )


def _get_reasoning_path(task_id: str, artifact_id: str, request_owner_id: str) -> Dict[str, Any]:
    """
    íŠ¹ì • ê²°ê³¼ë¬¼ì˜ ìƒì„¸ ì‚¬ê³  ê³¼ì • ì¡°íšŒ
    ì¸ë©”ëª¨ë¦¬ ìºì‹±ì„ ì ìš©í•˜ì—¬ S3 í˜¸ì¶œ ë¹„ìš© ì ˆê°
    """
    try:
        # DynamoDBì—ì„œ Task ì¡°íšŒ
        response = executions_table.get_item(Key={"execution_id": task_id})
        task = response.get("Item")
        
        if not task:
            return _error_response(404, f"Task not found: {task_id}")
        
        # ì†Œìœ ê¶Œ ê²€ì¦
        task_owner_id = task.get("ownerId") or task.get("user_id") or task.get("created_by")
        if task_owner_id != request_owner_id:
            logger.warning(f"Unauthorized access attempt: user {request_owner_id} tried to access task {task_id}")
            return _error_response(403, "You do not have permission to access this task")
        
        # ìƒíƒœ í™•ì¸ - Empty State ì²˜ë¦¬
        status = task.get("status", "UNKNOWN")
        if status in ("QUEUED", "PENDING", "INITIALIZING"):
            return _user_friendly_response(
                task_id=task_id,
                artifact_id=artifact_id,
                status=status,
                message="AIê°€ ì‘ì—…ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”."
            )
        elif status in ("RUNNING", "IN_PROGRESS"):
            return _user_friendly_response(
                task_id=task_id,
                artifact_id=artifact_id,
                status=status,
                message="AIê°€ ê²°ê³¼ë¬¼ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤. ì™„ë£Œë˜ë©´ ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤."
            )
        
        # í•´ë‹¹ ì•„í‹°íŒ©íŠ¸ ì°¾ê¸°
        artifacts = task.get("artifacts", [])
        target_artifact = None
        
        for artifact in artifacts:
            if artifact.get("artifact_id") == artifact_id:
                target_artifact = artifact
                break
        
        if not target_artifact:
            return _error_response(404, f"Artifact not found: {artifact_id}")
        
        # ì‚¬ê³  ê³¼ì • ì¶”ì¶œ
        logic_trace_id = target_artifact.get("logic_trace_id")
        reasoning_steps = []
        
        # thought_historyì—ì„œ ê´€ë ¨ í•­ëª© ì¶”ì¶œ
        thought_history = task.get("thought_history", [])
        
        for i, thought in enumerate(thought_history):
            # logic_trace_idê°€ ìˆìœ¼ë©´ í•´ë‹¹ ì‹œì ê¹Œì§€ë§Œ
            if logic_trace_id and thought.get("thought_id") == logic_trace_id:
                # ì´ ì‹œì ê¹Œì§€ì˜ ì‚¬ê³  ê³¼ì •
                break
            
            step = ReasoningStep(
                step_id=thought.get("thought_id", f"step_{i}"),
                timestamp=thought.get("timestamp", datetime.now(timezone.utc).isoformat()),
                step_type=_map_thought_type(thought.get("thought_type", "progress")),
                content=thought.get("message", ""),
                node_id=thought.get("node_id"),
                confidence=thought.get("confidence"),
            )
            reasoning_steps.append(step)
        
        # S3ì—ì„œ ì¶”ê°€ íŠ¸ë ˆì´ìŠ¤ ë¡œë“œ (ìˆëŠ” ê²½ìš°)
        extended = target_artifact.get("extended_metadata", {})
        reasoning_path_ref = extended.get("reasoning_path_ref")
        
        if reasoning_path_ref:
            additional_steps = _load_reasoning_from_s3(reasoning_path_ref)
            reasoning_steps.extend(additional_steps)
        
        # ì´ ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
        total_duration_seconds = _calculate_total_duration(reasoning_steps, task)
        
        # ì‘ë‹µ êµ¬ì„±
        response_data = ReasoningPathResponse(
            artifact_id=artifact_id,
            artifact_title=target_artifact.get("title", "ê²°ê³¼ë¬¼"),
            reasoning_steps=[s.model_dump() for s in reasoning_steps],
            total_steps=len(reasoning_steps),
            total_duration_seconds=total_duration_seconds,
        )
        
        return {
            "statusCode": 200,
            "body": json.dumps(response_data.model_dump(), ensure_ascii=False, default=str)
        }
        
    except ClientError as e:
        logger.error(f"DynamoDB error: {e}")
        return _error_response(500, "Database error")


def _map_thought_type(thought_type: str) -> str:
    """thought_typeì„ reasoning step typeìœ¼ë¡œ ë§¤í•‘"""
    mapping = {
        "progress": "observation",
        "decision": "decision",
        "question": "reasoning",
        "warning": "observation",
        "success": "action",
        "error": "observation",
    }
    return mapping.get(thought_type, "observation")


def _calculate_total_duration(reasoning_steps: List[ReasoningStep], task: Dict[str, Any]) -> Optional[float]:
    """
    ì´ ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
    
    ìš°ì„ ìˆœìœ„:
    1. Taskì˜ started_at ~ completed_at ì‚¬ìš©
    2. Reasoning stepsì˜ ì²« ë²ˆì§¸ ~ ë§ˆì§€ë§‰ timestamp ì‚¬ìš©
    3. ê³„ì‚° ë¶ˆê°€ ì‹œ None ë°˜í™˜
    """
    # ë°©ë²• 1: Task ë©”íƒ€ë°ì´í„°ì—ì„œ ê³„ì‚°
    started_at = task.get("started_at") or task.get("startedAt") or task.get("created_at")
    completed_at = task.get("completed_at") or task.get("completedAt") or task.get("updated_at")
    
    if started_at and completed_at:
        try:
            # ISO í˜•ì‹ íŒŒì‹±
            if isinstance(started_at, str):
                start_dt = datetime.fromisoformat(started_at.replace('Z', '+00:00'))
            else:
                start_dt = started_at
            
            if isinstance(completed_at, str):
                end_dt = datetime.fromisoformat(completed_at.replace('Z', '+00:00'))
            else:
                end_dt = completed_at
            
            duration = (end_dt - start_dt).total_seconds()
            if duration >= 0:
                return round(duration, 2)
        except Exception as e:
            logger.debug(f"Failed to calculate duration from task metadata: {e}")
    
    # ë°©ë²• 2: Reasoning stepsì—ì„œ ê³„ì‚°
    if reasoning_steps and len(reasoning_steps) >= 2:
        try:
            timestamps = []
            for step in reasoning_steps:
                ts = step.timestamp if hasattr(step, 'timestamp') else step.get('timestamp')
                if ts:
                    if isinstance(ts, str):
                        dt = datetime.fromisoformat(ts.replace('Z', '+00:00'))
                    else:
                        dt = ts
                    timestamps.append(dt)
            
            if len(timestamps) >= 2:
                timestamps.sort()
                duration = (timestamps[-1] - timestamps[0]).total_seconds()
                if duration >= 0:
                    return round(duration, 2)
        except Exception as e:
            logger.debug(f"Failed to calculate duration from reasoning steps: {e}")
    
    return None


def _load_reasoning_from_s3(s3_ref: str) -> List[ReasoningStep]:
    """
    S3ì—ì„œ ìƒì„¸ ì‚¬ê³  ê³¼ì • ë¡œë“œ (ì¸ë©”ëª¨ë¦¬ ìºì‹± ì ìš©)
    """
    # ìºì‹œ í™•ì¸
    cache_key = s3_ref
    if cache_key in _reasoning_cache:
        cached_data, cached_time = _reasoning_cache[cache_key]
        if (datetime.now(timezone.utc) - cached_time).total_seconds() < CACHE_TTL_SECONDS:
            logger.info(f"Cache hit for reasoning path: {s3_ref}")
            return cached_data
    
    try:
        if s3_ref.startswith("s3://"):
            parts = s3_ref[5:].split("/", 1)
            bucket = parts[0]
            key = parts[1] if len(parts) > 1 else ""
        else:
            bucket = S3_BUCKET
            key = s3_ref
        
        response = s3_client.get_object(Bucket=bucket, Key=key)
        content = response["Body"].read().decode("utf-8")
        data = json.loads(content)
        
        steps = []
        for item in data.get("steps", []):
            steps.append(ReasoningStep(
                step_id=item.get("id", ""),
                timestamp=item.get("timestamp", ""),
                step_type=item.get("type", "observation"),
                content=item.get("content", ""),
                node_id=item.get("node_id"),
                confidence=item.get("confidence"),
            ))
        
        # ìºì‹œì— ì €ì¥
        _reasoning_cache[cache_key] = (steps, datetime.now(timezone.utc))
        
        # ìºì‹œ í¬ê¸° ì œí•œ (100ê°œ)
        if len(_reasoning_cache) > 100:
            oldest_key = min(_reasoning_cache, key=lambda k: _reasoning_cache[k][1])
            del _reasoning_cache[oldest_key]
        
        return steps
        
    except Exception as e:
        logger.warning(f"Failed to load reasoning from S3: {e}")
        return []


def _generate_presigned_url(content_ref: Optional[str]) -> Optional[str]:
    """
    S3 ê°ì²´ì— ëŒ€í•œ Presigned URL ìƒì„±
    ìœ íš¨ì‹œê°„ì´ ì§§ì€ URLì„ ìƒì„±í•˜ì—¬ ë³´ì•ˆ ê°•í™”
    """
    if not content_ref:
        return None
    
    try:
        if content_ref.startswith("s3://"):
            parts = content_ref[5:].split("/", 1)
            bucket = parts[0]
            key = parts[1] if len(parts) > 1 else ""
        else:
            bucket = S3_BUCKET
            key = content_ref
        
        if not bucket or not key:
            return None
        
        presigned_url = s3_client.generate_presigned_url(
            "get_object",
            Params={"Bucket": bucket, "Key": key},
            ExpiresIn=PRESIGNED_URL_EXPIRY_SECONDS
        )
        
        return presigned_url
        
    except Exception as e:
        logger.warning(f"Failed to generate presigned URL: {e}")
        return None


def _user_friendly_response(
    task_id: str,
    artifact_id: str,
    status: str,
    message: str
) -> Dict[str, Any]:
    """
    ì‘ì—… ì§„í–‰ ì¤‘ì¼ ë•Œ ì‚¬ìš©ì ì¹œí™”ì ì¸ ì‘ë‹µ ìƒì„±
    ì—ëŸ¬ ëŒ€ì‹  ìƒíƒœ ì •ë³´ì™€ ì•ˆë‚´ ë©”ì‹œì§€ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """
    response_data = {
        "task_id": task_id,
        "artifact_id": artifact_id,
        "status": status,
        "is_ready": False,
        "message": message,
        "reasoning_steps": [],
        "total_steps": 0,
        "retry_after_seconds": 5 if status in ("RUNNING", "IN_PROGRESS") else 10,
    }
    
    return {
        "statusCode": 202,  # Accepted (ì²˜ë¦¬ ì¤‘)
        "body": json.dumps(response_data, ensure_ascii=False)
    }


def _error_response(status_code: int, message: str) -> Dict[str, Any]:
    """ì—ëŸ¬ ì‘ë‹µ"""
    return {
        "statusCode": status_code,
        "body": json.dumps({"error": message}, ensure_ascii=False)
    }
