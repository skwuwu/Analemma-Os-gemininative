{
  "id": "COST_OPTIMIZED_PARALLEL_TEST",
  "name": "Cost Optimized Parallel Scheduler Test",
  "description": "[Enhanced] COST_OPTIMIZED 전략 + 배치 분할 검증 + 토큰 스트레스 테스트",
  "version": "1.0.1",
  "test_category": "cost_guardrail",
  "nodes": [
    {
      "id": "setup",
      "type": "operator",
      "label": "테스트 설정",
      "config": {
        "language": "python",
        "code": "# 20개 문서 (각 1000 토큰 추정 = 20,000 토큰)\nstate['documents'] = [f'Long document content {i} ' * 150 for i in range(20)]\n# 50개 쿼리 (각 100 토큰 추정 = 5,000 토큰)\nstate['queries'] = [f'Complex query {i} ' * 10 for i in range(50)]\nstate['setup_complete'] = True\nprint(f'Setup: {len(state[\"documents\"])} documents (20k tokens), {len(state[\"queries\"])} queries (5k tokens)')"
      }
    },
    {
      "id": "cost_aware_parallel",
      "type": "parallel_group",
      "label": "비용 인지 병렬 그룹 (토큰 스트레스)",
      "resource_policy": {
        "max_concurrent_memory_mb": 2048,
        "max_concurrent_tokens": 10000,
        "max_concurrent_branches": 5,
        "strategy": "COST_OPTIMIZED"
      },
      "branches": [
        {
          "id": "branch_doc_summarize",
          "name": "문서 요약 (토큰 Heavy)",
          "nodes": [
            {
              "id": "doc_foreach",
              "type": "for_each",
              "config": {
                "input_list_key": "documents",
                "output_key": "summaries",
                "sub_node_config": {
                  "nodes": [
                    {
                      "id": "summarize_llm",
                      "type": "llm_chat",
                      "config": {
                        "model": "gemini-2.0-flash",
                        "prompt_template": "Summarize: {{item}}",
                        "output_key": "summary"
                      }
                    }
                  ],
                  "edges": []
                }
              }
            }
          ],
          "edges": []
        },
        {
          "id": "branch_query_process",
          "name": "쿼리 처리 (토큰 Medium)",
          "nodes": [
            {
              "id": "query_llm",
              "type": "llm_chat",
              "config": {
                "model": "gemini-2.0-flash",
                "prompt_template": "Process queries: {{queries}}",
                "output_key": "query_results"
              }
            }
          ],
          "edges": []
        },
        {
          "id": "branch_light_calc",
          "name": "경량 계산",
          "nodes": [
            {
              "id": "calc_code",
              "type": "operator",
              "config": {
                "language": "python",
                "code": "state['calc_result'] = sum(range(1000))"
              }
            }
          ],
          "edges": []
        }
      ]
    },
    {
      "id": "verify",
      "type": "operator",
      "label": "비용 최적화 검증",
      "config": {
        "language": "python",
        "code": "import json\n\nprint('[COST_OPTIMIZED VERIFICATION] Checking batch split results')\nprint(f'[DEBUG] State keys available: {list(state.keys())}')\n\n# ① scheduling_metadata 추출 (스케줄러가 저장한 예측 토큰)\nmetadata = state.get('scheduling_metadata', {})\nbatch_count = metadata.get('batch_count', 0)\nstrategy = metadata.get('strategy', '')\ntotal_tokens_scheduled = metadata.get('total_tokens', 0)\n\n# ② Backend Aggregator가 자동 집계한 실제 토큰 사용\n# Distributed mode: _handle_aggregator가 모든 브랜치 결과를 순회하며 토큰 합산\ntotal_tokens_actual = state.get('total_tokens', 0)\ntotal_input_tokens = state.get('total_input_tokens', 0)\ntotal_output_tokens = state.get('total_output_tokens', 0)\nbranch_token_details = state.get('branch_token_details', [])\n\n# ③ 토큰 값 결정: 스케줄러 예측값 또는 실제 집계값 중 유효한 값 사용\n# Mock 모드에서는 실제 LLM 호출이 없어 actual이 0이므로 scheduled 사용\ntotal_tokens = total_tokens_scheduled if total_tokens_scheduled > 0 else total_tokens_actual\n\nprint(f'Metadata: {json.dumps(metadata, indent=2)}')\nprint(f'Scheduled Tokens: {total_tokens_scheduled}')\nprint(f'Actual Aggregated Tokens: {total_tokens_actual}')\nprint(f'Using: {total_tokens} tokens')\nprint(f'Branch Token Details: {len(branch_token_details)} branches')\n\n# ④ 예상 검증: Bin Packing 알고리즘의 실제 동작\nexpected_min_batches = 2\n\nchecks = [\n    strategy == 'COST_OPTIMIZED',\n    batch_count >= expected_min_batches,\n    total_tokens > 20000,  # 최소 20k 토큰 확인\n    isinstance(branch_token_details, list)\n]\n\nall_passed = all(checks)\n\nprint(f'Strategy: {strategy} (expected: COST_OPTIMIZED)')\nprint(f'Batch Count: {batch_count} (expected: >={expected_min_batches})')\nprint(f'Total Tokens: {total_tokens} (expected: >20000)')\nprint(f'All checks passed: {all_passed}')\n\nstate['cost_test_complete'] = True\nstate['branch_count'] = 3\nstate['batch_verification'] = {\n    'strategy': strategy,\n    'batch_count': batch_count,\n    'total_tokens': total_tokens,\n    'expected_min_batches': expected_min_batches,\n    'batch_split_occurred': batch_count >= expected_min_batches,\n    'checks': checks,\n    'all_passed': all_passed\n}\n\nif all_passed:\n    state['TEST_RESULT'] = f'✅ COST_OPTIMIZED SUCCESS: Processed {total_tokens} tokens across {batch_count} batches (limit: 10000)'\n    state['VALIDATION_STATUS'] = 'PASSED'\n    print('✅ Cost optimization validation passed')\nelse:\n    failed_checks = []\n    if strategy != 'COST_OPTIMIZED': failed_checks.append(f'strategy={strategy}')\n    if batch_count < expected_min_batches: failed_checks.append(f'batch_count={batch_count}<{expected_min_batches}')\n    if total_tokens <= 20000: failed_checks.append(f'total_tokens={total_tokens}<=20000')\n    \n    state['TEST_RESULT'] = f'❌ COST_OPTIMIZED FAILED: {failed_checks}'\n    state['VALIDATION_STATUS'] = 'FAILED'\n    print(f'❌ Cost optimization validation failed: {failed_checks}')"
      }
    }
  ],
  "edges": [
    {
      "source": "setup",
      "target": "cost_aware_parallel"
    },
    {
      "source": "cost_aware_parallel",
      "target": "verify"
    }
  ],
  "start_node": "setup",
  "initial_state": {
    "distributed_mode": true
  },
  "metadata": {
    "test_features": [
      "cost_optimized_strategy",
      "token_based_batch_splitting",
      "token_stress_test",
      "scheduling_metadata_verification"
    ],
    "expected_behavior": "Kernel should split 25,000 tokens across multiple batches due to 10,000 token limit",
    "failure_mode": "No batch splitting occurs, all branches run concurrently exceeding token budget"
  }
}