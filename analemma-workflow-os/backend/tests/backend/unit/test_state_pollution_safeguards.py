# -*- coding: utf-8 -*-
"""
ğŸ›¡ï¸ State Pollution Safeguards - í†µí•© í…ŒìŠ¤íŠ¸

ì´ í…ŒìŠ¤íŠ¸ëŠ” ì‚¬ìš©ì ì •ì˜ ì½”ë“œ(Operator)ê°€ ì»¤ë„ì˜ ì˜ì—­ì„ ì¹¨ë²”í•˜ì§€ ëª»í•˜ê²Œ í•˜ëŠ”
'ì‚¬ìš©ì ëª¨ë“œ vs ì»¤ë„ ëª¨ë“œ'ì˜ ê²©ë¦¬ ê³„ì¸µì„ ê²€ì¦í•©ë‹ˆë‹¤.

íŠ¹íˆ 14ë§Œ ë¼ì¸ ê·œëª¨ì˜ ì‹œìŠ¤í…œì—ì„œ MOCK_MODEë¥¼ ë„ê³  ì‹¤ì œ LLMì„ ì˜¬ë ¸ì„ ë•Œ,
ëª¨ë¸ì´ ì„ì˜ì˜ JSON í‚¤ë¥¼ ìƒì„±í•˜ì—¬ ì‹œìŠ¤í…œ ë©”íƒ€ë°ì´í„°ë¥¼ ë®ì–´ì“°ëŠ” ì‚¬ê³ ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.

í…ŒìŠ¤íŠ¸ ë²”ìœ„:
1. RESERVED_STATE_KEYS í•„í„°ë§ (_validate_output_keys)
2. Pydantic ëª¨ë¸ ê²€ì¦ (SafeStateOutput + model_validator)
3. ìƒíƒœ ì˜¤ì—¼ ë°©ì§€ (None ë°˜í™˜ ëŒ€ì‹  í‚¤ ì‚­ì œ)
4. extra í•„ë“œ ê²€ì¦ (model_validatorì˜ ì „ì—­ ìŠ¤ìº”)
"""

import pytest
import logging
from typing import Dict, Any
from pydantic import ValidationError

# í…ŒìŠ¤íŠ¸ ëŒ€ìƒ ì„í¬íŠ¸
import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../src')))

from handlers.core.main import (
    RESERVED_STATE_KEYS,
    _validate_output_keys,
    SafeStateOutput,
    validate_state_with_schema
)

logger = logging.getLogger(__name__)


class TestReservedStateKeys:
    """RESERVED_STATE_KEYS ëª©ë¡ ì™„ì „ì„± í…ŒìŠ¤íŠ¸"""
    
    def test_flow_control_keys_present(self):
        """Flow Control í‚¤ê°€ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ê²€ì¦ (ë£¨í”„/ì„¸ê·¸ë¨¼íŠ¸ ì œì–´)"""
        required_flow_keys = {
            "loop_counter", "max_loop_iterations", "segment_id",
            "segment_to_run", "total_segments", "segment_type"
        }
        assert required_flow_keys.issubset(RESERVED_STATE_KEYS), \
            f"Missing flow control keys: {required_flow_keys - RESERVED_STATE_KEYS}"
    
    def test_state_infrastructure_keys_present(self):
        """State Infrastructure í‚¤ê°€ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ê²€ì¦ (S3 ì˜¤í”„ë¡œë”©)"""
        required_state_keys = {
            "current_state", "final_state", "state_s3_path", "final_state_s3_path",
            "partition_map", "partition_map_s3_path", "__s3_offloaded", "__s3_path"
        }
        assert required_state_keys.issubset(RESERVED_STATE_KEYS), \
            f"Missing state infrastructure keys: {required_state_keys - RESERVED_STATE_KEYS}"
    
    def test_telemetry_keys_present(self):
        """Telemetry í‚¤ê°€ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ê²€ì¦ (ì¶”ì ì„± ë³´í˜¸)"""
        required_telemetry_keys = {
            "step_history", "execution_logs", "__new_history_logs",
            "skill_execution_log", "__kernel_actions"
        }
        assert required_telemetry_keys.issubset(RESERVED_STATE_KEYS), \
            f"Missing telemetry keys: {required_telemetry_keys - RESERVED_STATE_KEYS}"
    
    def test_response_envelope_keys_present(self):
        """Response Envelope í‚¤ê°€ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ê²€ì¦ (Step Functions ì •í•©ì„±)"""
        required_envelope_keys = {"status", "error_info"}
        assert required_envelope_keys.issubset(RESERVED_STATE_KEYS), \
            f"Missing response envelope keys: {required_envelope_keys - RESERVED_STATE_KEYS}"
    
    def test_alias_compatibility_keys_present(self):
        """Alias/Compatibility í‚¤ê°€ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ê²€ì¦ (camelCase & snake_case)"""
        required_alias_keys = {
            "workflowId", "workflow_id", "ownerId", "owner_id"
        }
        assert required_alias_keys.issubset(RESERVED_STATE_KEYS), \
            f"Missing alias keys: {required_alias_keys - RESERVED_STATE_KEYS}"


class TestValidateOutputKeys:
    """_validate_output_keys í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ (Layer 1 ë°©ì–´ì„ )"""
    
    def test_safe_output_passes(self):
        """ì•ˆì „í•œ ì¶œë ¥(ì˜ˆì•½ í‚¤ ì—†ìŒ)ì€ ê·¸ëŒ€ë¡œ í†µê³¼"""
        output = {"result": "success", "data": [1, 2, 3], "user_field": "custom"}
        validated = _validate_output_keys(output, "test_node")
        
        assert validated == output
        assert "result" in validated
        assert "data" in validated
    
    def test_reserved_keys_blocked(self):
        """ì˜ˆì•½ í‚¤ê°€ í¬í•¨ëœ ì¶œë ¥ì€ í•„í„°ë§ë¨"""
        output = {
            "result": "success",
            "loop_counter": 999,  # ì˜ˆì•½ í‚¤ - ì°¨ë‹¨ë˜ì–´ì•¼ í•¨
            "segment_id": 5,  # ì˜ˆì•½ í‚¤ - ì°¨ë‹¨ë˜ì–´ì•¼ í•¨
            "user_field": "custom"
        }
        validated = _validate_output_keys(output, "malicious_node")
        
        # ì˜ˆì•½ í‚¤ëŠ” ì œê±°ë˜ê³  ì•ˆì „í•œ í‚¤ë§Œ ë‚¨ìŒ
        assert "loop_counter" not in validated
        assert "segment_id" not in validated
        assert "result" in validated
        assert "user_field" in validated
    
    def test_flow_control_pollution_blocked(self):
        """Flow Control í‚¤ ì˜¤ì—¼ ì‹œë„ ì°¨ë‹¨ (ë¬´í•œ ë£¨í”„ ë°©ì§€)"""
        output = {
            "loop_counter": 1,  # ë£¨í”„ ì¹´ìš´í„°ë¥¼ 1ë¡œ ì¡°ì‘ ì‹œë„
            "max_loop_iterations": 9999,  # ë£¨í”„ ì œí•œì„ ë¬´í•œìœ¼ë¡œ ë³€ê²½ ì‹œë„
            "result": "hacked"
        }
        validated = _validate_output_keys(output, "loop_hacker")
        
        assert "loop_counter" not in validated
        assert "max_loop_iterations" not in validated
        assert "result" in validated
    
    def test_s3_infrastructure_pollution_blocked(self):
        """S3 Infrastructure í‚¤ ì˜¤ì—¼ ì‹œë„ ì°¨ë‹¨ (S3 ì •í•©ì„± ë³´í˜¸)"""
        output = {
            "state_s3_path": "s3://malicious-bucket/fake-path",
            "__s3_offloaded": True,
            "result": "data_leak_attempt"
        }
        validated = _validate_output_keys(output, "s3_hacker")
        
        assert "state_s3_path" not in validated
        assert "__s3_offloaded" not in validated
        assert "result" in validated
    
    def test_telemetry_pollution_blocked(self):
        """Telemetry í‚¤ ì˜¤ì—¼ ì‹œë„ ì°¨ë‹¨ (ì¶”ì ì„± ë³´í˜¸)"""
        output = {
            "step_history": [],  # íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” ì‹œë„
            "__kernel_actions": {"fake": "action"},
            "execution_logs": "erased",
            "result": "cover_tracks"
        }
        validated = _validate_output_keys(output, "telemetry_eraser")
        
        assert "step_history" not in validated
        assert "__kernel_actions" not in validated
        assert "execution_logs" not in validated
    
    def test_non_dict_output_passes_through(self):
        """ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ì¶œë ¥ì€ ê·¸ëŒ€ë¡œ í†µê³¼ (ë¬¸ìì—´, ë¦¬ìŠ¤íŠ¸ ë“±)"""
        output_str = "simple string result"
        output_list = [1, 2, 3]
        output_none = None
        
        assert _validate_output_keys(output_str, "node1") == output_str
        assert _validate_output_keys(output_list, "node2") == output_list
        assert _validate_output_keys(output_none, "node3") == output_none


class TestPydanticModelValidator:
    """SafeStateOutput Pydantic ëª¨ë¸ í…ŒìŠ¤íŠ¸ (Layer 2 ë°©ì–´ì„ )"""
    
    def test_model_validator_blocks_extra_reserved_keys(self):
        """model_validatorê°€ extra í•„ë“œì˜ ì˜ˆì•½ í‚¤ë„ ì°¨ë‹¨í•˜ëŠ”ì§€ ê²€ì¦"""
        data = {
            "user_field": "custom",
            "__new_history_logs": ["fake", "logs"],  # extra í•„ë“œì´ì§€ë§Œ ì˜ˆì•½ í‚¤
            "partition_map": {"fake": "map"},  # extra í•„ë“œì´ì§€ë§Œ ì˜ˆì•½ í‚¤
            "result": "success"
        }
        
        # model_validatorì—ì„œ ì˜ˆì•½ í‚¤ê°€ ì œê±°ë¨
        validated = SafeStateOutput(**data)
        dumped = validated.model_dump(exclude_none=True, exclude_unset=True)
        
        # ì˜ˆì•½ í‚¤ëŠ” ëª¨ë¸ì—ì„œ ì œê±°ë˜ì–´ì•¼ í•¨
        assert "__new_history_logs" not in dumped
        assert "partition_map" not in dumped
        # ì•ˆì „í•œ í‚¤ëŠ” ë³´ì¡´
        assert "user_field" in dumped
        assert "result" in dumped
    
    def test_frozen_fields_cannot_be_set(self):
        """frozen í•„ë“œëŠ” ì„¤ì •í•  ìˆ˜ ì—†ìŒì„ ê²€ì¦"""
        data = {
            "workflowId": "test-workflow-id",
            "loop_counter": 5
        }
        
        validated = SafeStateOutput(**data)
        
        # frozen í•„ë“œëŠ” ì„¤ì •ë˜ì§€ë§Œ ë³€ê²½ ë¶ˆê°€
        with pytest.raises(ValidationError):
            validated.workflowId = "new-id"  # ë³€ê²½ ì‹œë„ â†’ ì—ëŸ¬
    
    def test_type_coercion_works(self):
        """Pydantic íƒ€ì… ë³€í™˜(coercion)ì´ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ ê²€ì¦"""
        data = {
            "loop_counter": "5",  # ë¬¸ìì—´ â†’ intë¡œ ë³€í™˜ë˜ì–´ì•¼ í•¨
            "max_loop_iterations": "10"
        }
        
        validated = SafeStateOutput(**data)
        
        # íƒ€ì… ë³€í™˜ ê²€ì¦
        assert validated.loop_counter is None or isinstance(validated.loop_counter, int)
        assert validated.max_loop_iterations is None or isinstance(validated.max_loop_iterations, int)
    
    def test_negative_loop_counter_rejected(self):
        """loop_counterì— ìŒìˆ˜ ê°’ì´ ë“¤ì–´ì˜¤ë©´ ê±°ë¶€ë˜ëŠ”ì§€ ê²€ì¦ (ge=0 ì œì•½)"""
        data = {"loop_counter": -1}
        
        # Pydanticì´ ge=0 ì œì•½ì„ ê²€ì¦í•˜ì§€ë§Œ, model_validatorì—ì„œ ë¨¼ì € ì œê±°ë¨
        # ë”°ë¼ì„œ ì—ëŸ¬ê°€ ë°œìƒí•˜ì§€ ì•Šê³  í‚¤ê°€ ì œê±°ë¨
        validated = SafeStateOutput(**data)
        dumped = validated.model_dump(exclude_none=True, exclude_unset=True)
        
        # loop_counterëŠ” ì˜ˆì•½ í‚¤ì´ë¯€ë¡œ ì œê±°ë¨
        assert "loop_counter" not in dumped


class TestValidateStateWithSchema:
    """validate_state_with_schema í†µí•© í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ (2ë‹¨ê³„ ë°©ì–´ ì‹œìŠ¤í…œ)"""
    
    def test_two_layer_defense_blocks_pollution(self):
        """2ë‹¨ê³„ ë°©ì–´(Layer 1 + Layer 2)ê°€ ëª¨ë“  ì˜¤ì—¼ ì‹œë„ë¥¼ ì°¨ë‹¨í•˜ëŠ”ì§€ ê²€ì¦"""
        # ì•…ì˜ì ì¸ ë…¸ë“œ ì¶œë ¥ (ëª¨ë“  ì¢…ë¥˜ì˜ ì˜ˆì•½ í‚¤ í¬í•¨)
        malicious_output = {
            "result": "success",
            "loop_counter": 1,  # Flow Control ì˜¤ì—¼
            "state_s3_path": "s3://fake",  # S3 ì˜¤ì—¼
            "__kernel_actions": {"fake": "action"},  # Telemetry ì˜¤ì—¼
            "segment_id": 999,  # Flow Control ì˜¤ì—¼
            "user_custom_field": "legitimate_data"
        }
        
        # Layer 1: _validate_output_keys
        layer1_output = _validate_output_keys(malicious_output, "malicious_node")
        
        # Layer 2: validate_state_with_schema
        final_output = validate_state_with_schema(layer1_output, "malicious_node")
        
        # ìµœì¢… ì¶œë ¥ì—ëŠ” ì˜ˆì•½ í‚¤ê°€ í•˜ë‚˜ë„ ì—†ì–´ì•¼ í•¨
        for reserved_key in RESERVED_STATE_KEYS:
            assert reserved_key not in final_output, f"Reserved key '{reserved_key}' leaked through defenses!"
        
        # ì•ˆì „í•œ ì‚¬ìš©ì ì •ì˜ í•„ë“œëŠ” ë³´ì¡´ë˜ì–´ì•¼ í•¨
        assert "result" in final_output
        assert "user_custom_field" in final_output
    
    def test_llm_json_pollution_scenario(self):
        """LLMì´ ì„ì˜ì˜ JSONì„ ìƒì„±í•˜ì—¬ ì‹œìŠ¤í…œ í‚¤ë¥¼ ë®ì–´ì“°ëŠ” ì‹œë‚˜ë¦¬ì˜¤"""
        # LLMì´ ìƒì„±í•œ ì•…ì˜ì (ë˜ëŠ” ì‹¤ìˆ˜) JSON
        llm_output = {
            "analysis_result": "completed",
            "loop_counter": 1,  # LLMì´ "ë‹¤ì‹œ ì‹¤í–‰í•˜ë¼"ëŠ” ì˜ë¯¸ë¡œ ìƒì„±
            "status": "failed",  # Response envelope ì˜¤ì—¼
            "segment_to_run": 0,  # ì˜ëª»ëœ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ì í”„ ì‹œë„
            "execution_logs": "LLM generated fake logs",  # ë¡œê·¸ ì˜¤ì—¼
            "final_state": {"documents": []},  # ìµœì¢… ìƒíƒœ ì˜¤ì—¼
            "user_query": "What is the weather?"  # ì •ìƒ í•„ë“œ
        }
        
        # 2ë‹¨ê³„ ë°©ì–´ ì ìš©
        validated = _validate_output_keys(llm_output, "llm_node")
        final = validate_state_with_schema(validated, "llm_node")
        
        # ì˜ˆì•½ í‚¤ëŠ” ëª¨ë‘ ì œê±°ë˜ì–´ì•¼ í•¨
        assert "loop_counter" not in final
        assert "status" not in final
        assert "segment_to_run" not in final
        assert "execution_logs" not in final
        assert "final_state" not in final
        
        # ì •ìƒ í•„ë“œëŠ” ë³´ì¡´
        assert "analysis_result" in final
        assert "user_query" in final
    
    def test_state_pollution_prevention_on_merge(self):
        """
        ìƒíƒœ ë³‘í•© ì‹œ ì˜¤ì—¼ ë°©ì§€ ê²€ì¦
        
        ì‹œë‚˜ë¦¬ì˜¤:
        - ê¸°ì¡´ ìƒíƒœ: loop_counter = 5
        - ë…¸ë“œ ì¶œë ¥: loop_counter = 1 (ì¡°ì‘ ì‹œë„)
        - ì˜ˆìƒ ê²°ê³¼: loop_counterëŠ” ì¶œë ¥ì—ì„œ ì œê±°ë˜ì–´ ê¸°ì¡´ ê°’(5) ìœ ì§€
        """
        existing_state = {"loop_counter": 5, "result": "initial"}
        node_output = {"loop_counter": 1, "result": "updated"}
        
        # ë°©ì–´ ì‹œìŠ¤í…œ ì ìš©
        validated = _validate_output_keys(node_output, "test_node")
        final = validate_state_with_schema(validated, "test_node")
        
        # loop_counterëŠ” finalì— ì—†ì–´ì•¼ í•¨ (ì œê±°ë¨)
        assert "loop_counter" not in final
        
        # ìƒíƒœ ë³‘í•© ì‹œë®¬ë ˆì´ì…˜
        merged_state = {**existing_state, **final}
        
        # ê¸°ì¡´ loop_counter ê°’ì´ ìœ ì§€ë˜ì–´ì•¼ í•¨ (Noneìœ¼ë¡œ ë®ì–´ì“°ì§€ ì•ŠìŒ)
        assert merged_state["loop_counter"] == 5
        assert merged_state["result"] == "updated"
    
    def test_validation_error_fallback(self):
        """Pydantic ê²€ì¦ ì‹¤íŒ¨ ì‹œ í´ë°± ë™ì‘ í™•ì¸"""
        # íƒ€ì… ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë°ì´í„° (í•˜ì§€ë§Œ Layer 1ì„ í†µê³¼)
        problematic_output = {
            "result": "success",
            "custom_field": {"nested": "data"}
        }
        
        # í´ë°±ì€ ì›ë³¸ì„ ë°˜í™˜ (Layer 1ì„ ì´ë¯¸ í†µê³¼í–ˆìœ¼ë¯€ë¡œ ì•ˆì „)
        final = validate_state_with_schema(problematic_output, "test_node")
        
        # ì›ë³¸ì´ ë°˜í™˜ë˜ì–´ì•¼ í•¨
        assert final == problematic_output


class TestIntegrationWithNodes:
    """ì‹¤ì œ ë…¸ë“œ ì‹¤í–‰ í†µí•© í…ŒìŠ¤íŠ¸"""
    
    def test_llm_node_output_safeguarded(self):
        """LLM ë…¸ë“œ ì¶œë ¥ì´ safeguardë¥¼ í†µê³¼í•˜ëŠ”ì§€ ì‹œë®¬ë ˆì´ì…˜"""
        # LLM ë…¸ë“œê°€ ë°˜í™˜í•˜ëŠ” ì „í˜•ì ì¸ ì¶œë ¥ êµ¬ì¡°
        llm_node_output = {
            "llm_response_output": "Generated text response",
            "llm_response_meta": {
                "model": "claude-sonnet-4",
                "tokens": 150
            },
            "step_history": ["node1:llm_chat:claude"],  # ì˜ˆì•½ í‚¤
            "usage": {"total_tokens": 150}
        }
        
        # ì‹¤ì œ ë…¸ë“œì—ì„œ í˜¸ì¶œë˜ëŠ” ê²ƒê³¼ ë™ì¼í•œ ë°©ì–´ ë¡œì§ ì ìš©
        validated = _validate_output_keys(llm_node_output, "llm_node_1")
        final = validate_state_with_schema(validated, "llm_node_1")
        
        # step_historyëŠ” ì˜ˆì•½ í‚¤ì´ë¯€ë¡œ ì œê±°ë˜ì–´ì•¼ í•¨
        assert "step_history" not in final
        
        # ì •ìƒ í•„ë“œëŠ” ë³´ì¡´
        assert "llm_response_output" in final
        assert "llm_response_meta" in final
    
    def test_operator_node_output_safeguarded(self):
        """Operator ë…¸ë“œ ì¶œë ¥ì´ safeguardë¥¼ í†µê³¼í•˜ëŠ”ì§€ ì‹œë®¬ë ˆì´ì…˜"""
        # ì‚¬ìš©ì ì •ì˜ Operatorê°€ ë°˜í™˜í•˜ëŠ” ì¶œë ¥
        operator_output = {
            "operator_result": {"processed": True},
            "partition_map": {"fake": "map"},  # ì˜ˆì•½ í‚¤ - ì•…ì˜ì  ë˜ëŠ” ì‹¤ìˆ˜
            "current_state": {"leaked": "data"},  # ì˜ˆì•½ í‚¤
            "user_metadata": "custom info"
        }
        
        validated = _validate_output_keys(operator_output, "custom_operator")
        final = validate_state_with_schema(validated, "custom_operator")
        
        # ì˜ˆì•½ í‚¤ ì œê±° í™•ì¸
        assert "partition_map" not in final
        assert "current_state" not in final
        
        # ì •ìƒ í•„ë“œ ë³´ì¡´
        assert "operator_result" in final
        assert "user_metadata" in final


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short"])
