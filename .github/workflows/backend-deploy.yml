name: Backend Deploy

on:
  push:
    branches: [ main ]
    paths:
      - 'analemma-workflow-os/backend/**'
      - 'analemma-workflow-os/backend/scripts/**'
      - '.github/workflows/backend-deploy.yml'
  workflow_dispatch: # Added to allow manual execution (recommended)

jobs:
  deploy-dev:
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    timeout-minutes: 90  # Extended for 64 Lambda Docker builds
    permissions:
      id-token: write
      contents: read
    env:
      STAGE_NAME: dev
      SAM_STACK_NAME: backend-workflow-dev
      AWS_REGION: ${{ secrets.AWS_REGION }}
    environment: dev
    defaults:
      run:
        working-directory: ./analemma-workflow-os/backend

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials using OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}
          role-session-name: GitHubActions-${{ github.run_id }}


      # [Optimization 1] Integrated Python setup and enhanced caching
      # IMPORTANT: Setup Python BEFORE disk cleanup to preserve Python installations
      - name: Setup Python 3.12 (Primary)
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
          cache-dependency-path: |
            analemma-workflow-os/backend/requirements.txt
            analemma-workflow-os/backend/src/requirements.txt

      - name: Setup Python 3.11 for SAM CLI
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      # [Optimization] Maximize disk space (for building 64 Lambda images)
      # Run AFTER Python Setup to avoid deleting required Python versions
      - name: Maximize disk space for Docker builds
        run: |
          echo "=== Current disk space ==="
          df -h
          echo ""
          echo "=== Removing unnecessary tools ==="
          # Remove large tools (~30GB freed) - Keep Python installations
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          sudo rm -rf /usr/local/share/boost
          sudo rm -rf /usr/local/share/chromium
          sudo rm -rf /usr/local/share/powershell
          sudo rm -rf /usr/share/swift
          sudo rm -rf /opt/hostedtoolcache/node
          sudo rm -rf /opt/az
          sudo apt-get clean
          # Clean up unused Docker data
          docker system prune -af --volumes || true
          echo ""
          echo "=== Disk space after cleanup ==="
          df -h


      - name: Verify Python versions
        run: |
          python3.12 --version
          python3.11 --version
          python3 --version

      # [Optimization 2] Enhanced SAM build artifact caching
      - name: Cache SAM Build Artifacts
        uses: actions/cache@v4
        with:
          path: |
            analemma-workflow-os/backend/.aws-sam
            ~/.cache/pip
          key: ${{ runner.os }}-sam-${{ hashFiles('analemma-workflow-os/backend/template.yaml', 'analemma-workflow-os/backend/requirements.txt', 'analemma-workflow-os/backend/src/requirements.txt', 'analemma-workflow-os/backend/Dockerfile.lambda', 'analemma-workflow-os/backend/Dockerfile.base') }}
          restore-keys: |
            ${{ runner.os }}-sam-

      - name: Install Python dependencies
        run: |
          pip install -r src/requirements.txt

      - name: Setup AWS SAM CLI
        uses: aws-actions/setup-sam@v2

      # [FIX] Enable ARM64 cross-compilation for Graviton2 Lambda
      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3
        with:
          platforms: arm64

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      # [Optimization 2] Base Image change detection (maintained)
      - name: Check for Base Image changes
        id: base-image-check
        run: |
          HASH=$(sha256sum Dockerfile.base src/requirements.txt | sha256sum | awk '{print $1}')
          echo "hash=${HASH}" >> $GITHUB_OUTPUT
          echo "Base Image Hash: ${HASH}"

      - name: Create ECR Repository for Base Image
        if: steps.base-image-check.outputs.hash != ''
        run: |
          repo="backend-llm-base"
          aws ecr describe-repositories --repository-names ${repo} --region ${AWS_REGION} || aws ecr create-repository --repository-name ${repo} --region ${AWS_REGION}

      # [Optimization 1] Base Image Docker Layer Caching (using GHA cache)
      - name: Build and Push LLM Base Image
        uses: docker/build-push-action@v5
        id: docker_build
        with:
          context: ./analemma-workflow-os/backend
          file: ./analemma-workflow-os/backend/Dockerfile.base
          platforms: linux/arm64  # [FIX] ARM64 for Graviton2 Lambda
          push: true
          tags: |
            ${{ steps.login-ecr.outputs.registry }}/backend-llm-base:latest
            ${{ steps.login-ecr.outputs.registry }}/backend-llm-base:${{ steps.base-image-check.outputs.hash }}
          # Build speed improved by 50% using GitHub Actions cache
          cache-from: type=gha
          cache-to: type=gha,mode=max
          provenance: false

      - name: Set BASE_IMAGE_URI
        run: |
           echo "BASE_IMAGE_URI=${{ steps.login-ecr.outputs.registry }}/backend-llm-base:latest" >> $GITHUB_ENV

      # [Addition] Create ECR repository for Lambda Image
      - name: Create ECR Repository for Lambda Image
        run: |
          repo="backend-lambda-function"
          aws ecr describe-repositories --repository-names ${repo} --region ${AWS_REGION} || aws ecr create-repository --repository-name ${repo} --region ${AWS_REGION}

      # [REMOVED] cp -r sync step - SAM now uses DockerContext: ./src from Metadata blocks

      # [FIX] Docker build context changed to src/ after apps/ folder deletion
      - name: Build and Push Final Lambda Image
        uses: docker/build-push-action@v5
        id: build-app-image
        with:
          context: ./analemma-workflow-os/backend/src
          file: ./analemma-workflow-os/backend/src/Dockerfile.lambda
          platforms: linux/arm64  # [FIX] ARM64 for Graviton2 Lambda
          push: true
          tags: |
            ${{ steps.login-ecr.outputs.registry }}/backend-lambda-function:latest
            ${{ steps.login-ecr.outputs.registry }}/backend-lambda-function:${{ github.sha }}
          # [FIX] Disable cache temporarily to ensure fresh build with synced src/
          no-cache: true
          provenance: false
          build-args: |
            BASE_IMAGE_URI=${{ env.BASE_IMAGE_URI }}


      - name: Login to Amazon ECR Public
        run: |
          aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws

      # [Optimization 3] Enable SAM Build cache (for template validation)
      - name: SAM Build
        env:
          STAGE_NAME: ${{ env.STAGE_NAME }}
        run: |
          # Docker images are built directly by SAM from DockerContext: ./src (always use latest code with cache disabled)
          sam build --parameter-overrides StageName=${STAGE_NAME}

      # [Added] Pre-allocate Kinesis stream
      - name: Ensure Kinesis Stream Exists
        id: ensure-kinesis
        run: |
          chmod +x scripts/ensure-kinesis.sh
          ./scripts/ensure-kinesis.sh "dev" "${{ env.AWS_REGION }}"

      - name: SAM Deploy
        env:
          STAGE_NAME: ${{ env.STAGE_NAME }}
          SAM_STACK_NAME: ${{ env.SAM_STACK_NAME }}
          AWS_REGION: ${{ env.AWS_REGION }}
          COGNITO_ISSUER_URL: ${{ secrets.COGNITO_ISSUER_URL }}
          COGNITO_AUDIENCE: ${{ secrets.COGNITO_AUDIENCE }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
          TEST_USER_EMAIL: ${{ secrets.TEST_USER_EMAIL || '' }}
          TEST_USER_PASSWORD: ${{ secrets.TEST_USER_PASSWORD || '' }}
          ASYNC_WORKER_ECS_CLUSTER: ${{ secrets.ASYNC_WORKER_ECS_CLUSTER || '' }}
          ASYNC_WORKER_TASK_DEFINITION: ${{ secrets.ASYNC_WORKER_TASK_DEFINITION || '' }}
          ASYNC_WORKER_EXECUTION_ROLE_ARN: ${{ secrets.ASYNC_WORKER_EXECUTION_ROLE_ARN || '' }}
          ASYNC_WORKER_SUBNET_IDS: ${{ secrets.ASYNC_WORKER_SUBNET_IDS || '' }}
          ASYNC_WORKER_SECURITY_GROUP_IDS: ${{ secrets.ASYNC_WORKER_SECURITY_GROUP_IDS || '' }}
          KINESIS_ARN: ${{ env.KINESIS_STREAM_ARN }}
          LAMBDA_IMAGE_URI: ${{ steps.login-ecr.outputs.registry }}/backend-lambda-function:${{ github.sha }}
          IMAGE_REPO_URI: ${{ steps.login-ecr.outputs.registry }}/backend-lambda-function
          WORKFLOW_STATE_BUCKET: ${{ secrets.WORKFLOW_STATE_BUCKET }}
        run: |
          # AllowedOrigins uses default value from template.yaml (not GitHub Secrets)
          PARAM_OVERRIDES="StageName=${STAGE_NAME} CognitoIssuerUrl=${COGNITO_ISSUER_URL} CognitoAudience=${COGNITO_AUDIENCE} OpenAiApiKey=${OPENAI_API_KEY} AnthropicApiKey=${ANTHROPIC_API_KEY} GoogleApiKey=${GOOGLE_API_KEY}"

          # Inject test user secrets (CI/CD ‚Üí AWS Secrets Manager)
          if [ -n "${TEST_USER_EMAIL}" ] && [ -n "${TEST_USER_PASSWORD}" ]; then
            PARAM_OVERRIDES="${PARAM_OVERRIDES} TestUserEmail=${TEST_USER_EMAIL} TestUserPassword=${TEST_USER_PASSWORD}"
          fi

          # [Critical] Specify existing S3 bucket for workflow state to prevent orphan buckets
          if [ -n "${WORKFLOW_STATE_BUCKET}" ]; then
            PARAM_OVERRIDES="${PARAM_OVERRIDES} WorkflowStateBucket=${WORKFLOW_STATE_BUCKET}"
            echo "‚úÖ Using existing S3 bucket for workflow state: ${WORKFLOW_STATE_BUCKET}"
          else
            echo "‚ö†Ô∏è WORKFLOW_STATE_BUCKET not set - CloudFormation will auto-create a new bucket"
          fi

          if [ -n "${ASYNC_WORKER_ECS_CLUSTER}" ]; then
            PARAM_OVERRIDES="${PARAM_OVERRIDES} AsyncWorkerEcsCluster=${ASYNC_WORKER_ECS_CLUSTER}"
          fi
          if [ -n "${ASYNC_WORKER_TASK_DEFINITION}" ]; then
            PARAM_OVERRIDES="${PARAM_OVERRIDES} AsyncWorkerTaskDefinition=${ASYNC_WORKER_TASK_DEFINITION}"
          fi
          if [ -n "${ASYNC_WORKER_EXECUTION_ROLE_ARN}" ]; then
            PARAM_OVERRIDES="${PARAM_OVERRIDES} AsyncWorkerExecutionRoleArn=${ASYNC_WORKER_EXECUTION_ROLE_ARN}"
          fi
          if [ -n "${ASYNC_WORKER_SUBNET_IDS}" ]; then
            PARAM_OVERRIDES="${PARAM_OVERRIDES} AsyncWorkerSubnetIds=${ASYNC_WORKER_SUBNET_IDS}"
          fi
          if [ -n "${ASYNC_WORKER_SECURITY_GROUP_IDS}" ]; then
            PARAM_OVERRIDES="${PARAM_OVERRIDES} AsyncWorkerSecurityGroupIds=${ASYNC_WORKER_SECURITY_GROUP_IDS}"
          fi
          
          if [ -z "${KINESIS_ARN}" ]; then
            echo "‚ùå Error: KINESIS_ARN is empty. Previous step failed to set it."
            exit 1
          fi
          PARAM_OVERRIDES="${PARAM_OVERRIDES} ExternalExecutionsStreamArn=${KINESIS_ARN}"
          
          # [Added] Image URI passing
          PARAM_OVERRIDES="${PARAM_OVERRIDES} BackendLambdaImageUri=${LAMBDA_IMAGE_URI}"

          echo "üöÄ Deploying with Parameters: ${PARAM_OVERRIDES}"

          sam deploy \
            --stack-name "${SAM_STACK_NAME}" \
            --region "${AWS_REGION}" \
            --resolve-s3 \
            --image-repository "${IMAGE_REPO_URI}" \
            --capabilities CAPABILITY_IAM CAPABILITY_NAMED_IAM \
            --no-confirm-changeset \
            --no-fail-on-empty-changeset \
            --parameter-overrides ${PARAM_OVERRIDES}

      - name: Update SSM Parameters
        run: |
          chmod +x scripts/update-api-url-ssm.sh
          ./scripts/update-api-url-ssm.sh "${SAM_STACK_NAME}" "${AWS_REGION}"

      - name: Notify deployment status
        if: always()
        env:
          STAGE_NAME: ${{ env.STAGE_NAME }}
        run: |
          if [ "${{ job.status }}" == "success" ]; then
            echo "‚úÖ Deployment to ${STAGE_NAME} environment successful"
          else
            echo "‚ùå Deployment to ${STAGE_NAME} environment failed"
          fi
